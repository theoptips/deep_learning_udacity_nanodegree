{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "## Project: Write an Algorithm for a Dog Identification App \n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this project. You will not need to modify the included code beyond what is requested. Sections that begin with **'(IMPLEMENTATION)'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section, and the specifics of the implementation are marked in the code block with a 'TODO' statement. Please be sure to read the instructions carefully! \n",
    "\n",
    "> **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the Jupyter Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to **File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question X'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut.  Markdown cells can be edited by double-clicking the cell to enter edit mode.\n",
    "\n",
    "The rubric contains _optional_ \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. If you decide to pursue the \"Stand Out Suggestions\", you should include the code in this Jupyter notebook.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "### Why We're Here \n",
    "\n",
    "In this notebook, you will make the first steps towards developing an algorithm that could be used as part of a mobile or web app.  At the end of this project, your code will accept any user-supplied image as input.  If a dog is detected in the image, it will provide an estimate of the dog's breed.  If a human is detected, it will provide an estimate of the dog breed that is most resembling.  The image below displays potential sample output of your finished project (... but we expect that each student's algorithm will behave differently!). \n",
    "\n",
    "![Sample Dog Output](images/sample_dog_output.png)\n",
    "\n",
    "In this real-world setting, you will need to piece together a series of models to perform different tasks; for instance, the algorithm that detects humans in an image will be different from the CNN that infers dog breed.  There are many points of possible failure, and no perfect algorithm exists.  Your imperfect solution will nonetheless create a fun user experience!\n",
    "\n",
    "### The Road Ahead\n",
    "\n",
    "We break the notebook into separate steps.  Feel free to use the links below to navigate the notebook.\n",
    "\n",
    "* [Step 0](#step0): Import Datasets\n",
    "* [Step 1](#step1): Detect Humans\n",
    "* [Step 2](#step2): Detect Dogs\n",
    "* [Step 3](#step3): Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "* [Step 4](#step4): Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "* [Step 5](#step5): Write your Algorithm\n",
    "* [Step 6](#step6): Test Your Algorithm\n",
    "\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## Step 0: Import Datasets\n",
    "\n",
    "Make sure that you've downloaded the required human and dog datasets:\n",
    "* Download the [dog dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip).  Unzip the folder and place it in this project's home directory, at the location `/dog_images`. \n",
    "\n",
    "* Download the [human dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip).  Unzip the folder and place it in the home directory, at location `/lfw`.  \n",
    "\n",
    "*Note: If you are using a Windows machine, you are encouraged to use [7zip](http://www.7-zip.org/) to extract the folder.*\n",
    "\n",
    "In the code cell below, we save the file paths for both the human (LFW) dataset and dog dataset in the numpy arrays `human_files` and `dog_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13233 total human images.\n",
      "There are 8351 total dog images.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# load filenames for human and dog images\n",
    "human_files = np.array(glob(\"/data/lfw/*/*\"))\n",
    "dog_files = np.array(glob(\"/data/dog_images/*/*/*\"))\n",
    "\n",
    "# print number of images in each dataset\n",
    "print('There are %d total human images.' % len(human_files))\n",
    "print('There are %d total dog images.' % len(dog_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Detect Humans\n",
    "\n",
    "In this section, we use OpenCV's implementation of [Haar feature-based cascade classifiers](http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html) to detect human faces in images.  \n",
    "\n",
    "OpenCV provides many pre-trained face detectors, stored as XML files on [github](https://github.com/opencv/opencv/tree/master/data/haarcascades).  We have downloaded one of these detectors and stored it in the `haarcascades` directory.  In the next code cell, we demonstrate how to use this detector to find human faces in a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f90f1c2dd30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline                               \n",
    "\n",
    "# extract pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# load color (BGR) image\n",
    "img = cv2.imread(human_files[0])\n",
    "# convert BGR image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find faces in image\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "# print number of faces detected in the image\n",
    "print('Number of faces detected:', len(faces))\n",
    "\n",
    "# get bounding box for each detected face\n",
    "for (x,y,w,h) in faces:\n",
    "    # add bounding box to color image\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "# convert BGR image to RGB for plotting\n",
    "cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# display the image, along with bounding box\n",
    "plt.imshow(cv_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using any of the face detectors, it is standard procedure to convert the images to grayscale.  The `detectMultiScale` function executes the classifier stored in `face_cascade` and takes the grayscale image as a parameter.  \n",
    "\n",
    "In the above code, `faces` is a numpy array of detected faces, where each row corresponds to a detected face.  Each detected face is a 1D array with four entries that specifies the bounding box of the detected face.  The first two entries in the array (extracted in the above code as `x` and `y`) specify the horizontal and vertical positions of the top left corner of the bounding box.  The last two entries in the array (extracted here as `w` and `h`) specify the width and height of the box.\n",
    "\n",
    "### Write a Human Face Detector\n",
    "\n",
    "We can use this procedure to write a function that returns `True` if a human face is detected in an image and `False` otherwise.  This function, aptly named `face_detector`, takes a string-valued file path to an image as input and appears in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns \"True\" if face is detected in image stored at img_path\n",
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Assess the Human Face Detector\n",
    "\n",
    "__Question 1:__ Use the code cell below to test the performance of the `face_detector` function.  \n",
    "- What percentage of the first 100 images in `human_files` have a detected human face?  \n",
    "- What percentage of the first 100 images in `dog_files` have a detected human face? \n",
    "\n",
    "Ideally, we would like 100% of human images with a detected face and 0% of dog images with a detected face.  You will see that our algorithm falls short of this goal, but still gives acceptable performance.  We extract the file paths for the first 100 images from each of the datasets and store them in the numpy arrays `human_files_short` and `dog_files_short`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ \n",
    "(You can print out your results and/or write your percentages in this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face deteced in human set 98\n",
      "face deteced in dog set 17\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "human_files_short = human_files[:100]\n",
    "dog_files_short = dog_files[:100]\n",
    "\n",
    "#-#-# Do NOT modify the code above this line. #-#-#\n",
    "\n",
    "## TODO: Test the performance of the face_detector algorithm \n",
    "## on the images in human_files_short and dog_files_short.\n",
    "'''\n",
    "test_h = human_files_short[0]\n",
    "test_d = dog_files_short[0]\n",
    "\n",
    "img = cv2.imread(test_d)\n",
    "gray = `cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "faces is () #dog face returns empty tuple\n",
    "\n",
    "'''\n",
    "\n",
    "def detect():\n",
    "    '''\n",
    "    images = [] #debug feature\n",
    "    result = [] #debug feature\n",
    "    \n",
    "    for _ in dataset:\n",
    "        img = cv2.imread(_)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces =face_cascade.detectMultiScale(gray)        \n",
    "        \n",
    "        #if faces is ():\n",
    "        if len(faces)<=0:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            #debug\n",
    "            images.append(img)\n",
    "            \n",
    "            result.append(1)\n",
    "            \n",
    "    #return np.array(result).sum().mean()\n",
    "    return (images, result)\n",
    "    '''\n",
    "    count_human = 0\n",
    "    count_dog = 0\n",
    "    for pic in human_files_short:\n",
    "        if face_detector(pic) == True:\n",
    "            count_human +=1\n",
    "            \n",
    "    for pic in dog_files_short:\n",
    "        if face_detector(pic) == True:\n",
    "            count_dog +=1\n",
    "    return count_human, count_dog\n",
    "\n",
    "count_human, count_dog = detect()\n",
    "            \n",
    "print('face deteced in human set', count_human)\n",
    "print('face deteced in dog set', count_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef calc_percentage(result):\\n    return np.array(result).sum().mean()\\n\\ncalc_percentage(result)\\nhuman_images, human_result = detect(human_files_short)\\nimport pandas as pd\\nresult_df = pd.DataFrame(human_result)\\nresult_df[result_df[0] == 0]\\n# above result shows face detect algorithm failed to find human faces in index 56 and index 87\\n# let's take a look\\nimg56 = cv2.imread(human_files_short[56])\\nimg87 = cv2.imread(human_files_short[87])\\nplt.imshow(img56)\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#debug\n",
    "#images, result = detect(dog_files_short)\n",
    "#plt.imshow(images[1])\n",
    "#plt.imshow(images[6])\n",
    "'''\n",
    "def calc_percentage(result):\n",
    "    return np.array(result).sum().mean()\n",
    "\n",
    "calc_percentage(result)\n",
    "human_images, human_result = detect(human_files_short)\n",
    "import pandas as pd\n",
    "result_df = pd.DataFrame(human_result)\n",
    "result_df[result_df[0] == 0]\n",
    "# above result shows face detect algorithm failed to find human faces in index 56 and index 87\n",
    "# let's take a look\n",
    "img56 = cv2.imread(human_files_short[56])\n",
    "img87 = cv2.imread(human_files_short[87])\n",
    "plt.imshow(img56)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suggest the face detector from OpenCV as a potential way to detect human images in your algorithm, but you are free to explore other approaches, especially approaches that make use of deep learning :).  Please use the code cell below to design and test your own face detection algorithm.  If you decide to pursue this _optional_ task, report performance on `human_files_short` and `dog_files_short`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (Optional) \n",
    "### TODO: Test performance of anotherface detection algorithm.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "### SEE ANSWER BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY ANSWERS\n",
    "\n",
    "Face detect found human faces in 17% of dog_file_short. While a few did have human faces in it, there seems to be at least one breed that the Face detect mistakenly think as human.\n",
    "\n",
    "Face detect finds 98.2% in human_files_short. Where it fails is: image 56 and 87. It could be that image 56 has a unique angle of eyes and the face is not perfectly symmetric, and image 87 has sunglasses. Though for human brains, these are obviously faces, it's not clear why the algorithm fails on obvious cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick google search didn't immediately yield any obvious disadvantage or shortfall of cv2.CascadeClassifier.\n",
    "\n",
    "But I suspect there's something about the eyes being covered or looking unusual in both images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "## Step 2: Detect Dogs\n",
    "\n",
    "In this section, we use a [pre-trained model](http://pytorch.org/docs/master/torchvision/models.html) to detect dogs in images.  \n",
    "\n",
    "### Obtain Pre-trained VGG-16 Model\n",
    "\n",
    "The code cell below downloads the VGG-16 model, along with weights that have been trained on [ImageNet](http://www.image-net.org/), a very large, very popular dataset used for image classification and other vision tasks.  ImageNet contains over 10 million URLs, each linking to an image containing an object from one of [1000 categories](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# define VGG16 model\n",
    "VGG16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    VGG16 = VGG16.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an image, this pre-trained VGG-16 model returns a prediction (derived from the 1000 possible categories in ImageNet) for the object that is contained in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Making Predictions with a Pre-trained Model\n",
    "\n",
    "In the next code cell, you will write a function that accepts a path to an image (such as `'dogImages/train/001.Affenpinscher/Affenpinscher_00001.jpg'`) as input and returns the index corresponding to the ImageNet class that is predicted by the pre-trained VGG-16 model.  The output should always be an integer between 0 and 999, inclusive.\n",
    "\n",
    "Before writing the function, make sure that you take the time to learn  how to appropriately pre-process tensors for pre-trained models in the [PyTorch documentation](http://pytorch.org/docs/stable/torchvision/models.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 834], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "#import torchvision.models\n",
    "\n",
    "def data_loader():\n",
    "    pass\n",
    "\n",
    "def VGG16_predict(img_path):\n",
    "    '''\n",
    "    Use pre-trained VGG-16 model to obtain index corresponding to \n",
    "    predicted ImageNet class for image at specified path\n",
    "    \n",
    "    Args:\n",
    "        img_path: path to an image\n",
    "        \n",
    "    Returns:\n",
    "        Index corresponding to VGG-16 model's prediction\n",
    "    '''\n",
    "    \n",
    "    ## TODO: Complete the function.\n",
    "    ## Load and pre-process an image from the given img_path\n",
    "    ## Return the *index* of the predicted class for that image\n",
    "    #vgg16 = models.vgg16(pretrained=True)\n",
    "    #print(vgg16)\n",
    "    #output = vgg16(img_path)\n",
    "    \n",
    "    image = Image.open(img_path)\n",
    "    image = image.resize((224, 224), Image.ANTIALIAS) #huge difference without this line, this function is SUPER slow\n",
    "    \n",
    "    # debugging\n",
    "    # plt.imshow(image)\n",
    "    \n",
    "    image =  TF.to_tensor(image)\n",
    "    image.unsqueeze_(0)\n",
    "    if use_cuda:\n",
    "        image = image.cuda() \n",
    "    output = VGG16(image)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "VGG16_predict(human_files_short[3])\n",
    "#VGG16_predict(dog_files_short[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('features.0.weight', tensor([[[[-0.5537,  0.1427,  0.5290],\n",
       "                        [-0.5831,  0.3566,  0.7657],\n",
       "                        [-0.6902, -0.0480,  0.4841]],\n",
       "              \n",
       "                       [[ 0.1755,  0.0099, -0.0814],\n",
       "                        [ 0.0441, -0.0703, -0.2604],\n",
       "                        [ 0.1324, -0.1728, -0.1323]],\n",
       "              \n",
       "                       [[ 0.3130, -0.1659, -0.4275],\n",
       "                        [ 0.4752, -0.0827, -0.4870],\n",
       "                        [ 0.6320,  0.0193, -0.2775]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2325,  0.1267,  0.1861],\n",
       "                        [-0.4281, -0.2435,  0.2463],\n",
       "                        [-0.2507,  0.1418, -0.0055]],\n",
       "              \n",
       "                       [[-0.1408, -0.2190,  0.1504],\n",
       "                        [-0.8413, -0.3518,  0.5640],\n",
       "                        [-0.2419,  0.5193,  0.5391]],\n",
       "              \n",
       "                       [[-0.3143, -0.3705, -0.1309],\n",
       "                        [-0.4714, -0.1550,  0.3459],\n",
       "                        [ 0.0544,  0.5868,  0.4958]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1772,  0.5215,  0.0099],\n",
       "                        [-0.2718, -0.7171,  0.3129],\n",
       "                        [-0.0758, -0.2208,  0.3346]],\n",
       "              \n",
       "                       [[ 0.3092,  0.6707,  0.0205],\n",
       "                        [-0.4661, -1.0697,  0.3350],\n",
       "                        [-0.0803, -0.3052,  0.5446]],\n",
       "              \n",
       "                       [[ 0.3157,  0.4233, -0.3498],\n",
       "                        [ 0.0864, -0.4646,  0.0118],\n",
       "                        [ 0.1048, -0.1458, -0.0158]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0776,  0.1269,  0.0323],\n",
       "                        [ 0.2213,  0.2468, -0.0466],\n",
       "                        [ 0.0464,  0.0282,  0.0175]],\n",
       "              \n",
       "                       [[-0.1833, -0.0674, -0.0072],\n",
       "                        [-0.0489,  0.0070, -0.1288],\n",
       "                        [-0.0646, -0.0646,  0.0442]],\n",
       "              \n",
       "                       [[-0.2255, -0.1193, -0.0234],\n",
       "                        [-0.0992, -0.0151,  0.0010],\n",
       "                        [-0.0261,  0.0014,  0.1428]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0165, -0.0322, -0.0038],\n",
       "                        [-0.0682, -0.1944, -0.1417],\n",
       "                        [-0.0695, -0.1834, -0.1742]],\n",
       "              \n",
       "                       [[ 0.0428, -0.0675, -0.0070],\n",
       "                        [ 0.0118, -0.1496, -0.1236],\n",
       "                        [ 0.0102, -0.1039, -0.1174]],\n",
       "              \n",
       "                       [[ 0.1266,  0.0850,  0.1307],\n",
       "                        [ 0.1759,  0.1129,  0.1194],\n",
       "                        [ 0.1466,  0.0989,  0.1035]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0322, -0.1077, -0.2639],\n",
       "                        [ 0.2796, -0.0374, -0.2547],\n",
       "                        [ 0.3487,  0.0300, -0.0559]],\n",
       "              \n",
       "                       [[ 0.2506,  0.1554, -0.1743],\n",
       "                        [ 0.3925,  0.0323, -0.3519],\n",
       "                        [ 0.1930, -0.1990, -0.2971]],\n",
       "              \n",
       "                       [[ 0.4603,  0.4340,  0.2835],\n",
       "                        [ 0.1634, -0.0582, -0.1920],\n",
       "                        [-0.1952, -0.4563, -0.4273]]]], device='cuda:0')),\n",
       "             ('features.0.bias',\n",
       "              tensor([ 0.4034,  0.3778,  0.4644, -0.3228,  0.3940, -0.3953,  0.3951,\n",
       "                      -0.5496,  0.2693, -0.7602, -0.3508,  0.2334, -1.3239, -0.1694,\n",
       "                       0.3938, -0.1026,  0.0460, -0.6995,  0.1549,  0.5628,  0.3011,\n",
       "                       0.3425,  0.1073,  0.4651,  0.1295,  0.0788, -0.0492, -0.5638,\n",
       "                       0.1465, -0.3890, -0.0715,  0.0649,  0.2768,  0.3279,  0.5682,\n",
       "                      -1.2640, -0.8368, -0.9485,  0.1358,  0.2727,  0.1841, -0.5325,\n",
       "                       0.3507, -0.0827, -1.0248, -0.6912, -0.7711,  0.2612,  0.4033,\n",
       "                      -0.4802, -0.3066,  0.5807, -1.3325,  0.4844, -0.8160,  0.2386,\n",
       "                       0.2300,  0.4979,  0.5553,  0.5230, -0.2182,  0.0117, -0.5516,\n",
       "                       0.2108], device='cuda:0')),\n",
       "             ('features.2.weight',\n",
       "              tensor([[[[-3.0606e-02, -9.8520e-02, -1.3260e-01],\n",
       "                        [ 6.8208e-03, -8.3483e-02, -1.6697e-01],\n",
       "                        [ 3.1015e-02, -6.5803e-02, -1.3171e-01]],\n",
       "              \n",
       "                       [[ 4.7407e-02, -2.7588e-02, -5.1127e-02],\n",
       "                        [ 7.0129e-02,  8.2528e-03, -1.8340e-02],\n",
       "                        [ 6.9918e-02,  3.8993e-02,  1.6228e-02]],\n",
       "              \n",
       "                       [[ 7.0700e-02,  5.2703e-03, -4.7362e-02],\n",
       "                        [ 8.4006e-02,  4.9190e-02, -1.6474e-03],\n",
       "                        [ 8.5166e-03,  2.2350e-02,  5.9118e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.7666e-02,  2.1778e-02, -9.4606e-03],\n",
       "                        [ 2.5511e-02,  4.1186e-03, -3.4521e-02],\n",
       "                        [ 2.0150e-02,  3.7068e-02, -1.3509e-02]],\n",
       "              \n",
       "                       [[ 2.1684e-02,  4.1812e-02,  5.8284e-02],\n",
       "                        [ 2.7431e-02,  3.6847e-02,  3.4335e-02],\n",
       "                        [-9.4839e-03,  1.9745e-02,  5.0264e-02]],\n",
       "              \n",
       "                       [[ 2.1769e-02, -2.1388e-02, -9.9363e-02],\n",
       "                        [-5.7156e-02, -7.1328e-02, -7.7600e-02],\n",
       "                        [-3.7508e-02, -2.5453e-02, -4.5096e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3319e-02, -7.7979e-02, -1.3496e-01],\n",
       "                        [-3.7411e-02, -8.1807e-02, -1.4195e-01],\n",
       "                        [-4.1913e-02, -1.0756e-01, -1.6164e-01]],\n",
       "              \n",
       "                       [[-6.8725e-03,  4.8598e-02,  1.5008e-02],\n",
       "                        [ 1.8636e-02,  9.8393e-03, -1.5973e-02],\n",
       "                        [ 9.5164e-04, -3.2665e-02, -3.5824e-02]],\n",
       "              \n",
       "                       [[ 1.4780e-02, -1.4260e-02, -4.4468e-02],\n",
       "                        [-1.8438e-02,  1.4841e-02, -8.2337e-02],\n",
       "                        [ 1.8329e-02,  2.1435e-03,  9.0911e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.0342e-02,  3.6146e-02,  2.5515e-02],\n",
       "                        [ 1.5779e-02,  3.1012e-03, -1.0942e-02],\n",
       "                        [ 2.3790e-02,  1.6440e-02, -2.5835e-02]],\n",
       "              \n",
       "                       [[-2.2844e-02,  2.5371e-03, -2.1714e-02],\n",
       "                        [ 3.9534e-04, -6.4903e-03,  1.6979e-02],\n",
       "                        [-4.7200e-03, -2.2301e-02, -2.1298e-02]],\n",
       "              \n",
       "                       [[-2.8434e-02, -2.6771e-02,  2.7432e-02],\n",
       "                        [-5.8088e-02, -5.5869e-02,  7.0289e-02],\n",
       "                        [-6.4470e-02, -3.8172e-02,  4.1569e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2508e-02,  2.4738e-02,  5.3893e-02],\n",
       "                        [-2.5838e-02, -1.6176e-02,  2.8344e-02],\n",
       "                        [ 1.2948e-02,  9.0717e-03,  2.8181e-02]],\n",
       "              \n",
       "                       [[-7.9309e-02, -8.8828e-02, -5.5737e-02],\n",
       "                        [-4.8359e-02, -1.1139e-01, -1.0901e-02],\n",
       "                        [ 3.4640e-02,  2.3298e-02,  1.1002e-01]],\n",
       "              \n",
       "                       [[-4.3616e-02, -1.6598e-02, -1.0547e-02],\n",
       "                        [ 2.8982e-02,  4.5279e-02,  1.6869e-02],\n",
       "                        [ 8.8168e-02,  1.2599e-01,  7.2292e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.3967e-03,  1.5333e-02, -1.7196e-02],\n",
       "                        [-8.3107e-03, -1.2905e-02, -1.4394e-03],\n",
       "                        [ 6.3471e-03,  1.7825e-03, -3.3770e-02]],\n",
       "              \n",
       "                       [[-7.9354e-03, -5.8610e-03, -7.6292e-05],\n",
       "                        [ 6.8661e-04, -6.0019e-03,  1.0119e-02],\n",
       "                        [ 3.0581e-02,  1.6821e-02,  3.2570e-02]],\n",
       "              \n",
       "                       [[ 5.9351e-02, -7.4398e-03,  3.8274e-02],\n",
       "                        [-2.0792e-02, -4.8833e-02,  4.0274e-02],\n",
       "                        [ 2.3138e-02,  7.4794e-03,  3.5027e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-4.5464e-02, -2.9275e-02,  1.0282e-02],\n",
       "                        [-4.6952e-02, -4.9473e-02,  1.7632e-02],\n",
       "                        [-4.3815e-02, -2.4871e-02, -2.4908e-02]],\n",
       "              \n",
       "                       [[-1.9359e-02,  1.5948e-02, -6.3554e-02],\n",
       "                        [ 3.0096e-02,  2.8515e-02, -6.4439e-02],\n",
       "                        [-1.4547e-02,  2.2238e-03, -6.3371e-02]],\n",
       "              \n",
       "                       [[-2.7915e-02, -2.1738e-02, -5.1691e-02],\n",
       "                        [ 1.0889e-02, -5.1994e-02, -5.4649e-02],\n",
       "                        [-3.9741e-02,  5.2832e-04,  3.5375e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.9130e-03,  1.0995e-03, -7.4082e-03],\n",
       "                        [ 1.8428e-03,  8.2602e-03,  1.8680e-02],\n",
       "                        [ 1.1709e-02,  6.9263e-03,  3.3630e-02]],\n",
       "              \n",
       "                       [[ 8.9195e-03,  3.2807e-02,  3.9282e-02],\n",
       "                        [-2.5044e-03,  1.7645e-03,  1.4056e-02],\n",
       "                        [-5.4708e-03,  9.5572e-03,  2.8639e-02]],\n",
       "              \n",
       "                       [[-3.0241e-02, -6.7225e-02, -7.4299e-02],\n",
       "                        [-3.6222e-02, -9.7721e-03,  6.1669e-02],\n",
       "                        [-1.6392e-02,  5.8156e-02,  1.2894e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.0321e-02,  3.7677e-02,  1.7181e-02],\n",
       "                        [ 4.0298e-02,  2.9479e-02,  1.6698e-02],\n",
       "                        [-4.8739e-03,  2.1128e-02, -2.6295e-03]],\n",
       "              \n",
       "                       [[ 3.1079e-02, -1.6475e-02,  1.0769e-02],\n",
       "                        [-5.8626e-02, -4.6721e-02, -2.7764e-02],\n",
       "                        [-3.1245e-02,  1.7635e-02, -1.2211e-02]],\n",
       "              \n",
       "                       [[-9.8675e-02, -9.8915e-02, -1.3225e-01],\n",
       "                        [ 7.3214e-02, -7.5238e-03, -7.4033e-02],\n",
       "                        [ 1.7070e-01,  1.8346e-01,  3.3906e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.5318e-02,  3.2680e-02,  5.2874e-03],\n",
       "                        [-4.1894e-03,  2.0011e-02,  1.6021e-02],\n",
       "                        [-4.8276e-03, -2.9130e-02,  7.4975e-04]],\n",
       "              \n",
       "                       [[ 7.1959e-03, -5.1528e-03,  5.1333e-03],\n",
       "                        [-8.6466e-04,  1.2417e-02,  2.0805e-02],\n",
       "                        [ 2.4862e-03, -1.3194e-02,  3.6563e-03]],\n",
       "              \n",
       "                       [[ 3.2415e-02,  1.0823e-02,  3.1720e-02],\n",
       "                        [-8.4911e-03,  5.9831e-02,  3.4606e-02],\n",
       "                        [-2.0674e-02,  1.6525e-02, -1.3183e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.6955e-02,  1.0821e-02,  7.9260e-02],\n",
       "                        [ 1.0361e-02, -3.3380e-02,  5.2775e-02],\n",
       "                        [-3.8372e-02, -3.0964e-02,  6.5422e-02]],\n",
       "              \n",
       "                       [[ 5.4925e-02, -1.9160e-01,  9.9709e-02],\n",
       "                        [-1.8754e-01,  1.3248e-02,  2.4748e-01],\n",
       "                        [-5.6662e-03,  2.8737e-02, -8.9787e-02]],\n",
       "              \n",
       "                       [[-1.4905e-01, -1.2974e-01,  1.7649e-01],\n",
       "                        [-1.5774e-01,  1.5130e-01,  8.4126e-02],\n",
       "                        [ 9.4988e-02,  8.5186e-02, -3.3635e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.2278e-02,  3.3348e-02, -1.0524e-02],\n",
       "                        [ 5.0310e-02, -9.1280e-03, -3.3890e-02],\n",
       "                        [ 1.3459e-02, -2.9601e-02,  2.6862e-02]],\n",
       "              \n",
       "                       [[ 3.1006e-02,  2.8481e-02,  5.2361e-03],\n",
       "                        [ 3.8914e-03, -1.8899e-02, -2.1819e-02],\n",
       "                        [-8.4505e-03, -3.6632e-02, -1.9476e-02]],\n",
       "              \n",
       "                       [[ 2.3835e-02,  4.5658e-02,  6.7297e-02],\n",
       "                        [ 1.1103e-02,  3.2035e-02, -5.8449e-02],\n",
       "                        [ 2.6805e-02, -9.3975e-02, -4.0504e-02]]]], device='cuda:0')),\n",
       "             ('features.2.bias',\n",
       "              tensor([ 0.0020, -0.0902,  0.6164, -0.0818,  0.2450, -0.0488,  0.1307,\n",
       "                      -0.0290, -0.1429,  0.3068, -0.0399, -0.2524,  0.0999, -0.2326,\n",
       "                       0.0353, -0.0904,  0.1138, -0.0307, -0.0108, -0.0215,  0.0554,\n",
       "                       0.1382,  0.0362, -0.4511,  0.0056, -0.0246, -0.4296, -0.1458,\n",
       "                       0.3813, -0.0359,  0.1184, -0.3527, -0.0239, -0.0235,  0.6499,\n",
       "                      -0.0634, -0.0152, -0.2285,  0.0941, -0.5053,  0.1906,  0.0944,\n",
       "                       0.3406, -0.0833,  0.1924, -0.1953, -0.0421, -0.1606,  0.3964,\n",
       "                       0.2068,  0.1812, -0.1198, -0.0724, -0.1240,  0.1313,  0.1043,\n",
       "                       0.5469,  0.5208,  0.0509, -0.8278,  0.4372, -0.3734, -0.3264,\n",
       "                      -0.1213], device='cuda:0')),\n",
       "             ('features.5.weight',\n",
       "              tensor([[[[-6.2810e-02,  1.1339e-02, -4.0391e-02],\n",
       "                        [-5.1637e-02, -5.7086e-02, -1.2647e-01],\n",
       "                        [-1.3824e-02, -5.4079e-02, -8.2741e-02]],\n",
       "              \n",
       "                       [[-5.1361e-02, -3.3589e-02, -3.0128e-02],\n",
       "                        [-3.1981e-02, -3.5140e-02,  2.4252e-03],\n",
       "                        [-4.1960e-03, -1.4064e-02,  1.3642e-02]],\n",
       "              \n",
       "                       [[-2.8838e-02,  5.2136e-02,  5.1848e-02],\n",
       "                        [-3.7392e-02,  1.4356e-01, -3.5255e-02],\n",
       "                        [-2.9268e-02,  2.1488e-02, -3.1739e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3000e-02, -1.1137e-02, -4.2528e-03],\n",
       "                        [-1.9321e-02, -4.3134e-02, -5.5873e-04],\n",
       "                        [-4.2867e-02, -1.4233e-02, -1.3526e-02]],\n",
       "              \n",
       "                       [[-2.7698e-02, -1.6312e-02, -2.3137e-02],\n",
       "                        [ 2.7924e-02,  3.4780e-02, -4.5055e-02],\n",
       "                        [ 4.9343e-02,  1.1931e-02, -3.7526e-03]],\n",
       "              \n",
       "                       [[ 1.4084e-02,  1.7446e-02, -8.3521e-03],\n",
       "                        [ 6.4733e-03,  7.4886e-02, -5.2302e-03],\n",
       "                        [-3.3729e-02,  5.7670e-02, -1.1322e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.6400e-04, -3.0072e-02, -2.5162e-02],\n",
       "                        [-1.5606e-02, -3.7128e-02, -4.2133e-02],\n",
       "                        [-4.9897e-03, -2.8128e-03, -4.8388e-02]],\n",
       "              \n",
       "                       [[-2.1050e-02, -1.2844e-02,  2.3434e-03],\n",
       "                        [-3.1928e-02, -3.5125e-02,  1.3496e-02],\n",
       "                        [ 1.2840e-02, -2.1722e-03,  1.9916e-02]],\n",
       "              \n",
       "                       [[-5.4853e-02, -1.4703e-02,  5.7742e-02],\n",
       "                        [-1.4970e-01,  9.0838e-02,  1.8018e-01],\n",
       "                        [-5.1293e-02,  4.0009e-03,  7.5791e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.3281e-02, -2.7738e-02, -4.9568e-02],\n",
       "                        [ 2.3973e-02, -2.3895e-02, -6.5836e-03],\n",
       "                        [ 5.9873e-02,  2.1132e-02, -1.5224e-02]],\n",
       "              \n",
       "                       [[-5.2145e-02, -2.6414e-02, -2.5841e-02],\n",
       "                        [-3.0816e-02, -5.0158e-02,  3.9022e-02],\n",
       "                        [ 4.1870e-02, -2.2169e-02, -3.2523e-02]],\n",
       "              \n",
       "                       [[-2.4134e-03,  3.2657e-03,  2.7356e-02],\n",
       "                        [-4.2036e-02,  7.5291e-03, -1.1726e-02],\n",
       "                        [ 4.0441e-02,  1.2264e-01, -4.8728e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3180e-02, -2.2260e-02, -3.3540e-03],\n",
       "                        [ 1.4570e-02,  7.5933e-02, -5.2729e-02],\n",
       "                        [-4.9156e-02,  3.9846e-02,  8.7439e-04]],\n",
       "              \n",
       "                       [[ 1.5670e-02,  5.4018e-03,  4.5666e-02],\n",
       "                        [-6.3589e-03,  4.6707e-02,  4.5305e-02],\n",
       "                        [-7.1617e-02,  3.8063e-02,  1.4691e-02]],\n",
       "              \n",
       "                       [[-4.5694e-02,  3.2703e-02,  1.1262e-02],\n",
       "                        [-4.9579e-02,  2.9527e-02, -2.7634e-02],\n",
       "                        [ 1.1622e-02,  5.6397e-02, -2.6861e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.1792e-02, -2.6591e-02, -2.0085e-04],\n",
       "                        [-6.0890e-02, -5.5885e-02, -3.8149e-02],\n",
       "                        [ 3.8406e-02, -9.7790e-03, -1.4222e-03]],\n",
       "              \n",
       "                       [[-4.4498e-02, -2.2446e-02, -6.2459e-02],\n",
       "                        [-2.5728e-02,  1.1222e-02, -2.5034e-02],\n",
       "                        [ 1.9746e-02, -4.1720e-02, -3.2745e-02]],\n",
       "              \n",
       "                       [[ 2.3275e-02, -5.6597e-04,  1.7023e-02],\n",
       "                        [-3.7929e-02,  8.4074e-02,  1.5500e-02],\n",
       "                        [ 8.4187e-03, -5.3071e-02, -1.9120e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 6.8440e-03, -9.4784e-03, -1.9466e-02],\n",
       "                        [-1.7608e-02,  4.3330e-02, -4.1369e-02],\n",
       "                        [-2.6391e-02, -2.8507e-02, -9.8986e-04]],\n",
       "              \n",
       "                       [[-6.2622e-02, -4.5775e-02,  1.0037e-02],\n",
       "                        [-3.5123e-02, -5.3560e-02,  2.6610e-02],\n",
       "                        [ 7.1417e-03, -1.4646e-02,  6.5733e-03]],\n",
       "              \n",
       "                       [[ 1.5414e-02,  2.7492e-01,  2.1435e-01],\n",
       "                        [-9.2970e-02, -1.7520e-02,  6.8770e-02],\n",
       "                        [-1.4798e-01, -1.1129e-01, -7.8531e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.9160e-03,  5.5912e-02,  8.1550e-03],\n",
       "                        [-8.3287e-03, -3.8522e-02, -4.4384e-02],\n",
       "                        [ 3.0769e-02,  5.2761e-02, -3.3069e-03]],\n",
       "              \n",
       "                       [[ 4.4858e-03,  1.0840e-01, -9.7890e-03],\n",
       "                        [-3.9745e-02, -1.3879e-01,  1.2488e-02],\n",
       "                        [-4.7321e-02, -2.9251e-02, -2.4057e-02]],\n",
       "              \n",
       "                       [[-9.8491e-02,  7.1428e-03, -3.5822e-02],\n",
       "                        [-3.7229e-02,  1.6014e-01, -2.8598e-02],\n",
       "                        [-1.4895e-02,  7.6893e-02,  7.7165e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.3394e-02,  4.9751e-02,  2.0830e-02],\n",
       "                        [ 1.6439e-02,  1.7401e-02, -2.3603e-02],\n",
       "                        [-2.3165e-02, -9.2761e-02, -2.4903e-02]],\n",
       "              \n",
       "                       [[-4.5251e-02, -2.4458e-02,  9.8124e-03],\n",
       "                        [-8.4512e-03, -2.0820e-02,  2.8578e-02],\n",
       "                        [ 4.5104e-02,  1.2810e-03,  2.3833e-02]],\n",
       "              \n",
       "                       [[ 8.3300e-02,  6.6573e-02,  3.1433e-02],\n",
       "                        [-1.1266e-01,  9.9167e-02,  1.6835e-01],\n",
       "                        [-3.5607e-02, -4.2154e-02,  5.0973e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.1448e-02,  3.5827e-02,  5.3240e-02],\n",
       "                        [-4.3761e-02, -2.4301e-02,  2.9110e-02],\n",
       "                        [-3.8008e-04,  3.3345e-02,  5.7502e-03]],\n",
       "              \n",
       "                       [[ 2.8796e-04,  6.5530e-03, -6.0024e-02],\n",
       "                        [-4.6629e-02, -1.9900e-02,  9.3691e-03],\n",
       "                        [ 7.9185e-02,  6.4821e-02,  1.0142e-02]],\n",
       "              \n",
       "                       [[ 7.4917e-02,  4.8451e-02,  1.5926e-01],\n",
       "                        [-4.0570e-02, -1.6576e-01,  3.1683e-02],\n",
       "                        [-5.5403e-02, -1.4255e-02,  2.3551e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4041e-02, -9.3939e-03,  3.3714e-02],\n",
       "                        [ 6.1786e-02, -7.3343e-02, -4.9163e-02],\n",
       "                        [ 7.0314e-02,  7.0862e-02, -3.5670e-02]],\n",
       "              \n",
       "                       [[-6.0474e-03,  2.3996e-03,  2.4723e-02],\n",
       "                        [ 1.1873e-02, -1.4914e-02,  2.6962e-02],\n",
       "                        [-9.5375e-03, -2.8718e-02, -1.2086e-02]],\n",
       "              \n",
       "                       [[-1.0172e-01, -2.3414e-01, -5.6336e-02],\n",
       "                        [ 7.5019e-02,  1.3930e-03, -6.2536e-02],\n",
       "                        [ 1.4913e-01,  2.4970e-01,  1.4187e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.7739e-03, -4.8837e-02, -3.6353e-03],\n",
       "                        [ 1.8116e-02, -3.6125e-02,  6.8408e-03],\n",
       "                        [ 3.9892e-02,  4.8252e-04,  1.6367e-02]],\n",
       "              \n",
       "                       [[-6.7317e-02, -1.9475e-01, -9.3308e-02],\n",
       "                        [ 1.3558e-01,  7.9305e-02, -9.1780e-02],\n",
       "                        [ 1.0593e-02,  3.3229e-02,  2.0905e-02]],\n",
       "              \n",
       "                       [[ 7.5557e-02, -2.7272e-02,  1.5518e-02],\n",
       "                        [-6.9644e-03, -1.0359e-01,  4.6841e-02],\n",
       "                        [ 3.0022e-02, -5.4782e-02,  5.3461e-02]]]], device='cuda:0')),\n",
       "             ('features.5.bias',\n",
       "              tensor([ 0.0866, -0.0181,  0.1342,  0.0217,  0.0626, -0.0747,  0.0331,\n",
       "                       0.0904,  0.1834,  0.0745,  0.0599, -0.0143,  0.1710,  0.0063,\n",
       "                       0.0350,  0.1791, -0.0589,  0.1270,  0.1791,  0.2375,  0.0187,\n",
       "                      -0.0289,  0.1874,  0.0398,  0.1465,  0.0219,  0.1050,  0.1421,\n",
       "                      -0.0710, -0.0183,  0.0890,  0.0571,  0.1389,  0.2082,  0.1077,\n",
       "                       0.0854,  0.0171,  0.2711,  0.0871,  0.0594,  0.3166, -0.0526,\n",
       "                       0.1508,  0.0641,  0.1760,  0.1703, -0.0646,  0.1362,  0.0167,\n",
       "                      -0.0678,  0.0631,  0.1492,  0.1051,  0.0478,  0.2765,  0.0723,\n",
       "                      -0.1261,  0.1634, -0.0645, -0.0079,  0.1438,  0.1614,  0.0255,\n",
       "                       0.1175, -0.0888,  0.2224,  0.0558,  0.0144,  0.1645, -0.1988,\n",
       "                       0.0002,  0.0229, -0.1726,  0.0812,  0.0380, -0.1106,  0.0684,\n",
       "                       0.0533,  0.0056,  0.0683, -0.2563,  0.0812, -0.0692,  0.0545,\n",
       "                      -0.0599,  0.1202, -0.1720,  0.0710,  0.0310, -0.0808,  0.0513,\n",
       "                      -0.2062,  0.1945, -0.0890, -0.0861,  0.1709,  0.1631,  0.2255,\n",
       "                       0.1363, -0.0290, -0.0853, -0.0016,  0.0128, -0.0764, -0.0235,\n",
       "                       0.0330,  0.1655, -0.0215, -0.0101,  0.1256,  0.2002,  0.1658,\n",
       "                       0.0250,  0.0905,  0.1588, -0.1416,  0.0882,  0.0490, -0.0779,\n",
       "                       0.1304,  0.0825,  0.2060,  0.0749, -0.0097, -0.0108,  0.0744,\n",
       "                       0.0742,  0.1448], device='cuda:0')),\n",
       "             ('features.7.weight',\n",
       "              tensor([[[[ 2.5788e-02, -1.9852e-02, -1.0697e-02],\n",
       "                        [-1.6114e-02, -4.1759e-03,  8.4582e-03],\n",
       "                        [ 4.0309e-03,  1.8973e-02,  3.8059e-02]],\n",
       "              \n",
       "                       [[-5.4261e-02, -2.9872e-02,  1.1506e-02],\n",
       "                        [-1.8266e-02, -1.5708e-02, -1.2726e-02],\n",
       "                        [ 2.0867e-02, -5.6425e-03, -5.1218e-04]],\n",
       "              \n",
       "                       [[ 1.8961e-02, -2.3766e-03,  6.1427e-03],\n",
       "                        [-5.1761e-02, -1.7272e-02,  8.7075e-03],\n",
       "                        [-4.4383e-02,  2.3661e-02,  9.0710e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.8603e-02, -2.2412e-02,  1.4266e-03],\n",
       "                        [-1.0810e-02, -1.2563e-02,  5.8555e-02],\n",
       "                        [-1.9603e-02,  3.8292e-02,  6.6033e-02]],\n",
       "              \n",
       "                       [[ 8.0053e-02,  4.5974e-02,  4.2854e-02],\n",
       "                        [ 3.4144e-02,  4.1228e-02,  8.4107e-03],\n",
       "                        [-8.5212e-02, -7.2149e-02, -6.1367e-02]],\n",
       "              \n",
       "                       [[-5.1872e-02, -1.7269e-02,  8.3412e-03],\n",
       "                        [-1.5657e-02,  6.5357e-03,  5.3442e-03],\n",
       "                        [ 7.0546e-02,  6.6640e-02,  2.9743e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4477e-02,  1.7372e-02,  3.8637e-02],\n",
       "                        [ 1.7122e-02,  6.5499e-03,  3.3277e-02],\n",
       "                        [ 5.1735e-02,  5.2232e-02,  2.2086e-02]],\n",
       "              \n",
       "                       [[-4.9817e-03,  7.8477e-03,  1.0481e-03],\n",
       "                        [-5.5254e-03,  1.1731e-03, -2.8846e-02],\n",
       "                        [-1.5166e-02,  1.4712e-02, -2.5996e-02]],\n",
       "              \n",
       "                       [[ 1.4313e-02,  7.7863e-03, -2.5710e-02],\n",
       "                        [ 3.6445e-02,  3.8037e-02,  2.1568e-02],\n",
       "                        [ 3.9633e-02,  4.1395e-02, -2.7349e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.9668e-02, -1.8495e-02, -4.5170e-03],\n",
       "                        [ 1.0013e-02,  8.0232e-03, -4.4554e-02],\n",
       "                        [ 2.3961e-02, -2.2513e-02,  3.8967e-03]],\n",
       "              \n",
       "                       [[-9.3318e-03, -2.7975e-03, -4.5400e-03],\n",
       "                        [ 1.9306e-03, -3.1315e-02,  6.2495e-03],\n",
       "                        [ 8.4360e-03, -3.6533e-02,  3.6175e-03]],\n",
       "              \n",
       "                       [[-3.0665e-02, -4.4897e-02, -7.7372e-02],\n",
       "                        [-3.9120e-02, -6.0861e-02, -8.4005e-02],\n",
       "                        [ 5.7575e-02, -4.9973e-04, -1.2297e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.7533e-02,  6.1958e-02, -1.5773e-02],\n",
       "                        [-4.7994e-02, -5.2918e-02, -5.5357e-02],\n",
       "                        [-9.8468e-04, -2.2081e-02,  8.1542e-03]],\n",
       "              \n",
       "                       [[ 2.1069e-02, -3.1143e-02, -2.8263e-02],\n",
       "                        [-5.5108e-02, -1.2559e-01, -8.1983e-02],\n",
       "                        [ 2.1143e-02, -3.4396e-02, -1.1907e-02]],\n",
       "              \n",
       "                       [[-9.8582e-03, -5.1275e-03,  1.4424e-03],\n",
       "                        [ 5.5997e-02,  1.3562e-01,  1.9257e-02],\n",
       "                        [-6.5687e-02, -1.8309e-02, -3.9470e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.8227e-02,  4.5086e-02, -3.0288e-02],\n",
       "                        [-1.6840e-02, -2.2179e-03, -3.2186e-02],\n",
       "                        [-4.6969e-02, -8.1806e-02,  7.7194e-02]],\n",
       "              \n",
       "                       [[-7.4163e-02, -4.7645e-02,  5.8225e-02],\n",
       "                        [-7.1075e-02,  1.0040e-02,  6.5806e-02],\n",
       "                        [-3.9398e-03, -9.7729e-03,  9.5199e-02]],\n",
       "              \n",
       "                       [[-4.3413e-02,  2.7101e-02, -1.2636e-02],\n",
       "                        [ 3.7488e-03,  4.2913e-03,  3.0900e-03],\n",
       "                        [ 3.3433e-02,  3.0384e-02,  5.1019e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5468e-02,  5.1462e-02,  2.2881e-02],\n",
       "                        [ 5.7329e-02,  1.7325e-02, -1.2769e-02],\n",
       "                        [ 3.1118e-02, -3.9026e-02, -6.2358e-02]],\n",
       "              \n",
       "                       [[-7.0737e-02, -4.5867e-02, -1.8765e-02],\n",
       "                        [-6.7420e-03, -1.0010e-02, -6.2032e-02],\n",
       "                        [ 6.2941e-03, -1.3777e-02, -5.5997e-02]],\n",
       "              \n",
       "                       [[-1.2475e-02,  2.6069e-02, -4.5512e-03],\n",
       "                        [ 4.8936e-02, -7.6861e-03, -1.0415e-01],\n",
       "                        [ 1.1287e-02, -4.4848e-02, -8.4382e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.0006e-02,  5.7238e-02, -3.4275e-03],\n",
       "                        [ 4.7454e-02,  4.8209e-03, -8.8796e-02],\n",
       "                        [ 6.8828e-02, -3.6591e-02, -8.3883e-02]],\n",
       "              \n",
       "                       [[-8.6139e-02, -4.4840e-02, -5.2773e-02],\n",
       "                        [-3.1619e-02,  8.5002e-04,  2.5091e-02],\n",
       "                        [ 4.1867e-03,  2.5540e-02,  5.2885e-02]],\n",
       "              \n",
       "                       [[-2.6334e-02, -8.2095e-02, -4.9413e-02],\n",
       "                        [-1.4520e-02, -6.7272e-02, -4.8400e-02],\n",
       "                        [-3.4450e-02, -5.3121e-02,  1.4509e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1221e-02, -2.6395e-02, -6.8177e-02],\n",
       "                        [-1.3308e-02, -2.4194e-02, -2.1912e-02],\n",
       "                        [-1.8293e-02, -1.8923e-02, -1.0353e-02]],\n",
       "              \n",
       "                       [[-2.7944e-02, -2.5907e-02, -1.5582e-02],\n",
       "                        [-4.8443e-02, -6.0070e-03,  1.2176e-04],\n",
       "                        [-3.3587e-02, -2.2929e-02, -3.5778e-03]],\n",
       "              \n",
       "                       [[-5.3952e-02, -5.4047e-02, -2.1393e-02],\n",
       "                        [-2.5399e-02, -4.8201e-03,  1.2715e-02],\n",
       "                        [-3.3006e-02, -9.2941e-03,  4.0095e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0834e-01,  3.6012e-02, -1.4283e-02],\n",
       "                        [ 6.2926e-02,  9.6225e-03, -1.5355e-02],\n",
       "                        [ 3.4179e-02, -2.8131e-03, -3.6031e-02]],\n",
       "              \n",
       "                       [[-6.5453e-02, -4.3534e-02, -1.2491e-02],\n",
       "                        [-6.4196e-02, -5.0347e-02, -1.9350e-02],\n",
       "                        [-2.0023e-02,  6.0370e-04,  1.2963e-03]],\n",
       "              \n",
       "                       [[-1.2661e-02, -8.3580e-03,  5.1847e-03],\n",
       "                        [ 4.2209e-03, -1.9068e-02,  1.4444e-02],\n",
       "                        [ 4.2795e-03,  7.2975e-03,  1.5227e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.0003e-03,  1.0324e-02, -7.5080e-03],\n",
       "                        [-4.3927e-04,  4.9710e-03,  2.4126e-02],\n",
       "                        [ 4.4565e-03,  3.8436e-02,  6.3350e-03]],\n",
       "              \n",
       "                       [[-1.2821e-02,  1.2153e-02,  1.8981e-02],\n",
       "                        [-9.3514e-03,  1.8435e-02, -1.3223e-02],\n",
       "                        [-5.3401e-04,  1.0125e-02, -6.2764e-03]],\n",
       "              \n",
       "                       [[-3.9147e-05,  2.6507e-02, -2.3274e-02],\n",
       "                        [-3.3350e-02,  3.1395e-02, -3.3022e-02],\n",
       "                        [-2.0826e-02,  2.2062e-03, -4.0605e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3357e-02,  1.3738e-02, -3.0007e-02],\n",
       "                        [-4.8696e-03,  3.5501e-02, -3.0733e-02],\n",
       "                        [-3.6084e-02, -4.8515e-03, -2.5580e-02]],\n",
       "              \n",
       "                       [[ 4.5643e-02, -8.4773e-03, -1.2161e-02],\n",
       "                        [ 2.9042e-02,  1.0096e-02,  2.8676e-02],\n",
       "                        [-1.9727e-02, -2.3097e-02,  1.5411e-03]],\n",
       "              \n",
       "                       [[ 4.5912e-02,  5.1751e-02, -1.0848e-02],\n",
       "                        [-6.4884e-03, -2.1099e-02, -1.6500e-02],\n",
       "                        [-7.0777e-03, -5.5341e-03,  1.7106e-02]]]], device='cuda:0')),\n",
       "             ('features.7.bias',\n",
       "              tensor([-0.0262,  0.3756, -0.1096, -0.1291, -0.0331, -0.1777,  0.2666,\n",
       "                      -0.0003,  0.1015, -0.1363, -0.1349, -0.0823, -0.0387, -0.0135,\n",
       "                       0.1480,  0.1459,  0.1221, -0.2619, -0.0039,  0.2607, -0.1341,\n",
       "                       0.0811,  0.0467,  0.0884,  0.9218,  0.1764,  0.2663, -0.0249,\n",
       "                       0.1491,  0.0536,  0.0603,  0.1167, -0.1255,  0.1778, -0.0381,\n",
       "                      -0.0706, -0.0163, -0.0089, -0.2624,  0.1835, -0.0247, -0.0160,\n",
       "                       0.0412, -0.1339,  0.0446, -0.2691, -0.0562,  0.0350, -0.0410,\n",
       "                      -0.0080, -0.0945,  0.1180, -0.2116,  0.2552,  0.0831, -0.0848,\n",
       "                       0.0002,  0.0327,  0.0193, -0.0830,  0.1235,  0.1245,  0.0425,\n",
       "                       0.1983,  0.0359,  0.0332, -0.0151,  0.0175, -0.0557,  0.0186,\n",
       "                       0.0987,  0.0059, -0.0742,  0.0835,  0.1180,  0.2276,  0.2639,\n",
       "                       0.0189,  0.0071,  0.0244, -0.0381,  0.1186, -0.0258, -0.1649,\n",
       "                      -0.0600,  0.1583, -0.0181,  0.0171, -0.0768, -0.1140, -0.0110,\n",
       "                       0.0154, -0.1781,  0.0242, -0.0618,  0.0583, -0.0226, -0.0044,\n",
       "                      -0.2152,  0.3571,  0.0704,  0.0898, -0.1222,  0.0284,  0.2813,\n",
       "                       0.0321, -0.0241,  0.0980,  0.1928,  0.0488,  0.1869, -0.3095,\n",
       "                       0.0442,  0.2661, -0.0601, -0.1004, -0.2336,  0.0603, -0.0573,\n",
       "                       0.0403, -0.1885, -0.1059,  0.2728,  0.1737,  0.2609, -0.0351,\n",
       "                       0.0635,  0.2141], device='cuda:0')),\n",
       "             ('features.10.weight',\n",
       "              tensor([[[[-1.1008e-02,  5.2181e-04,  2.0165e-02],\n",
       "                        [-1.9239e-02, -3.1387e-02, -9.3394e-03],\n",
       "                        [-5.2665e-02, -5.4552e-02, -6.9972e-03]],\n",
       "              \n",
       "                       [[ 2.0017e-02,  1.7184e-02,  2.1192e-02],\n",
       "                        [ 8.5676e-03,  1.1236e-02,  2.0709e-02],\n",
       "                        [ 6.6602e-03, -2.2648e-02,  1.2209e-02]],\n",
       "              \n",
       "                       [[ 4.9262e-02,  1.0558e-02, -2.9823e-03],\n",
       "                        [-8.8304e-04,  1.2206e-02,  2.0749e-03],\n",
       "                        [ 2.7586e-02,  7.7105e-05,  2.1245e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0546e-02,  2.1967e-02,  2.3511e-02],\n",
       "                        [-6.7902e-02, -8.1078e-03,  2.6165e-02],\n",
       "                        [-1.0581e-01, -6.6538e-02,  2.7534e-03]],\n",
       "              \n",
       "                       [[ 3.6559e-02,  3.6259e-02,  4.6347e-02],\n",
       "                        [-9.3869e-03,  7.9205e-03,  3.2348e-02],\n",
       "                        [-3.5539e-02, -1.5318e-02,  1.1864e-03]],\n",
       "              \n",
       "                       [[-2.1000e-02,  5.7321e-03, -8.2030e-03],\n",
       "                        [-1.8231e-02,  1.2254e-02,  1.4853e-02],\n",
       "                        [-3.0732e-02, -5.5477e-03, -2.5914e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1417e-02, -2.8491e-02, -3.2380e-02],\n",
       "                        [ 2.3106e-03, -1.5136e-02, -2.7720e-02],\n",
       "                        [-4.1440e-02, -3.7288e-02, -1.8089e-02]],\n",
       "              \n",
       "                       [[ 3.9357e-03, -6.3219e-03,  6.6615e-03],\n",
       "                        [ 2.0829e-02,  1.1740e-02, -2.5786e-03],\n",
       "                        [ 2.2405e-02,  1.2657e-02, -1.9856e-02]],\n",
       "              \n",
       "                       [[ 5.5530e-02,  7.8947e-02,  7.7657e-02],\n",
       "                        [ 9.1851e-02,  3.1986e-01,  1.6033e-01],\n",
       "                        [ 7.9647e-02,  2.1483e-01,  1.2694e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.3931e-03, -3.2048e-02, -2.0430e-02],\n",
       "                        [-2.4674e-02, -4.8157e-02, -5.4472e-02],\n",
       "                        [-3.8650e-02, -5.1003e-02, -2.0275e-02]],\n",
       "              \n",
       "                       [[ 4.0564e-02,  1.2618e-02,  9.2595e-03],\n",
       "                        [ 2.6360e-02, -1.4243e-02, -1.0471e-02],\n",
       "                        [-7.4169e-03, -2.0603e-02, -2.5345e-02]],\n",
       "              \n",
       "                       [[ 1.3168e-04,  5.7046e-03, -2.1024e-04],\n",
       "                        [ 4.6556e-02,  7.7847e-03,  1.2681e-02],\n",
       "                        [ 6.8144e-04, -1.5033e-02, -1.1644e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0750e-02, -3.4188e-02, -2.8340e-03],\n",
       "                        [-4.3754e-02, -5.6995e-02,  1.2863e-02],\n",
       "                        [-3.1518e-02, -6.6091e-02,  1.4699e-02]],\n",
       "              \n",
       "                       [[ 5.0747e-02, -3.6635e-03,  3.6801e-03],\n",
       "                        [-1.9261e-03, -4.4846e-02,  5.4276e-02],\n",
       "                        [-2.3349e-03, -2.0560e-02,  4.7001e-02]],\n",
       "              \n",
       "                       [[ 2.7941e-02,  5.9823e-02, -1.0393e-02],\n",
       "                        [ 8.7131e-02, -4.7270e-03,  1.1249e-02],\n",
       "                        [ 6.9137e-02,  7.5738e-04,  1.6339e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.6982e-02,  4.0079e-02, -7.7930e-03],\n",
       "                        [-3.7076e-02, -1.9312e-02, -2.7063e-02],\n",
       "                        [-1.0673e-02, -2.4535e-02,  9.9783e-03]],\n",
       "              \n",
       "                       [[-1.2083e-02,  2.4626e-03, -1.4940e-02],\n",
       "                        [ 2.1548e-03,  2.9447e-02, -2.1811e-03],\n",
       "                        [-2.0534e-02,  3.7243e-02, -2.7121e-02]],\n",
       "              \n",
       "                       [[-1.3047e-02, -3.7589e-02, -6.5744e-02],\n",
       "                        [ 8.3570e-03,  8.3306e-03, -3.1694e-02],\n",
       "                        [-1.6594e-02, -2.7705e-03, -8.8299e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9315e-02,  1.2145e-02, -3.1176e-02],\n",
       "                        [ 6.3027e-03, -7.1481e-04, -3.1927e-02],\n",
       "                        [ 1.9364e-02,  4.2052e-03, -1.9566e-02]],\n",
       "              \n",
       "                       [[-1.9855e-02,  1.7430e-02,  2.4015e-02],\n",
       "                        [ 2.1444e-02,  3.7237e-02,  1.4681e-02],\n",
       "                        [ 1.5801e-02,  2.6180e-02, -1.6995e-02]],\n",
       "              \n",
       "                       [[ 4.5251e-02,  4.0553e-02, -7.1369e-03],\n",
       "                        [ 3.3669e-02,  2.8528e-02,  2.5468e-02],\n",
       "                        [ 8.5669e-04, -2.9174e-02, -1.8554e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.4969e-02, -3.0427e-02, -9.2000e-03],\n",
       "                        [ 1.9208e-02, -4.9419e-02, -3.1581e-02],\n",
       "                        [ 3.0536e-02, -2.1661e-02, -2.9521e-02]],\n",
       "              \n",
       "                       [[ 4.3994e-02,  5.1959e-02,  3.9573e-02],\n",
       "                        [ 1.3979e-02,  1.1414e-02,  3.1020e-03],\n",
       "                        [ 3.2651e-04, -8.9496e-03, -7.7691e-03]],\n",
       "              \n",
       "                       [[ 1.4944e-02,  5.2261e-03, -1.3485e-02],\n",
       "                        [ 3.2752e-02,  3.7579e-02,  2.5116e-02],\n",
       "                        [ 2.9907e-02,  5.7022e-02,  3.0312e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.9953e-02,  4.8833e-02,  5.2309e-02],\n",
       "                        [ 3.7285e-02,  1.9263e-02, -2.6015e-03],\n",
       "                        [ 2.8197e-02, -1.7366e-02, -1.4688e-02]],\n",
       "              \n",
       "                       [[ 4.1824e-02,  5.1154e-02, -8.5273e-03],\n",
       "                        [ 3.7180e-02,  3.8831e-02,  3.7352e-03],\n",
       "                        [ 7.8400e-03,  2.2572e-02, -2.8450e-02]],\n",
       "              \n",
       "                       [[-1.7513e-02,  1.5097e-02,  6.8811e-03],\n",
       "                        [-1.1041e-02, -4.0475e-02, -1.7788e-02],\n",
       "                        [-2.0693e-02, -5.6653e-03,  1.1377e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.3747e-02,  9.7299e-03,  1.4505e-02],\n",
       "                        [ 2.7115e-02,  2.3613e-02,  4.5637e-02],\n",
       "                        [ 2.6436e-02,  5.4756e-02,  1.0891e-02]],\n",
       "              \n",
       "                       [[ 2.0090e-02,  1.5176e-02,  1.1319e-02],\n",
       "                        [ 8.3680e-03, -1.9435e-02, -1.6546e-02],\n",
       "                        [ 6.3271e-04, -2.2041e-02,  4.5867e-04]],\n",
       "              \n",
       "                       [[-5.0706e-03,  1.8152e-02, -9.4108e-03],\n",
       "                        [ 4.8371e-02,  4.0391e-02,  2.3098e-02],\n",
       "                        [-3.6311e-03, -1.9629e-02, -1.4882e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8183e-03, -3.6297e-02, -3.2657e-02],\n",
       "                        [-2.4205e-02, -9.7398e-03,  3.2626e-02],\n",
       "                        [-5.6366e-03, -4.0292e-03,  2.0640e-03]],\n",
       "              \n",
       "                       [[ 3.1122e-02,  4.8816e-03, -1.5482e-02],\n",
       "                        [ 6.2455e-02,  5.1292e-02, -1.9035e-02],\n",
       "                        [ 5.9365e-03,  3.6890e-02, -1.8871e-02]],\n",
       "              \n",
       "                       [[-2.6442e-02, -3.0729e-02, -4.8413e-02],\n",
       "                        [ 1.6397e-02, -6.3393e-03, -9.1918e-03],\n",
       "                        [ 2.1574e-03, -5.1694e-02, -2.1939e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.9026e-03, -3.0305e-02, -1.5312e-02],\n",
       "                        [-1.8327e-02,  1.9854e-03,  1.4306e-03],\n",
       "                        [-3.1173e-02,  2.7919e-02,  3.5750e-02]],\n",
       "              \n",
       "                       [[ 2.5499e-02, -1.9174e-04,  1.8887e-03],\n",
       "                        [ 2.0551e-02,  4.8186e-03, -2.3756e-02],\n",
       "                        [ 1.6665e-03,  1.3548e-02, -7.0371e-03]],\n",
       "              \n",
       "                       [[-7.9219e-03, -9.3038e-03, -4.3883e-03],\n",
       "                        [ 2.5065e-02,  4.2599e-02,  5.9507e-02],\n",
       "                        [-3.5919e-02, -3.5388e-02, -1.7800e-02]]]], device='cuda:0')),\n",
       "             ('features.10.bias',\n",
       "              tensor([ 0.0202,  0.0338, -0.0698,  0.0923, -0.0507, -0.1150,  0.0449,\n",
       "                       0.0521, -0.0903,  0.0583, -0.0690,  0.1236,  0.0341,  0.3370,\n",
       "                       0.0851,  0.2053, -0.0117,  0.0298,  0.0317,  0.0693,  0.2639,\n",
       "                       0.0290, -0.0116,  0.2532, -0.0276, -0.0319,  0.1731,  0.1032,\n",
       "                      -0.0482, -0.0700,  0.1377,  0.1121,  0.1247, -0.1866,  0.0523,\n",
       "                       0.0129, -0.0979,  0.0436, -0.0428, -0.0525, -0.0452,  0.0206,\n",
       "                      -0.0350, -0.2777,  0.0497, -0.0120,  0.0802,  0.0229, -0.0659,\n",
       "                      -0.0475,  0.0331,  0.0134,  0.0792, -0.1670, -0.0224,  0.2618,\n",
       "                      -0.0800, -0.0817,  0.1192,  0.1644,  0.0690, -0.0693, -0.0453,\n",
       "                       0.0007,  0.0384,  0.1381, -0.0329,  0.1217, -0.1571,  0.1048,\n",
       "                       0.2537,  0.0729,  0.0065, -0.1082,  0.0637,  0.1831,  0.0179,\n",
       "                       0.0243, -0.0031,  0.0226,  0.0155,  0.1098, -0.0128,  0.0941,\n",
       "                      -0.0131, -0.0109,  0.1651,  0.0746, -0.0199,  0.1716,  0.1827,\n",
       "                       0.0386, -0.0462,  0.0753, -0.0519,  0.0758, -0.0737,  0.1672,\n",
       "                      -0.0833,  0.0866,  0.0048,  0.1771,  0.0611,  0.0143, -0.0191,\n",
       "                      -0.0037, -0.0503,  0.0224,  0.0290, -0.0603,  0.0606,  0.0479,\n",
       "                       0.0623,  0.0467,  0.0509,  0.0057, -0.1018,  0.3235,  0.0255,\n",
       "                      -0.0259,  0.0334,  0.0222,  0.0960, -0.0305,  0.1143,  0.0661,\n",
       "                      -0.0127, -0.1167, -0.1040, -0.0135, -0.0364, -0.0290, -0.0250,\n",
       "                       0.1876, -0.0326,  0.0989,  0.0342, -0.0897,  0.0944,  0.1789,\n",
       "                      -0.0282,  0.1338,  0.0010, -0.1821, -0.0319, -0.0067, -0.0338,\n",
       "                       0.0077, -0.0149,  0.0979,  0.1016,  0.2405,  0.0388,  0.0089,\n",
       "                      -0.0198,  0.0120,  0.1005, -0.0686, -0.1431, -0.0015,  0.0348,\n",
       "                       0.0225, -0.0254, -0.0148, -0.1054,  0.0236, -0.0599,  0.0279,\n",
       "                      -0.0951, -0.0027, -0.0068,  0.0917,  0.0216,  0.0261,  0.1450,\n",
       "                      -0.0396, -0.0315, -0.1445,  0.0360,  0.0219,  0.1183,  0.0352,\n",
       "                      -0.0246,  0.0475,  0.1258, -0.1394,  0.0567,  0.0946,  0.0147,\n",
       "                       0.1129,  0.0779,  0.0804,  0.0271, -0.0323, -0.0129, -0.0387,\n",
       "                      -0.0446,  0.1217,  0.0598,  0.0433, -0.1319,  0.1268, -0.1234,\n",
       "                       0.0316, -0.0856,  0.1249,  0.0661,  0.0018, -0.0216, -0.0617,\n",
       "                       0.2800, -0.0765,  0.1273, -0.0189,  0.0966, -0.1477, -0.0838,\n",
       "                       0.1879,  0.0175,  0.0795, -0.1509,  0.0410, -0.0384,  0.1817,\n",
       "                      -0.0146, -0.0034, -0.1029,  0.0061, -0.0540,  0.0698, -0.0075,\n",
       "                       0.0486,  0.0549,  0.1806,  0.0658,  0.0229,  0.0516, -0.0191,\n",
       "                      -0.0434,  0.0674, -0.0060, -0.0954, -0.0659,  0.1381, -0.0737,\n",
       "                      -0.0144, -0.0212, -0.1298, -0.0794,  0.1023, -0.0754, -0.1380,\n",
       "                      -0.0433,  0.0886,  0.1197,  0.1059], device='cuda:0')),\n",
       "             ('features.12.weight',\n",
       "              tensor([[[[ 1.4458e-02,  5.4262e-02,  2.5967e-02],\n",
       "                        [-1.6342e-02,  1.6133e-02,  3.6962e-03],\n",
       "                        [-8.6773e-02, -4.2430e-02, -2.7797e-02]],\n",
       "              \n",
       "                       [[ 8.4293e-03, -1.0796e-03,  5.8639e-03],\n",
       "                        [ 5.3881e-03, -3.8932e-03,  2.0397e-02],\n",
       "                        [-2.7216e-02, -1.7411e-03, -2.5664e-03]],\n",
       "              \n",
       "                       [[-6.0055e-02,  2.7928e-02,  5.7307e-02],\n",
       "                        [-7.8412e-02,  1.0588e-03, -2.2218e-02],\n",
       "                        [-2.0841e-02,  5.3504e-02,  9.2433e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.4644e-03,  9.6476e-03,  1.4500e-02],\n",
       "                        [ 7.9505e-04,  7.9915e-03,  5.1864e-03],\n",
       "                        [-9.7005e-03, -1.4069e-02, -8.9335e-03]],\n",
       "              \n",
       "                       [[ 1.5228e-02, -3.4120e-02, -5.4391e-02],\n",
       "                        [-8.1824e-03, -7.1585e-03, -3.7906e-02],\n",
       "                        [-1.5072e-02,  6.2816e-02, -4.9534e-03]],\n",
       "              \n",
       "                       [[ 1.1094e-02,  7.8073e-02,  2.7350e-02],\n",
       "                        [-2.2723e-02,  4.1529e-02, -1.9598e-02],\n",
       "                        [-1.6419e-02, -1.6679e-02, -9.1728e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.5749e-02,  2.4898e-02,  1.9001e-02],\n",
       "                        [ 8.7312e-04,  1.9976e-02,  2.9733e-02],\n",
       "                        [ 3.0736e-03,  4.2173e-03,  7.2681e-03]],\n",
       "              \n",
       "                       [[ 4.7883e-02,  6.1909e-02,  9.2755e-02],\n",
       "                        [-9.3805e-03, -1.6869e-02,  2.8851e-02],\n",
       "                        [ 9.3722e-03, -3.0548e-02, -1.6118e-02]],\n",
       "              \n",
       "                       [[ 1.1930e-02, -7.6034e-03,  1.3502e-02],\n",
       "                        [ 1.8976e-02,  8.4897e-03,  9.9239e-03],\n",
       "                        [ 2.7998e-02,  3.3866e-03,  3.0706e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.1611e-02,  1.3576e-02, -2.2638e-03],\n",
       "                        [ 3.1981e-04,  5.5566e-03,  1.4303e-03],\n",
       "                        [-1.3221e-03, -2.6181e-03,  1.6269e-02]],\n",
       "              \n",
       "                       [[ 9.1360e-03, -1.3612e-02,  1.0803e-02],\n",
       "                        [-1.7446e-02, -2.3003e-02,  6.0578e-03],\n",
       "                        [-1.7264e-02, -5.3412e-03,  1.1269e-03]],\n",
       "              \n",
       "                       [[-1.2673e-02,  1.9370e-02,  2.2894e-03],\n",
       "                        [ 4.0198e-03,  1.6175e-03,  1.0278e-02],\n",
       "                        [-2.4483e-02, -2.5677e-02, -7.6767e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.9262e-03, -5.6233e-03, -3.5152e-03],\n",
       "                        [-6.5375e-03, -1.4448e-02, -9.9792e-03],\n",
       "                        [-2.5880e-02, -1.3281e-02, -1.9598e-02]],\n",
       "              \n",
       "                       [[-8.5774e-03, -2.0572e-02, -1.4821e-02],\n",
       "                        [ 1.8767e-02, -1.2778e-02, -1.5670e-02],\n",
       "                        [ 1.3260e-02, -3.0004e-03, -1.8270e-02]],\n",
       "              \n",
       "                       [[ 1.7317e-02,  1.0014e-02,  1.5421e-02],\n",
       "                        [ 1.6499e-02, -1.4778e-02,  1.2397e-02],\n",
       "                        [-1.6704e-02, -2.5014e-02,  1.4771e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.0394e-03,  1.2566e-02,  1.5867e-02],\n",
       "                        [ 9.8934e-03,  2.9302e-02,  4.7297e-03],\n",
       "                        [ 1.1337e-02, -1.9948e-03,  1.0692e-02]],\n",
       "              \n",
       "                       [[ 3.4212e-03,  5.1473e-03, -1.4110e-02],\n",
       "                        [ 5.1296e-03, -1.3783e-02, -2.9022e-02],\n",
       "                        [-5.5250e-03,  6.1991e-03,  7.0356e-03]],\n",
       "              \n",
       "                       [[ 3.5273e-03, -8.8340e-03, -2.1254e-02],\n",
       "                        [ 1.5234e-02, -8.9212e-03,  1.2711e-02],\n",
       "                        [-3.2081e-03, -2.3476e-02, -8.4571e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-2.8562e-02, -7.5180e-03,  1.4599e-02],\n",
       "                        [-2.0243e-02, -2.9485e-02,  5.4713e-05],\n",
       "                        [-2.6308e-03, -2.8685e-02, -1.9327e-02]],\n",
       "              \n",
       "                       [[ 7.3137e-03, -6.8900e-03,  1.6473e-03],\n",
       "                        [ 2.3934e-02,  1.7293e-02,  1.8168e-02],\n",
       "                        [ 3.2893e-02,  3.2778e-02,  4.1614e-02]],\n",
       "              \n",
       "                       [[ 1.5314e-03, -4.7585e-02,  3.9553e-02],\n",
       "                        [-2.2300e-02, -5.7313e-02,  2.5074e-02],\n",
       "                        [-4.3050e-02, -1.2614e-02,  2.3613e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.4826e-03,  4.6901e-03,  2.3574e-02],\n",
       "                        [-7.8160e-03, -1.0316e-02,  3.5899e-02],\n",
       "                        [ 2.1178e-02,  5.7244e-03, -1.8567e-03]],\n",
       "              \n",
       "                       [[-5.9718e-04,  2.6017e-03,  3.9694e-02],\n",
       "                        [-3.0896e-03,  2.2937e-02,  3.3988e-02],\n",
       "                        [-3.9173e-02, -4.4933e-03,  9.7815e-03]],\n",
       "              \n",
       "                       [[-4.7458e-02,  9.8044e-02,  2.5373e-02],\n",
       "                        [-6.1261e-02,  4.3155e-02,  1.6545e-02],\n",
       "                        [-5.1283e-02, -3.7696e-02, -4.9548e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.3331e-02, -8.1990e-03, -5.3522e-02],\n",
       "                        [-2.2125e-02,  1.1858e-02, -3.4055e-02],\n",
       "                        [-3.6413e-02, -1.7979e-02, -4.2806e-02]],\n",
       "              \n",
       "                       [[-2.5023e-03,  1.1622e-03, -4.5095e-03],\n",
       "                        [-1.5937e-02,  1.3033e-03, -1.4039e-03],\n",
       "                        [ 8.4911e-03,  1.6547e-02,  1.6302e-02]],\n",
       "              \n",
       "                       [[ 3.4255e-02,  1.4493e-03, -2.0719e-02],\n",
       "                        [ 2.3174e-02, -2.6618e-02, -1.8910e-02],\n",
       "                        [ 8.0609e-03, -1.6315e-02,  1.3355e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.6971e-02,  3.6007e-03, -4.9184e-03],\n",
       "                        [ 3.3523e-03,  1.8616e-02, -1.2742e-02],\n",
       "                        [-2.6226e-03,  1.0755e-02, -2.8754e-03]],\n",
       "              \n",
       "                       [[-4.1152e-02, -1.6278e-02,  3.4659e-02],\n",
       "                        [ 1.4860e-02,  2.6478e-02,  6.8205e-02],\n",
       "                        [ 1.4101e-02,  4.9415e-02,  6.2358e-02]],\n",
       "              \n",
       "                       [[-3.2522e-02,  8.4283e-03, -3.2296e-02],\n",
       "                        [-2.6740e-02,  6.3519e-02,  7.2680e-03],\n",
       "                        [-8.6290e-03,  5.3084e-02,  2.2354e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8128e-02,  4.9794e-03, -2.7731e-02],\n",
       "                        [-5.2834e-02, -1.6674e-02, -4.8823e-02],\n",
       "                        [-4.3085e-02, -4.8342e-03, -2.1020e-02]],\n",
       "              \n",
       "                       [[-1.8078e-02,  7.5349e-03,  2.1894e-02],\n",
       "                        [ 2.0570e-03,  2.1014e-02,  2.7317e-02],\n",
       "                        [-4.4044e-03, -5.6735e-03, -1.1678e-02]],\n",
       "              \n",
       "                       [[-3.9333e-03,  1.5431e-02,  3.1095e-03],\n",
       "                        [-3.4266e-02, -8.0041e-03, -4.0737e-02],\n",
       "                        [-1.0373e-02, -1.3137e-02, -2.5135e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.1422e-02, -1.1068e-02, -2.6556e-02],\n",
       "                        [ 5.5402e-04, -1.1401e-02, -2.5478e-02],\n",
       "                        [-1.0598e-02,  1.1776e-02,  2.3815e-02]],\n",
       "              \n",
       "                       [[-2.0722e-02, -2.0430e-02, -1.3406e-02],\n",
       "                        [-2.9648e-02, -2.0838e-02, -3.3982e-02],\n",
       "                        [-2.5423e-02, -5.0160e-03, -1.6819e-02]],\n",
       "              \n",
       "                       [[-2.8305e-02, -3.1576e-02, -4.5957e-02],\n",
       "                        [-2.3097e-02, -1.5578e-02, -2.3184e-02],\n",
       "                        [-2.1999e-02,  3.7065e-03,  2.3179e-03]]]], device='cuda:0')),\n",
       "             ('features.12.bias',\n",
       "              tensor([ 0.0081,  0.0008,  0.0921,  0.0401, -0.0459,  0.0429,  0.0023,\n",
       "                       0.0654,  0.0898,  0.0891,  0.0697,  0.2036, -0.1984, -0.0156,\n",
       "                      -0.0234, -0.0090, -0.0117,  0.0390, -0.0326,  0.2342,  0.1007,\n",
       "                       0.0658,  0.0196,  0.1381, -0.1318,  0.0273,  0.2149,  0.0126,\n",
       "                       0.0744,  0.1737, -0.1128,  0.1259,  0.0321,  0.1362,  0.0060,\n",
       "                       0.0778,  0.1610,  0.2223,  0.1665, -0.0132, -0.0238,  0.1425,\n",
       "                       0.1552,  0.0869,  0.1412, -0.0429,  0.0677,  0.0206,  0.1080,\n",
       "                       0.2640,  0.1063, -0.0261, -0.0140,  0.1273,  0.0410, -0.1462,\n",
       "                      -0.0257,  0.0140,  0.0486, -0.0092,  0.0228,  0.0428,  0.0226,\n",
       "                       0.0066,  0.0014,  0.1270,  0.0320,  0.0989, -0.0172,  0.1474,\n",
       "                       0.0830,  0.1477,  0.2371,  0.0403, -0.0558,  0.0189,  0.0474,\n",
       "                      -0.0311,  0.0552,  0.0268,  0.0219, -0.1241, -0.0402,  0.0836,\n",
       "                       0.0670,  0.0083,  0.0702,  0.1147,  0.1347, -0.0128,  0.2890,\n",
       "                       0.1577, -0.1817, -0.0160, -0.0036,  0.0874,  0.0404,  0.0438,\n",
       "                       0.0861,  0.1154,  0.1607, -0.0231,  0.1155, -0.0018,  0.0136,\n",
       "                       0.0950,  0.0477, -0.0988,  0.0616,  0.0948, -0.0689, -0.0102,\n",
       "                       0.1182, -0.1292,  0.0223,  0.0818,  0.0722,  0.0156,  0.1165,\n",
       "                      -0.0359,  0.0751,  0.0290,  0.0286, -0.0560,  0.1883,  0.0147,\n",
       "                       0.1054,  0.1067, -0.1083,  0.0514,  0.1042,  0.0518,  0.1017,\n",
       "                       0.1114,  0.0223, -0.0822, -0.0090,  0.0857,  0.0251, -0.0731,\n",
       "                       0.1057,  0.1295,  0.0430,  0.0721,  0.0236,  0.0671,  0.0714,\n",
       "                       0.0003,  0.0366, -0.0715,  0.0393,  0.0395, -0.0209,  0.0509,\n",
       "                      -0.0400,  0.0318,  0.0060, -0.0212, -0.0153,  0.1134,  0.0069,\n",
       "                       0.0592, -0.0839, -0.0743, -0.1683, -0.0244,  0.1875,  0.0369,\n",
       "                       0.1861,  0.0996,  0.0322,  0.0711,  0.0483,  0.1173,  0.0322,\n",
       "                       0.0079, -0.0453,  0.0019,  0.0067,  0.1854,  0.0722,  0.0462,\n",
       "                       0.0480,  0.0030,  0.1393,  0.0149, -0.0285,  0.0869,  0.0425,\n",
       "                      -0.0315,  0.0561,  0.1013,  0.0567,  0.1636, -0.0591,  0.1075,\n",
       "                      -0.0456,  0.0341, -0.0290,  0.1095,  0.1375, -0.0356,  0.0761,\n",
       "                       0.0288,  0.0551,  0.1078, -0.0363,  0.2171,  0.0526,  0.0696,\n",
       "                      -0.1063,  0.1262,  0.0418,  0.0290,  0.0689,  0.1373, -0.0678,\n",
       "                       0.1006, -0.0019, -0.0919,  0.1378, -0.0968,  0.0735,  0.0374,\n",
       "                       0.0339, -0.0866,  0.0631,  0.0561,  0.0815,  0.0047, -0.0130,\n",
       "                       0.0500, -0.1108,  0.0169,  0.1148,  0.0299,  0.0398,  0.1097,\n",
       "                       0.0245,  0.0545, -0.1936,  0.1633,  0.0391, -0.0328,  0.1820,\n",
       "                       0.0246,  0.0244,  0.0986, -0.0062,  0.0407, -0.0133,  0.0259,\n",
       "                       0.1405,  0.0653, -0.0096,  0.0564], device='cuda:0')),\n",
       "             ('features.14.weight',\n",
       "              tensor([[[[-1.5544e-02,  3.3516e-03, -2.0751e-02],\n",
       "                        [-1.5367e-02,  1.0605e-02, -1.2374e-03],\n",
       "                        [-4.6054e-03,  1.7772e-02, -3.5606e-03]],\n",
       "              \n",
       "                       [[-2.0633e-02,  6.5511e-03, -1.8140e-02],\n",
       "                        [ 1.1604e-02, -3.8011e-03, -2.2577e-02],\n",
       "                        [ 3.5573e-02, -5.5596e-03, -3.5889e-03]],\n",
       "              \n",
       "                       [[ 1.4331e-04, -1.4505e-02,  2.5937e-02],\n",
       "                        [ 3.4630e-02,  2.2740e-02,  1.4167e-02],\n",
       "                        [ 4.8566e-02,  3.4959e-02,  2.3550e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.0420e-04, -9.1078e-03, -9.9376e-03],\n",
       "                        [-1.3810e-02,  1.5919e-02,  1.3157e-02],\n",
       "                        [-3.8292e-02,  3.1625e-03,  2.1699e-02]],\n",
       "              \n",
       "                       [[-2.4960e-02, -3.8537e-02, -2.2257e-02],\n",
       "                        [-4.9760e-02, -4.9415e-02, -4.2074e-02],\n",
       "                        [-4.3309e-02, -3.7308e-02, -2.0301e-02]],\n",
       "              \n",
       "                       [[ 2.0194e-02,  2.5575e-02,  7.0617e-03],\n",
       "                        [ 1.7423e-04,  8.3635e-03,  2.4267e-02],\n",
       "                        [ 9.5661e-03,  6.7630e-03,  2.9889e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.5263e-03, -2.9669e-02, -1.8027e-02],\n",
       "                        [-5.5181e-03, -1.1077e-02, -1.3884e-02],\n",
       "                        [-5.7321e-03, -4.9993e-03,  1.8030e-02]],\n",
       "              \n",
       "                       [[ 2.0556e-02,  1.6408e-02,  4.7495e-03],\n",
       "                        [ 7.2905e-03, -1.2065e-02, -1.6603e-02],\n",
       "                        [-2.8449e-02, -4.4583e-02, -4.1656e-02]],\n",
       "              \n",
       "                       [[-1.0331e-02, -1.2687e-02, -4.5574e-02],\n",
       "                        [ 2.2775e-02,  1.0676e-02, -2.3934e-03],\n",
       "                        [ 4.3244e-02,  4.3693e-02,  4.5349e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.3707e-03,  1.4907e-02,  1.5282e-02],\n",
       "                        [-1.9736e-02, -7.7375e-03, -8.2349e-03],\n",
       "                        [-4.3112e-02, -5.1415e-02, -5.3313e-02]],\n",
       "              \n",
       "                       [[-8.2975e-03, -2.0927e-02, -1.9813e-02],\n",
       "                        [-1.1684e-02, -3.6922e-02, -4.2012e-02],\n",
       "                        [ 4.1431e-03, -2.6438e-02, -1.3934e-02]],\n",
       "              \n",
       "                       [[ 1.1557e-03, -1.4097e-02,  9.8918e-03],\n",
       "                        [-9.9301e-03,  2.6239e-03,  1.3651e-02],\n",
       "                        [-9.0890e-03, -2.1858e-02, -2.2494e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6160e-03, -1.1019e-02, -1.4342e-02],\n",
       "                        [-8.8264e-03,  1.3350e-02, -1.1531e-02],\n",
       "                        [-5.9485e-03,  9.4718e-03, -9.1793e-03]],\n",
       "              \n",
       "                       [[ 4.2511e-03,  1.6032e-02,  7.6145e-03],\n",
       "                        [ 8.6857e-03, -3.5891e-03, -1.1714e-02],\n",
       "                        [-1.3860e-02, -3.1661e-02, -2.3928e-02]],\n",
       "              \n",
       "                       [[-2.2805e-02, -1.4389e-02,  3.9767e-03],\n",
       "                        [-1.5152e-02,  2.2924e-02,  1.5583e-03],\n",
       "                        [ 1.7095e-02,  3.6812e-02,  5.1749e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.0707e-02, -3.1764e-02,  9.1967e-03],\n",
       "                        [-2.4740e-03, -3.5157e-02,  2.4755e-02],\n",
       "                        [-2.2312e-03, -4.9634e-02,  6.6611e-03]],\n",
       "              \n",
       "                       [[-2.3822e-02, -3.0434e-02, -1.1702e-02],\n",
       "                        [-1.5988e-02, -5.3436e-02, -2.8461e-02],\n",
       "                        [-2.0167e-02, -3.8936e-02, -2.8995e-02]],\n",
       "              \n",
       "                       [[ 1.2318e-03,  3.0418e-03, -8.1856e-03],\n",
       "                        [ 1.1941e-02,  2.3479e-02, -1.2295e-03],\n",
       "                        [ 3.1632e-02,  9.8497e-02,  1.1167e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.3978e-02, -1.0096e-02, -6.7816e-03],\n",
       "                        [-2.0337e-02, -1.2788e-02, -1.5630e-02],\n",
       "                        [ 1.3211e-02,  3.8027e-02,  3.3175e-04]],\n",
       "              \n",
       "                       [[ 4.0026e-02,  5.8814e-02,  2.9283e-02],\n",
       "                        [-2.0939e-03, -1.0230e-02,  2.5083e-02],\n",
       "                        [ 2.3883e-02,  7.6345e-03,  1.3915e-02]],\n",
       "              \n",
       "                       [[-1.1005e-02, -1.7670e-02, -2.2506e-02],\n",
       "                        [ 8.4216e-03, -7.1628e-03, -4.0214e-03],\n",
       "                        [ 2.4506e-02,  2.8798e-02,  3.8584e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5745e-02,  1.6152e-02,  2.4768e-02],\n",
       "                        [-3.0895e-02, -5.3081e-02, -3.7917e-03],\n",
       "                        [ 1.1524e-02, -2.0494e-02, -3.7499e-02]],\n",
       "              \n",
       "                       [[-3.6624e-02, -4.6628e-02, -1.4860e-02],\n",
       "                        [-9.5098e-03, -9.1068e-03,  4.3600e-04],\n",
       "                        [ 5.1414e-03,  2.4316e-02,  3.3786e-02]],\n",
       "              \n",
       "                       [[-1.6674e-02, -2.3379e-02,  5.9119e-03],\n",
       "                        [-9.6027e-03, -1.1790e-02, -7.3357e-03],\n",
       "                        [ 3.7716e-02,  4.8927e-03,  1.0373e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6137e-03,  9.3332e-03, -1.7039e-02],\n",
       "                        [ 1.8564e-02,  1.2758e-02, -1.4459e-02],\n",
       "                        [ 1.2688e-02,  8.9029e-03, -1.7960e-02]],\n",
       "              \n",
       "                       [[-2.4035e-03, -1.5381e-02,  1.8711e-02],\n",
       "                        [ 3.1369e-02,  1.0875e-03,  1.8606e-02],\n",
       "                        [ 3.1375e-02,  3.1507e-02,  2.5750e-02]],\n",
       "              \n",
       "                       [[ 1.4468e-02, -4.9880e-03, -2.3109e-03],\n",
       "                        [ 1.5343e-02,  1.3154e-04,  7.0862e-04],\n",
       "                        [ 5.4596e-03, -1.1760e-02,  1.3427e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.0560e-02,  1.5818e-02, -1.3037e-02],\n",
       "                        [-1.6662e-02,  6.9287e-03, -1.6611e-02],\n",
       "                        [-6.8834e-03,  1.0386e-02, -1.7669e-02]],\n",
       "              \n",
       "                       [[ 1.3056e-02, -1.8228e-02, -1.1621e-02],\n",
       "                        [ 1.3019e-02, -7.6602e-03, -5.8207e-03],\n",
       "                        [ 2.9629e-02, -1.2289e-02,  6.9818e-03]],\n",
       "              \n",
       "                       [[-6.9196e-03, -2.9970e-02, -3.3678e-03],\n",
       "                        [-4.6268e-02, -5.4458e-02,  7.2381e-04],\n",
       "                        [-4.8718e-02, -3.9557e-02,  3.5889e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6158e-02, -5.6350e-02, -1.7474e-02],\n",
       "                        [-1.7418e-02, -5.4957e-02, -2.3799e-02],\n",
       "                        [ 3.1004e-02,  1.3744e-02, -1.0487e-02]],\n",
       "              \n",
       "                       [[ 4.9110e-02,  1.3333e-02,  5.3027e-03],\n",
       "                        [ 1.9727e-02,  3.4211e-02,  4.4024e-03],\n",
       "                        [ 7.8734e-03,  5.6557e-03,  3.0069e-02]],\n",
       "              \n",
       "                       [[ 1.2763e-02,  5.6162e-03,  1.5483e-02],\n",
       "                        [ 3.4423e-02, -8.1900e-03, -9.6889e-03],\n",
       "                        [ 3.6588e-02,  2.9389e-04, -2.4553e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.9680e-03,  1.1742e-02,  1.1846e-02],\n",
       "                        [-7.7828e-04,  9.1763e-03,  1.1474e-02],\n",
       "                        [-1.0945e-02,  8.2790e-04, -1.5765e-02]],\n",
       "              \n",
       "                       [[-2.0633e-02, -7.6791e-02, -7.4553e-02],\n",
       "                        [-2.5410e-03, -3.5546e-02, -4.2239e-02],\n",
       "                        [ 1.7062e-02, -1.1370e-02, -3.1354e-02]],\n",
       "              \n",
       "                       [[-1.2148e-02, -1.1332e-02,  1.5274e-02],\n",
       "                        [-1.4124e-02, -6.5950e-03,  1.3761e-02],\n",
       "                        [-8.3379e-03, -2.1941e-02, -5.4669e-04]]]], device='cuda:0')),\n",
       "             ('features.14.bias',\n",
       "              tensor([ 0.1527,  0.0026,  0.0118,  0.0612,  0.0751,  0.0336,  0.0359,\n",
       "                       0.1965, -0.0776, -0.0464,  0.0143, -0.0799, -0.1670, -0.0019,\n",
       "                       0.2606,  0.1202, -0.0356, -0.0970,  0.1096,  0.3574, -0.1109,\n",
       "                      -0.1799,  0.0262,  0.0853,  0.0695,  0.1890,  0.0186, -0.0910,\n",
       "                      -0.0431, -0.1330,  0.0615, -0.0163,  0.0268,  0.0015,  0.0059,\n",
       "                       0.3832, -0.0661, -0.0292,  0.1524,  0.0463,  0.0012, -0.0849,\n",
       "                       0.0185,  0.1371,  0.0122, -0.0279,  0.0299,  0.2400,  0.0575,\n",
       "                       0.0058, -0.0423, -0.0749,  0.0616,  0.0374, -0.0554,  0.2787,\n",
       "                      -0.0078,  0.0378,  0.0448,  0.0146,  0.1976, -0.0101,  0.1134,\n",
       "                      -0.0527,  0.0147,  0.0263,  0.0608,  0.1433, -0.1462,  0.0421,\n",
       "                       0.1858,  0.0425, -0.0079,  0.1064,  0.0585,  0.0768, -0.0239,\n",
       "                      -0.0044, -0.0805, -0.0221,  0.1140, -0.0683, -0.0827, -0.0357,\n",
       "                      -0.0555,  0.3748,  0.0047,  0.4622, -0.1137,  0.0499, -0.0782,\n",
       "                      -0.0067, -0.1540,  0.0021,  0.0214,  0.2276, -0.0322, -0.1061,\n",
       "                       0.0281,  0.0258,  0.0006,  0.0171, -0.0165, -0.0237,  0.0153,\n",
       "                      -0.1518,  0.0878, -0.0198, -0.0478,  0.0325, -0.0095, -0.0673,\n",
       "                       0.0015, -0.0601, -0.0157,  0.0288,  0.3301, -0.0207,  0.1275,\n",
       "                       0.0270,  0.1409, -0.0736, -0.0761,  0.0053, -0.1070,  0.0598,\n",
       "                      -0.0250,  0.3023, -0.0699,  0.0256,  0.1078, -0.0116, -0.0383,\n",
       "                      -0.0591, -0.1085,  0.0720, -0.0430,  0.2818,  0.0155, -0.0255,\n",
       "                      -0.0499,  0.0225,  0.0256,  0.1965,  0.0169, -0.0636, -0.0493,\n",
       "                       0.2131,  0.0348,  0.0979,  0.0510, -0.0073, -0.0826, -0.0063,\n",
       "                      -0.0395,  0.0054,  0.1830,  0.0029,  0.0332,  0.2406,  0.0567,\n",
       "                       0.0066, -0.1359, -0.0163,  0.1877, -0.0564, -0.1024, -0.0884,\n",
       "                       0.0464,  0.1190, -0.1196,  0.0211, -0.0810,  0.0997, -0.1556,\n",
       "                      -0.0740, -0.0100, -0.0201,  0.0839, -0.0453,  0.0081,  0.0599,\n",
       "                      -0.0338,  0.2230, -0.1076,  0.0043,  0.0065, -0.0494, -0.0767,\n",
       "                       0.0475, -0.0149,  0.2279, -0.0490, -0.0124, -0.0288, -0.0238,\n",
       "                       0.0233, -0.0998,  0.0037,  0.3284, -0.0424,  0.3322,  0.0159,\n",
       "                      -0.0710,  0.0465,  0.0838,  0.0332,  0.1902,  0.0334, -0.0613,\n",
       "                       0.1509,  0.0363,  0.1291, -0.1115, -0.0433,  0.0450, -0.0986,\n",
       "                       0.0771,  0.0814,  0.0824, -0.0308, -0.0128, -0.0068, -0.0059,\n",
       "                      -0.0202,  0.0106, -0.1317,  0.1157, -0.1242, -0.0816, -0.0769,\n",
       "                      -0.0481,  0.0572,  0.1796, -0.0352, -0.0285,  0.0144,  0.1194,\n",
       "                      -0.0091,  0.1399, -0.0381,  0.0255, -0.0679,  0.0725,  0.0707,\n",
       "                       0.0324,  0.0248, -0.0288, -0.0367,  0.1565,  0.0469, -0.0201,\n",
       "                      -0.0677, -0.0388, -0.1451, -0.1943], device='cuda:0')),\n",
       "             ('features.17.weight',\n",
       "              tensor([[[[-7.0407e-03, -1.2371e-02,  2.2388e-03],\n",
       "                        [-3.4945e-04,  8.3066e-03, -3.3719e-03],\n",
       "                        [ 1.4878e-03,  1.1629e-02,  1.7914e-02]],\n",
       "              \n",
       "                       [[ 1.7044e-02,  1.3268e-02,  1.6129e-02],\n",
       "                        [-9.7721e-04, -1.2761e-03,  5.3491e-03],\n",
       "                        [-4.9739e-03,  6.8304e-03, -1.4400e-02]],\n",
       "              \n",
       "                       [[-1.3706e-02, -1.5852e-02, -7.2444e-03],\n",
       "                        [ 1.1695e-02,  7.9012e-03,  3.7443e-03],\n",
       "                        [ 3.4724e-03,  1.2283e-02,  1.2933e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.5974e-02,  6.9182e-02,  6.9327e-02],\n",
       "                        [ 4.5527e-02, -1.3160e-03,  6.0608e-02],\n",
       "                        [ 7.0592e-02,  5.3374e-02,  2.0030e-02]],\n",
       "              \n",
       "                       [[ 1.4789e-02, -1.7400e-02, -2.3320e-02],\n",
       "                        [ 1.1156e-02,  1.5264e-02, -9.4171e-03],\n",
       "                        [ 2.1255e-02,  1.4230e-02, -1.3540e-02]],\n",
       "              \n",
       "                       [[-2.0577e-02, -9.5674e-03,  6.9175e-03],\n",
       "                        [-7.2709e-03, -1.7179e-02,  2.0196e-02],\n",
       "                        [ 1.7350e-02,  5.2181e-03, -1.2872e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0917e-02, -1.6156e-02, -4.3484e-03],\n",
       "                        [-2.5008e-02, -4.2966e-02, -3.0563e-02],\n",
       "                        [-2.6327e-02, -2.4413e-02, -8.5690e-03]],\n",
       "              \n",
       "                       [[-3.7772e-02, -1.2624e-02, -2.0013e-02],\n",
       "                        [-3.3966e-02, -1.6831e-02, -1.0124e-02],\n",
       "                        [-1.8217e-02, -1.5020e-02,  1.3080e-03]],\n",
       "              \n",
       "                       [[ 1.2184e-02, -1.2087e-02,  1.7991e-02],\n",
       "                        [ 5.2722e-02,  8.0374e-03,  2.2514e-02],\n",
       "                        [ 5.8993e-02,  3.2782e-02,  2.1087e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.8349e-03, -4.7245e-03,  2.4834e-02],\n",
       "                        [-7.2375e-03, -1.1020e-02,  1.7923e-02],\n",
       "                        [ 2.6053e-02, -1.8564e-02, -2.8714e-03]],\n",
       "              \n",
       "                       [[ 1.6234e-02, -3.4470e-02, -1.4160e-02],\n",
       "                        [ 2.6344e-03, -3.5605e-02, -4.0918e-02],\n",
       "                        [ 3.2230e-03, -1.3359e-02, -1.6670e-02]],\n",
       "              \n",
       "                       [[-2.8010e-02, -1.8247e-02, -1.0266e-02],\n",
       "                        [-2.4739e-02, -4.9246e-02, -2.1506e-02],\n",
       "                        [-3.2995e-02, -3.5000e-02, -2.9097e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.9750e-03,  2.6729e-02,  3.2822e-02],\n",
       "                        [ 3.6466e-03, -1.7902e-02, -4.3422e-03],\n",
       "                        [-8.5616e-03, -1.7390e-02, -6.4783e-03]],\n",
       "              \n",
       "                       [[-2.4613e-02, -1.8950e-02, -2.5066e-02],\n",
       "                        [-1.7697e-02, -9.3534e-03, -6.0126e-03],\n",
       "                        [ 9.1716e-03, -2.1026e-03,  8.8393e-03]],\n",
       "              \n",
       "                       [[-8.2647e-03, -1.0965e-02,  1.1624e-02],\n",
       "                        [ 1.5643e-02, -1.4625e-02,  3.9084e-03],\n",
       "                        [ 3.4610e-02, -3.9968e-03,  1.7886e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.8449e-02, -2.2875e-02, -3.0008e-02],\n",
       "                        [-3.7424e-02, -4.2076e-02, -5.0794e-02],\n",
       "                        [-1.4039e-02,  4.4702e-02,  7.4715e-02]],\n",
       "              \n",
       "                       [[ 3.3004e-03,  7.3116e-03,  3.0886e-03],\n",
       "                        [-4.4847e-02, -5.6967e-03, -1.3882e-02],\n",
       "                        [-2.5696e-02, -2.6993e-02,  6.3057e-03]],\n",
       "              \n",
       "                       [[ 1.8556e-03, -1.5118e-02,  2.4970e-03],\n",
       "                        [ 4.8854e-02,  2.7233e-02, -2.2185e-02],\n",
       "                        [ 1.1909e-02,  5.5265e-03, -2.7282e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 7.5810e-03, -9.0366e-03,  1.4369e-03],\n",
       "                        [-4.1151e-03, -5.4969e-03,  1.4365e-02],\n",
       "                        [-1.1409e-03,  2.9281e-03,  4.0953e-03]],\n",
       "              \n",
       "                       [[-4.2916e-02, -3.9380e-02, -1.5347e-02],\n",
       "                        [-3.2325e-02, -1.0138e-02, -8.9602e-03],\n",
       "                        [-6.7189e-03,  9.2747e-03,  3.9578e-03]],\n",
       "              \n",
       "                       [[ 6.2547e-03,  2.0394e-02,  3.2767e-02],\n",
       "                        [-9.7907e-03, -4.7231e-03,  3.3003e-02],\n",
       "                        [-7.1901e-03, -9.9433e-03, -3.3229e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.7658e-02,  4.6615e-02,  9.7046e-03],\n",
       "                        [ 2.7706e-03,  1.7994e-03, -3.2915e-03],\n",
       "                        [-3.6330e-05,  1.3310e-02, -3.9286e-03]],\n",
       "              \n",
       "                       [[-6.9039e-03,  6.3574e-03,  1.6824e-02],\n",
       "                        [-2.9717e-02, -2.2547e-02,  7.5127e-03],\n",
       "                        [ 1.7091e-03, -2.6405e-02, -7.0685e-03]],\n",
       "              \n",
       "                       [[ 7.4595e-03,  1.0742e-02, -3.1499e-04],\n",
       "                        [-6.9448e-03, -2.4510e-02, -2.4144e-02],\n",
       "                        [-3.1542e-02, -1.5262e-02, -1.4584e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.9512e-02,  2.3043e-02,  2.2162e-02],\n",
       "                        [-1.2518e-03, -3.5788e-03,  6.6051e-03],\n",
       "                        [ 1.4536e-02,  1.2092e-02,  1.0204e-02]],\n",
       "              \n",
       "                       [[-5.4716e-05, -9.5875e-03,  1.0365e-02],\n",
       "                        [-8.1047e-03, -2.0313e-02, -4.4185e-03],\n",
       "                        [ 1.3795e-02,  1.4303e-03,  1.5385e-02]],\n",
       "              \n",
       "                       [[ 2.8190e-03, -1.0707e-02, -1.1369e-03],\n",
       "                        [-2.1748e-03, -2.2595e-02, -1.0350e-02],\n",
       "                        [-2.2768e-02, -1.3309e-02, -9.0804e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.8838e-02,  2.8987e-02,  1.6121e-02],\n",
       "                        [ 1.1093e-02, -2.4850e-02, -2.4911e-02],\n",
       "                        [ 5.4552e-03, -4.9657e-03, -1.5505e-02]],\n",
       "              \n",
       "                       [[ 5.5599e-03, -3.9190e-02, -2.5970e-02],\n",
       "                        [-1.9628e-02, -4.3369e-02, -1.1961e-02],\n",
       "                        [-1.9965e-02, -3.1207e-02,  4.5270e-04]],\n",
       "              \n",
       "                       [[ 1.1173e-02,  8.0449e-04,  9.5013e-03],\n",
       "                        [-1.9043e-02, -2.9472e-02, -1.4361e-02],\n",
       "                        [-3.0420e-02, -1.2566e-02, -1.6186e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5104e-03, -3.1250e-03, -1.4089e-02],\n",
       "                        [-2.5407e-03,  4.5601e-03, -3.2633e-02],\n",
       "                        [ 9.2935e-03, -2.8452e-03,  1.9294e-03]],\n",
       "              \n",
       "                       [[-1.2509e-02, -1.7259e-02,  1.3495e-03],\n",
       "                        [ 5.4679e-03, -5.5054e-03,  2.3635e-02],\n",
       "                        [ 5.8567e-03,  1.2592e-02,  2.7611e-02]],\n",
       "              \n",
       "                       [[-1.3583e-02, -4.1725e-02, -3.4188e-02],\n",
       "                        [-1.9751e-02, -3.7626e-02, -2.4501e-02],\n",
       "                        [-5.7688e-03, -2.1353e-02, -4.6215e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.1298e-02, -5.5083e-03, -1.7650e-02],\n",
       "                        [-7.7781e-03, -3.0555e-02, -2.7287e-02],\n",
       "                        [-2.6451e-02, -4.3400e-02, -2.3002e-02]],\n",
       "              \n",
       "                       [[-2.6287e-03, -1.7704e-02, -2.6902e-02],\n",
       "                        [-4.5120e-03, -4.0293e-02, -2.8228e-02],\n",
       "                        [-1.3612e-02, -2.6651e-02, -7.3693e-03]],\n",
       "              \n",
       "                       [[-9.8540e-03, -1.2848e-02, -8.3328e-04],\n",
       "                        [-1.2088e-02, -1.4440e-02,  1.5528e-02],\n",
       "                        [-2.7315e-02,  5.2576e-03,  2.6680e-02]]]], device='cuda:0')),\n",
       "             ('features.17.bias',\n",
       "              tensor([ 0.0626, -0.0063, -0.0952,  0.0643,  0.0506,  0.1833,  0.1208,\n",
       "                       0.0395,  0.1299, -0.1333,  0.2948,  0.0101, -0.0220, -0.0240,\n",
       "                      -0.0888, -0.1247, -0.0263,  0.0123,  0.0427,  0.0222,  0.0791,\n",
       "                       0.0587, -0.0492,  0.0321,  0.0027, -0.0644, -0.0257, -0.0252,\n",
       "                       0.0672,  0.0208, -0.0379, -0.0122, -0.0481, -0.1384, -0.0953,\n",
       "                      -0.0174, -0.0362, -0.0132,  0.1091, -0.0381,  0.0116, -0.0166,\n",
       "                      -0.0437, -0.0470, -0.0621, -0.1515, -0.0957, -0.0466, -0.0666,\n",
       "                       0.4091, -0.0140,  0.0058, -0.1020, -0.0413,  0.0066, -0.0202,\n",
       "                       0.0711, -0.0546,  0.0049,  0.0573,  0.0067, -0.0012,  0.0566,\n",
       "                      -0.0622,  0.0548,  0.0503,  0.0062,  0.2510, -0.0328, -0.3222,\n",
       "                      -0.0821, -0.0828,  0.0509,  0.1537,  0.1584,  0.0963,  0.0441,\n",
       "                      -0.0935, -0.0413, -0.0679,  0.0742, -0.0676,  0.0916, -0.0431,\n",
       "                      -0.0177, -0.0324, -0.2270, -0.0185, -0.0022,  0.0315,  0.0637,\n",
       "                       0.0410,  0.0356, -0.0157, -0.0398,  0.0767, -0.0245,  0.0178,\n",
       "                       0.0452, -0.0780, -0.1281,  0.0056, -0.0365, -0.0723,  0.0155,\n",
       "                       0.0307,  0.0124,  0.0036,  0.0070,  0.0114,  0.0122,  0.0176,\n",
       "                      -0.0497,  0.2951,  0.0770,  0.1238,  0.2965,  0.0056, -0.0956,\n",
       "                      -0.0553, -0.0481,  0.0449,  0.0054, -0.0402, -0.0277,  0.0789,\n",
       "                       0.0347,  0.2086, -0.0552,  0.0926,  0.0254, -0.0116, -0.0091,\n",
       "                      -0.0478,  0.0075,  0.0418, -0.0268, -0.1673,  0.0159,  0.1045,\n",
       "                      -0.0129,  0.0283, -0.1000,  0.0049,  0.0688, -0.0178, -0.0770,\n",
       "                      -0.0677, -0.2153,  0.1610, -0.0224,  0.2884,  0.1246, -0.0783,\n",
       "                      -0.0677, -0.0154,  0.2730, -0.0178,  0.0640, -0.0169, -0.0447,\n",
       "                      -0.0651, -0.0284,  0.0526, -0.1782, -0.0136, -0.0813,  0.1702,\n",
       "                       0.0654, -0.0515, -0.1942,  0.0268, -0.0172,  0.1493,  0.0371,\n",
       "                      -0.0558,  0.1171,  0.0083,  0.0911,  0.0352, -0.0018,  0.0244,\n",
       "                       0.0007,  0.0024, -0.0461, -0.1555,  0.1457,  0.1309,  0.0760,\n",
       "                       0.0496, -0.1175,  0.0793,  0.1834,  0.0141,  0.0350, -0.1533,\n",
       "                       0.2839, -0.0313,  0.0278,  0.2234,  0.2238,  0.0276, -0.0174,\n",
       "                       0.0662, -0.0142,  0.0345,  0.2238, -0.0809, -0.1098, -0.0535,\n",
       "                      -0.1319,  0.0029,  0.4623, -0.0958, -0.0409,  0.1214,  0.0506,\n",
       "                      -0.0204, -0.0094,  0.0157, -0.1331, -0.0233, -0.0479, -0.0812,\n",
       "                      -0.0336,  0.0161,  0.0737, -0.0498, -0.0080, -0.0084, -0.1142,\n",
       "                       0.0032, -0.1320, -0.0525,  0.0023, -0.0826,  0.0292,  0.0001,\n",
       "                      -0.0808,  0.0857, -0.0301,  0.0331, -0.0532,  0.0091,  0.0295,\n",
       "                      -0.0252, -0.0123, -0.1798, -0.0370, -0.0138, -0.2496,  0.0050,\n",
       "                      -0.0374,  0.1530,  0.0699,  0.0385, -0.1542,  0.1013,  0.0886,\n",
       "                      -0.0521, -0.0341,  0.1334, -0.0063,  0.0552, -0.0345,  0.0055,\n",
       "                       0.0019,  0.1038, -0.0460, -0.0741,  0.0307,  0.1053, -0.1386,\n",
       "                      -0.0012, -0.0004,  0.0091, -0.0463,  0.0007, -0.0027,  0.0898,\n",
       "                      -0.0275, -0.0902, -0.0590,  0.2123, -0.0449,  0.0204, -0.0439,\n",
       "                       0.0093,  0.0736, -0.0877,  0.0089, -0.0189, -0.2163,  0.0932,\n",
       "                      -0.1309, -0.1849, -0.0374,  0.0549,  0.0202,  0.0207, -0.0201,\n",
       "                       0.1427, -0.0005,  0.0011,  0.0907, -0.1240, -0.0347, -0.0311,\n",
       "                       0.2447, -0.1294, -0.0341, -0.0290,  0.0650,  0.0386,  0.1180,\n",
       "                      -0.0080, -0.0938,  0.0685,  0.0218,  0.1570,  0.0023, -0.0906,\n",
       "                       0.0220,  0.0108,  0.0018,  0.3180, -0.0191, -0.0656,  0.0077,\n",
       "                      -0.1035, -0.0039, -0.0089, -0.0134,  0.0423,  0.1142,  0.2836,\n",
       "                      -0.0731,  0.0401,  0.1255,  0.0092, -0.1290, -0.1549, -0.0399,\n",
       "                      -0.0993, -0.0892,  0.0836, -0.0419,  0.0698,  0.1228, -0.0850,\n",
       "                      -0.0666,  0.0706, -0.1437,  0.0584,  0.0521, -0.0898, -0.1134,\n",
       "                      -0.0190,  0.0326, -0.0613,  0.1654,  0.0813, -0.1915, -0.0170,\n",
       "                      -0.0064,  0.0400,  0.1559, -0.1144,  0.1371,  0.0316,  0.1047,\n",
       "                       0.0023,  0.1965, -0.0222, -0.0143,  0.1055, -0.0871, -0.0868,\n",
       "                      -0.0680, -0.1811,  0.0480, -0.0421, -0.1110,  0.2643, -0.0150,\n",
       "                       0.0288,  0.1379, -0.0422,  0.0389,  0.1736, -0.0566, -0.0704,\n",
       "                       0.0861,  0.0840, -0.0908, -0.0509, -0.0566, -0.0325, -0.0419,\n",
       "                      -0.0238,  0.1737, -0.0568, -0.0401,  0.0447,  0.0058,  0.1187,\n",
       "                      -0.0994,  0.1013, -0.0344,  0.0326, -0.0702, -0.0829,  0.0425,\n",
       "                       0.0499, -0.1291, -0.1075, -0.0537,  0.0209,  0.0290,  0.0129,\n",
       "                      -0.0086,  0.1135,  0.0519,  0.0747,  0.0487,  0.1110, -0.0563,\n",
       "                       0.2042, -0.0524,  0.2102,  0.0776,  0.0687, -0.0497, -0.0107,\n",
       "                      -0.0695,  0.2056, -0.0438,  0.0638, -0.1543, -0.0404,  0.0252,\n",
       "                      -0.0829, -0.0116, -0.0720,  0.1758, -0.0359,  0.0379, -0.0053,\n",
       "                       0.0453, -0.0654, -0.1145,  0.2153, -0.0232,  0.0093,  0.0255,\n",
       "                      -0.0140, -0.1671, -0.0871,  0.1042,  0.3070, -0.0999, -0.0885,\n",
       "                      -0.0137, -0.0123, -0.0393, -0.0287, -0.0773,  0.0182, -0.0693,\n",
       "                       0.0288, -0.0685,  0.0512, -0.0695,  0.0120, -0.0426, -0.0758,\n",
       "                      -0.1770, -0.0580, -0.1464,  0.0437,  0.0038, -0.0768, -0.0825,\n",
       "                      -0.0007,  0.1158,  0.0252, -0.1745,  0.1390,  0.1121, -0.1319,\n",
       "                       0.0663,  0.0061, -0.0746, -0.0029, -0.0711,  0.0253, -0.0532,\n",
       "                      -0.0308, -0.0724,  0.4190, -0.0721,  0.0381,  0.2175, -0.0210,\n",
       "                      -0.0028, -0.0969,  0.0020, -0.0906,  0.0692, -0.0837, -0.0485,\n",
       "                      -0.0114], device='cuda:0')),\n",
       "             ('features.19.weight',\n",
       "              tensor([[[[-2.5535e-03, -1.1158e-02, -8.2769e-03],\n",
       "                        [ 7.9291e-03, -3.0797e-03, -1.7211e-02],\n",
       "                        [ 2.1517e-02, -6.8554e-03, -2.0203e-02]],\n",
       "              \n",
       "                       [[ 1.7328e-02,  1.3599e-02,  2.5407e-02],\n",
       "                        [ 5.3267e-03,  1.1174e-02,  7.7055e-03],\n",
       "                        [ 2.3977e-02,  2.4697e-02,  1.7318e-02]],\n",
       "              \n",
       "                       [[-1.0630e-02, -2.0177e-02, -2.8308e-02],\n",
       "                        [ 2.3042e-02,  1.2405e-02, -1.9934e-02],\n",
       "                        [ 1.9213e-02, -1.2397e-02, -3.3434e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.6772e-02, -1.8914e-02, -3.7924e-02],\n",
       "                        [-2.5502e-02, -3.1720e-02, -2.6252e-02],\n",
       "                        [-2.4845e-02, -1.8907e-02, -1.9230e-02]],\n",
       "              \n",
       "                       [[-1.1758e-02, -2.0107e-02, -1.0928e-02],\n",
       "                        [-4.7293e-03,  1.3684e-03, -4.3430e-03],\n",
       "                        [ 1.3007e-02,  1.9641e-03, -4.9493e-03]],\n",
       "              \n",
       "                       [[-1.1713e-02, -1.2694e-04,  8.5288e-04],\n",
       "                        [-4.5545e-04,  1.5829e-02,  1.3876e-02],\n",
       "                        [-1.1323e-02,  2.0346e-02,  6.9136e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.9240e-03, -1.9465e-02, -1.7367e-02],\n",
       "                        [ 5.8091e-04,  3.8840e-03,  2.4610e-02],\n",
       "                        [-1.8340e-02,  1.6218e-02,  2.9450e-02]],\n",
       "              \n",
       "                       [[ 3.4527e-03, -1.0844e-02, -3.3924e-03],\n",
       "                        [ 1.0002e-02, -1.9492e-03,  1.1047e-02],\n",
       "                        [ 3.6633e-03,  6.9817e-03,  1.9736e-02]],\n",
       "              \n",
       "                       [[-3.8001e-02, -1.4251e-02,  2.6339e-03],\n",
       "                        [-3.6224e-02,  2.2680e-02,  3.3290e-02],\n",
       "                        [-1.0769e-02,  1.2441e-02, -4.9949e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.9896e-03, -6.4058e-03, -2.4101e-02],\n",
       "                        [ 1.2791e-02, -2.0637e-02, -2.6050e-02],\n",
       "                        [-2.7292e-03, -1.5665e-02, -4.9022e-03]],\n",
       "              \n",
       "                       [[ 2.3085e-02,  9.5574e-03, -7.8941e-03],\n",
       "                        [ 7.1988e-03, -8.5825e-03, -3.2298e-03],\n",
       "                        [-2.0175e-02, -9.5496e-03, -4.6666e-03]],\n",
       "              \n",
       "                       [[-2.0695e-02,  8.8610e-03,  5.2169e-03],\n",
       "                        [-5.8898e-03,  1.4058e-02,  5.3525e-03],\n",
       "                        [-1.4002e-02, -1.2316e-03,  7.7627e-05]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.8429e-03,  2.7116e-03,  2.3624e-02],\n",
       "                        [-4.1978e-03, -9.0837e-03,  2.5292e-03],\n",
       "                        [ 1.2860e-02,  6.1783e-03,  1.3395e-02]],\n",
       "              \n",
       "                       [[ 2.6529e-02,  1.9222e-02,  1.7867e-02],\n",
       "                        [ 8.9680e-03,  1.4672e-02, -7.2351e-04],\n",
       "                        [-1.3411e-02, -3.4650e-03, -6.1179e-03]],\n",
       "              \n",
       "                       [[ 1.7954e-02, -6.7881e-03,  3.9998e-03],\n",
       "                        [ 1.2262e-02,  4.4036e-03,  5.8230e-03],\n",
       "                        [ 8.0924e-03,  9.9460e-03,  1.5369e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.3355e-02, -4.9726e-03, -2.5974e-02],\n",
       "                        [ 1.8754e-02,  1.0445e-02, -4.4697e-04],\n",
       "                        [-1.1814e-02, -6.5553e-03, -2.6682e-03]],\n",
       "              \n",
       "                       [[-2.2084e-02, -9.9309e-03, -1.2186e-02],\n",
       "                        [-8.3404e-03, -8.9806e-03, -5.7598e-03],\n",
       "                        [-3.5855e-03, -4.3484e-03, -4.0049e-03]],\n",
       "              \n",
       "                       [[-1.0454e-03,  1.1157e-02,  1.2471e-02],\n",
       "                        [-2.7479e-04,  3.7508e-03,  1.3845e-02],\n",
       "                        [ 2.7957e-03, -1.5454e-03,  1.0712e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.6992e-02, -2.6317e-03, -7.9817e-03],\n",
       "                        [ 2.4494e-03,  2.6524e-02,  1.9120e-02],\n",
       "                        [ 1.5663e-02,  3.9729e-02,  4.4346e-02]],\n",
       "              \n",
       "                       [[ 1.5429e-02,  9.7136e-03,  1.5909e-02],\n",
       "                        [-1.8311e-02,  6.4525e-03,  1.9531e-02],\n",
       "                        [-1.6276e-02, -8.5435e-03, -2.8023e-03]],\n",
       "              \n",
       "                       [[-1.1841e-02, -1.3319e-02, -2.5728e-02],\n",
       "                        [-7.2776e-03, -1.2659e-02, -1.2658e-02],\n",
       "                        [-3.5886e-03, -3.3302e-03,  3.1721e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.8700e-04, -1.0890e-03, -8.2800e-03],\n",
       "                        [-1.0539e-02, -1.0870e-02, -1.2052e-02],\n",
       "                        [-2.7241e-02, -2.3530e-02, -9.9151e-03]],\n",
       "              \n",
       "                       [[ 7.9957e-03,  3.4473e-03,  2.3797e-02],\n",
       "                        [-1.9361e-02, -1.4075e-02, -7.2387e-03],\n",
       "                        [-3.0355e-02, -2.7729e-02, -7.0975e-03]],\n",
       "              \n",
       "                       [[ 1.6241e-02,  5.0342e-03, -5.4142e-03],\n",
       "                        [-8.1496e-03, -5.3835e-03, -1.0105e-02],\n",
       "                        [-1.8767e-02, -9.4346e-03, -1.6970e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2802e-03, -8.8761e-03, -2.2022e-02],\n",
       "                        [ 1.7355e-02,  1.4267e-02, -5.1140e-03],\n",
       "                        [ 8.5410e-03, -1.5400e-04,  3.2840e-03]],\n",
       "              \n",
       "                       [[-3.5262e-03, -1.5919e-02,  2.0676e-02],\n",
       "                        [-2.5445e-03,  1.6820e-03,  1.6177e-02],\n",
       "                        [-3.4168e-03, -6.6551e-03, -7.9188e-03]],\n",
       "              \n",
       "                       [[ 3.0259e-02,  2.8690e-02,  3.0252e-02],\n",
       "                        [-1.8220e-02, -9.3668e-03,  2.9770e-02],\n",
       "                        [-2.1978e-02, -4.9280e-03,  2.1961e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.8668e-02, -1.5138e-02,  8.6974e-03],\n",
       "                        [-1.4765e-02, -2.3513e-02,  1.1347e-03],\n",
       "                        [-1.4733e-02, -3.1786e-02, -2.6354e-03]],\n",
       "              \n",
       "                       [[ 1.5800e-02,  1.3073e-02,  3.2280e-02],\n",
       "                        [ 1.2601e-02,  1.1681e-02,  1.1965e-02],\n",
       "                        [ 3.5136e-03,  4.3679e-03, -2.2507e-03]],\n",
       "              \n",
       "                       [[ 2.8722e-04,  4.1636e-03,  1.7368e-02],\n",
       "                        [-1.7108e-02,  3.4045e-03,  3.0699e-02],\n",
       "                        [-2.1262e-02, -2.2950e-02,  1.6036e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1554e-03, -4.7330e-04,  9.6674e-03],\n",
       "                        [ 1.3853e-04, -9.1627e-03, -1.6065e-03],\n",
       "                        [-1.4993e-03, -8.4020e-03,  1.5302e-02]],\n",
       "              \n",
       "                       [[ 1.3718e-02,  1.3465e-02,  1.9703e-02],\n",
       "                        [ 9.3828e-03,  4.3403e-02,  4.0656e-02],\n",
       "                        [-1.7159e-02,  8.0563e-03,  3.4450e-03]],\n",
       "              \n",
       "                       [[-1.5223e-03,  3.1755e-02,  2.9220e-02],\n",
       "                        [ 1.0546e-02,  1.4674e-02,  2.5458e-03],\n",
       "                        [-5.4571e-03, -8.4497e-03, -6.3715e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.9381e-04, -2.2163e-03,  2.0394e-02],\n",
       "                        [-1.3424e-02, -1.4380e-02,  2.3028e-02],\n",
       "                        [-1.1290e-02, -1.5281e-02, -9.1222e-03]],\n",
       "              \n",
       "                       [[ 1.4791e-02,  2.7121e-02,  1.8470e-02],\n",
       "                        [-1.2051e-02,  4.4541e-03,  6.4978e-04],\n",
       "                        [-7.1708e-03, -1.5393e-02, -1.3675e-02]],\n",
       "              \n",
       "                       [[ 2.5665e-02,  2.3979e-02,  1.5356e-02],\n",
       "                        [-2.4473e-03, -8.8645e-03, -5.5669e-03],\n",
       "                        [-2.3476e-02, -1.9197e-02, -2.3337e-03]]]], device='cuda:0')),\n",
       "             ('features.19.bias',\n",
       "              tensor([-0.1175,  0.0094,  0.1134,  0.0125, -0.0803, -0.0382,  0.0259,\n",
       "                       0.0171, -0.0324, -0.0172,  0.0369,  0.0561, -0.0368, -0.0737,\n",
       "                      -0.0237,  0.0709,  0.1388,  0.0084,  0.1003,  0.1162,  0.0957,\n",
       "                      -0.1529, -0.0825,  0.0754,  0.0436,  0.0353, -0.0518,  0.0551,\n",
       "                       0.1000, -1.2884,  0.0005,  0.0499,  0.0632,  0.1029,  0.2318,\n",
       "                       0.0082,  0.0276,  0.0834,  0.1277,  0.1392,  0.1457,  0.0293,\n",
       "                      -0.1384,  0.0256, -0.0696, -0.1361,  0.0314,  0.0988,  0.0827,\n",
       "                       0.0843,  0.1356,  0.0506,  0.0125,  0.1500, -0.0676,  0.0430,\n",
       "                      -0.0018,  0.1661, -0.0913,  0.0787,  0.0876,  0.0103, -0.1740,\n",
       "                       0.1030,  0.1930,  0.0547, -0.0296,  0.0282,  0.2408,  0.1087,\n",
       "                       0.0529,  0.0791,  0.0887,  0.0109, -0.0518, -0.0373,  0.2698,\n",
       "                       0.0031,  0.0028,  0.2060, -0.0026,  0.0001, -0.2292,  0.2276,\n",
       "                       0.0333, -0.1087,  0.0688, -0.0336,  0.0854, -0.0222,  0.1329,\n",
       "                      -0.0150, -0.2161, -0.0516,  0.2946, -0.0588, -0.0118, -0.0378,\n",
       "                       0.0428,  0.0495,  0.1966, -0.1946,  0.0510, -0.0239,  0.0595,\n",
       "                      -0.0943,  0.1252,  0.0589, -0.0386,  0.0060, -0.0011,  0.0945,\n",
       "                       0.0550,  0.3310,  0.1038,  0.0075,  0.1017, -0.0465,  0.1713,\n",
       "                       0.1649,  0.1748, -0.0037,  0.0833,  0.1224,  0.0132,  0.0604,\n",
       "                       0.1321, -0.2861,  0.2137, -0.0450,  0.0765,  0.0403, -0.0550,\n",
       "                       0.2746,  0.0881,  0.0444,  0.1390,  0.0306,  0.0218,  0.0169,\n",
       "                       0.0153,  0.2283, -0.0362, -0.0301,  0.0354,  0.0222,  0.2243,\n",
       "                      -0.0309,  0.0813,  0.0974,  0.0829,  0.0104,  0.0976,  0.0478,\n",
       "                      -0.2354,  0.0926,  0.0517, -0.0995,  0.0578,  0.1031,  0.0917,\n",
       "                       0.0130,  0.0368,  0.1125,  0.0194, -0.1169,  0.3920, -0.0636,\n",
       "                       0.1151, -0.1598,  0.1292,  0.1757,  0.0122, -0.0578,  0.1786,\n",
       "                       0.0873,  0.1908,  0.0377,  0.0286,  0.0595, -0.2116,  0.0342,\n",
       "                      -0.0106,  0.0256,  0.1047, -0.0556, -0.0205,  0.0696,  0.1812,\n",
       "                      -0.0062, -0.0978, -0.0220, -0.0031,  0.0625,  0.0117, -0.0035,\n",
       "                       0.0426,  0.0939,  0.1254,  0.0416,  0.0763,  0.1214, -0.0556,\n",
       "                       0.1338,  0.1027,  0.1045,  0.0240,  0.1402, -0.0399,  0.0320,\n",
       "                       0.1205,  0.0154,  0.0745, -0.1932,  0.0618, -0.0738, -0.0252,\n",
       "                       0.1500,  0.1453, -0.8463,  0.0871,  0.1082,  0.0351,  0.0851,\n",
       "                      -0.1222,  0.1283,  0.1561, -0.0376,  0.0802,  0.1645,  0.1225,\n",
       "                      -0.0007,  0.0829, -0.0392, -0.1353,  0.0026, -0.1342,  0.1764,\n",
       "                       0.0879,  0.0077,  0.0998,  0.0695,  0.1037, -0.0029,  0.2065,\n",
       "                       0.0586,  0.0744,  0.0900, -0.0277, -0.0497, -0.0691,  0.1087,\n",
       "                       0.0262, -0.2021,  0.0474,  0.1237, -0.0055, -0.0040, -0.0300,\n",
       "                       0.1408,  0.1236,  0.0037,  0.2645,  0.1492,  0.0782, -0.4348,\n",
       "                       0.0288,  0.0548, -0.1236, -0.3035,  0.1121,  0.0714,  0.0026,\n",
       "                       0.0977, -0.0208,  0.0769,  0.0481, -0.0350,  0.1597,  0.0685,\n",
       "                       0.0732,  0.0782,  0.0255,  0.1369, -0.0098,  0.1085, -0.0762,\n",
       "                       0.0008,  0.2038, -0.0995, -0.0935,  0.0957, -0.0069, -0.1097,\n",
       "                       0.0869,  0.0365,  0.3351,  0.1218,  0.1820, -0.0968, -0.1149,\n",
       "                       0.1291,  0.0323,  0.1191,  0.0345,  0.1901,  0.0730,  0.0390,\n",
       "                      -0.1051, -0.0098, -0.1511, -0.0897,  0.3769,  0.0572,  0.0099,\n",
       "                       0.0754,  0.0159, -0.0235,  0.0162,  0.0302,  0.1417, -0.0459,\n",
       "                      -0.0325,  0.0244, -0.0517,  0.0081,  0.1405,  0.1474,  0.0670,\n",
       "                      -0.0064, -0.0772,  0.0621,  0.1373, -0.3657,  0.2221,  0.0537,\n",
       "                       0.0523,  0.0209,  0.0630,  0.2204, -0.0459,  0.1165, -0.0645,\n",
       "                       0.1186,  0.1032,  0.0731,  0.1617,  0.1009,  0.0950,  0.0237,\n",
       "                       0.0475,  0.2697,  0.0307,  0.1056,  0.0655,  0.2152, -0.2640,\n",
       "                       0.0519,  0.0434,  0.0314,  0.0788, -0.2150, -0.0310, -0.1820,\n",
       "                      -0.1306,  0.1998,  0.0949,  0.0295,  0.0127,  0.0385,  0.0602,\n",
       "                       0.1481,  0.1604,  0.0625,  0.1562,  0.0425, -0.1852,  0.0370,\n",
       "                       0.0328,  0.0150, -0.1801,  0.1791,  0.1716, -0.0123,  0.1497,\n",
       "                       0.0497,  0.0592,  0.1180, -0.0058,  0.1404, -0.3370,  0.0911,\n",
       "                      -0.0128,  0.1255,  0.1442,  0.1249, -0.0138,  0.0796, -0.1847,\n",
       "                       0.0353,  0.0482,  0.0731,  0.1030,  0.0461,  0.1120, -0.0092,\n",
       "                      -0.0940, -0.1132,  0.2123,  0.1031,  0.0948,  0.0531,  0.0422,\n",
       "                       0.0430, -0.0440, -0.0251, -0.0560,  0.0399,  0.0724,  0.1415,\n",
       "                       0.1721,  0.0762,  0.0313,  0.0653, -0.1098, -0.0317,  0.1130,\n",
       "                       0.0283, -0.0332,  0.1774,  0.0935,  0.2208, -0.0174, -0.0158,\n",
       "                       0.0298, -0.0103,  0.0282,  0.0418,  0.0531, -0.1486,  0.0533,\n",
       "                       0.0319,  0.1954,  0.0080,  0.0015,  0.1295,  0.1353,  0.1536,\n",
       "                       0.0973,  0.0861, -0.1114, -0.0179,  0.0093,  0.1629,  0.4944,\n",
       "                      -0.1407,  0.0611, -0.0125, -0.0961,  0.0032,  0.0426, -0.0680,\n",
       "                      -0.0239,  0.0167,  0.0074, -0.0545, -0.1713,  0.0807,  0.1704,\n",
       "                      -0.1621, -0.0266,  0.0745,  0.2471,  0.2026, -0.0197,  0.0505,\n",
       "                       0.1587,  0.0400,  0.1763, -0.3787,  0.1428,  0.1470,  0.1058,\n",
       "                       0.1532,  0.0941,  0.1128, -0.1301,  0.0120, -0.1675,  0.1225,\n",
       "                      -0.0060,  0.0344,  0.0056,  0.1456,  0.0889,  0.1303,  0.0108,\n",
       "                      -0.0406, -0.0198, -0.2134,  0.0059,  0.1476,  0.0012,  0.0731,\n",
       "                       0.0132,  0.1529,  0.1050,  0.1346,  0.0369,  0.1260,  0.1677,\n",
       "                      -0.0021], device='cuda:0')),\n",
       "             ('features.21.weight',\n",
       "              tensor([[[[-3.4618e-02, -3.3801e-02, -2.2497e-02],\n",
       "                        [-3.2275e-02, -2.8543e-02, -1.5026e-02],\n",
       "                        [-3.1307e-02, -1.8263e-02, -1.1662e-02]],\n",
       "              \n",
       "                       [[-6.7787e-03, -5.1631e-03, -1.1498e-02],\n",
       "                        [-3.1353e-03, -9.5856e-03, -1.1940e-02],\n",
       "                        [-1.6923e-02, -1.5893e-02, -9.2058e-03]],\n",
       "              \n",
       "                       [[ 2.1721e-02,  1.6138e-03, -1.2762e-02],\n",
       "                        [ 1.1541e-02,  3.9117e-03, -1.7966e-02],\n",
       "                        [ 8.2566e-03, -7.2988e-03, -1.8711e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.1666e-02,  5.8356e-03,  5.1317e-03],\n",
       "                        [ 2.7172e-02,  3.0096e-02,  2.2107e-02],\n",
       "                        [ 5.0745e-02,  5.0426e-02,  5.2568e-02]],\n",
       "              \n",
       "                       [[ 1.5641e-02,  6.1531e-03,  1.0435e-02],\n",
       "                        [-4.9628e-03, -1.0472e-02, -9.7399e-03],\n",
       "                        [-1.3043e-02, -1.1895e-02, -8.3080e-03]],\n",
       "              \n",
       "                       [[-7.5200e-03, -8.6918e-03, -7.7642e-03],\n",
       "                        [-2.1090e-02, -1.2527e-02, -1.4423e-02],\n",
       "                        [-1.5833e-02, -1.0271e-02, -6.5119e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9262e-02,  2.4535e-02,  9.8333e-03],\n",
       "                        [ 1.3875e-02,  1.1888e-02,  1.5868e-03],\n",
       "                        [ 3.2187e-02,  2.7896e-02,  2.1428e-02]],\n",
       "              \n",
       "                       [[-1.2907e-02, -1.6465e-02, -1.0769e-02],\n",
       "                        [-1.2730e-02, -8.0963e-04, -9.7610e-03],\n",
       "                        [-1.7824e-02, -1.9745e-03, -6.0412e-03]],\n",
       "              \n",
       "                       [[ 7.3908e-03,  1.3782e-03, -2.7653e-03],\n",
       "                        [ 2.2362e-02,  3.1297e-03,  7.8103e-03],\n",
       "                        [-3.6186e-03,  4.7948e-03, -3.9560e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.8102e-03,  6.1981e-04, -9.2120e-04],\n",
       "                        [-2.2606e-03, -2.2002e-02, -3.1097e-03],\n",
       "                        [-9.4541e-03, -2.8003e-02, -2.2712e-02]],\n",
       "              \n",
       "                       [[ 2.0525e-03, -3.4167e-03,  1.0797e-02],\n",
       "                        [ 8.3235e-03, -7.1854e-03,  8.9610e-03],\n",
       "                        [ 1.1586e-02, -4.0099e-03,  1.9634e-02]],\n",
       "              \n",
       "                       [[ 7.4921e-03, -1.0478e-03,  1.5801e-02],\n",
       "                        [ 7.9514e-04, -1.6881e-02, -2.4732e-04],\n",
       "                        [ 1.5973e-02,  1.6192e-02,  3.7039e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3103e-02, -2.4085e-02, -2.1704e-02],\n",
       "                        [ 1.0276e-02, -7.1129e-03,  6.8848e-03],\n",
       "                        [ 8.5694e-03, -1.9288e-03, -2.8843e-03]],\n",
       "              \n",
       "                       [[-1.3841e-02, -1.0492e-02, -2.4102e-02],\n",
       "                        [-2.7612e-02, -2.5791e-02, -1.2960e-02],\n",
       "                        [-1.5598e-03,  3.6200e-04,  2.1741e-02]],\n",
       "              \n",
       "                       [[ 2.7855e-02,  2.6277e-02,  2.2290e-02],\n",
       "                        [ 2.4780e-02,  2.5150e-02,  2.5566e-03],\n",
       "                        [-1.9022e-03,  1.0823e-02, -8.6423e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.3089e-03,  1.8908e-03,  6.9918e-03],\n",
       "                        [-6.9307e-03, -8.7947e-03, -7.2253e-03],\n",
       "                        [-3.5385e-03, -4.9549e-03, -8.7845e-03]],\n",
       "              \n",
       "                       [[ 8.2309e-03,  1.8546e-04, -9.4308e-04],\n",
       "                        [ 2.4796e-04, -1.3734e-03, -6.4844e-03],\n",
       "                        [ 1.0330e-02, -6.3096e-03,  2.9899e-03]],\n",
       "              \n",
       "                       [[-3.2615e-03,  1.1206e-03,  2.0341e-03],\n",
       "                        [ 3.0882e-03, -1.5877e-02, -3.2855e-03],\n",
       "                        [-1.0955e-02, -5.5521e-03, -1.2025e-04]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.7462e-02, -3.8714e-02, -3.6843e-02],\n",
       "                        [-2.3918e-02, -3.9357e-02, -2.3753e-02],\n",
       "                        [-6.3624e-03, -1.7850e-02,  1.0370e-03]],\n",
       "              \n",
       "                       [[ 2.8356e-02,  1.4364e-02,  8.2898e-03],\n",
       "                        [ 1.7873e-02, -1.1615e-03,  5.5851e-03],\n",
       "                        [-1.2643e-03, -8.9554e-03, -3.0568e-03]],\n",
       "              \n",
       "                       [[ 5.1422e-03,  4.6503e-04,  9.0143e-03],\n",
       "                        [ 1.9823e-02,  3.4737e-02,  2.8242e-02],\n",
       "                        [ 3.2088e-02,  2.3840e-02,  2.2072e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.4983e-03,  9.9425e-03,  4.5399e-03],\n",
       "                        [ 1.1027e-02,  4.5929e-03,  2.6449e-03],\n",
       "                        [ 1.7532e-02, -1.0313e-03, -8.3937e-03]],\n",
       "              \n",
       "                       [[-1.0549e-02, -1.0171e-02, -5.7416e-03],\n",
       "                        [-8.2740e-03, -8.3159e-03, -1.4377e-02],\n",
       "                        [-1.1800e-02, -1.1000e-02, -1.6324e-03]],\n",
       "              \n",
       "                       [[-1.3096e-02, -3.1618e-02, -2.5536e-02],\n",
       "                        [-4.8419e-03, -1.3772e-02, -1.3568e-02],\n",
       "                        [-1.5098e-02, -8.9054e-03, -1.2804e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8384e-03, -6.2667e-03, -1.1664e-02],\n",
       "                        [ 3.3901e-03, -1.1676e-02, -6.1101e-03],\n",
       "                        [-1.7972e-02, -3.3468e-02, -9.4137e-03]],\n",
       "              \n",
       "                       [[ 1.0985e-03,  1.3939e-04,  5.5219e-03],\n",
       "                        [-9.3755e-03, -3.6006e-03, -3.1602e-05],\n",
       "                        [-2.7297e-03, -5.7176e-03, -3.4485e-03]],\n",
       "              \n",
       "                       [[ 1.9236e-02,  1.2842e-02,  8.1627e-03],\n",
       "                        [ 1.5062e-02,  4.3942e-04,  1.0795e-03],\n",
       "                        [ 6.7360e-03,  9.0229e-03,  2.8575e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.0815e-03, -4.9577e-03,  1.6272e-03],\n",
       "                        [ 2.0418e-03, -8.2440e-03,  8.4400e-03],\n",
       "                        [ 6.3961e-03, -5.5046e-03,  1.0984e-03]],\n",
       "              \n",
       "                       [[ 9.5378e-04, -1.1439e-02, -3.1516e-03],\n",
       "                        [ 1.0669e-03, -1.8538e-02, -1.2831e-02],\n",
       "                        [ 5.5736e-03, -1.1039e-02, -1.3992e-02]],\n",
       "              \n",
       "                       [[-1.9465e-02, -1.2852e-02, -1.8318e-02],\n",
       "                        [-2.6698e-02, -1.8011e-02, -1.0662e-02],\n",
       "                        [-1.6479e-02, -1.4482e-02, -1.6194e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3728e-02, -3.6695e-02, -3.7500e-02],\n",
       "                        [-1.3462e-03, -3.9573e-04,  3.2643e-03],\n",
       "                        [ 1.5174e-02,  2.6909e-02,  1.3840e-02]],\n",
       "              \n",
       "                       [[ 2.8536e-04, -1.5611e-02, -6.2689e-03],\n",
       "                        [-4.9708e-04, -2.2292e-02, -2.0291e-02],\n",
       "                        [ 1.2825e-02, -1.6755e-02, -2.1885e-02]],\n",
       "              \n",
       "                       [[ 8.5642e-03,  6.9444e-03,  9.6820e-03],\n",
       "                        [ 3.2590e-03,  1.7821e-02,  7.3303e-03],\n",
       "                        [ 1.2386e-02,  2.1082e-02, -7.5897e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.6673e-03,  1.3758e-02,  1.1945e-02],\n",
       "                        [ 8.6567e-03,  1.0310e-02, -1.6190e-03],\n",
       "                        [ 1.7062e-02, -6.1529e-03, -4.0647e-03]],\n",
       "              \n",
       "                       [[ 1.5687e-02,  3.6550e-03, -1.1310e-02],\n",
       "                        [-1.4527e-04,  8.9713e-04,  2.0525e-03],\n",
       "                        [-1.0805e-02, -5.5566e-03,  8.8173e-03]],\n",
       "              \n",
       "                       [[-1.4262e-02, -1.7638e-02, -6.3932e-03],\n",
       "                        [-2.4702e-03, -1.2362e-02, -2.2834e-02],\n",
       "                        [-4.4622e-03, -9.5870e-03, -1.7204e-02]]]], device='cuda:0')),\n",
       "             ('features.21.bias',\n",
       "              tensor([ 0.0531,  0.0105,  0.2303,  0.0376,  0.0864, -0.0534,  0.1386,\n",
       "                      -0.0711, -0.0416, -0.0604,  0.0287,  0.0399,  0.0245, -0.0292,\n",
       "                       0.0225,  0.1570,  0.1507, -0.0347, -0.0293,  0.1687, -0.0789,\n",
       "                       0.1566,  0.0693,  0.2194,  0.0086,  0.0442,  0.0058,  0.3205,\n",
       "                       0.2137,  0.0207, -0.2106,  0.2345, -0.0005,  0.1282,  0.0277,\n",
       "                       0.0138, -0.0825,  0.1166,  0.0014, -0.0693, -0.0425, -0.0487,\n",
       "                       0.1516,  0.0452,  0.0955,  0.0992, -0.0496,  0.1038, -0.1906,\n",
       "                      -0.0068,  0.1283, -0.1541, -0.0829,  0.1284,  0.1052, -0.0035,\n",
       "                      -0.0241,  0.2739,  0.0825,  0.0261,  0.1039,  0.1287,  0.0119,\n",
       "                       0.3224,  0.0775,  0.1568, -0.0945,  0.0659,  0.1161,  0.0299,\n",
       "                       0.0450,  0.0668, -0.0039,  0.0456, -0.0608, -0.0790,  0.1897,\n",
       "                       0.0972,  0.0289,  0.0525,  0.0895, -0.0102, -0.0332,  0.0325,\n",
       "                       0.1745,  0.0541,  0.0355, -0.0600,  0.1099,  0.0416,  0.1017,\n",
       "                      -0.0139, -0.0222, -0.0237, -0.0207, -0.0741,  0.0711,  0.2893,\n",
       "                       0.0574,  0.2700,  0.1369,  0.1286,  0.0978, -0.0340, -0.6077,\n",
       "                       0.1329,  0.0761,  0.0018,  0.0380,  0.0313,  0.2315,  0.1725,\n",
       "                       0.0792,  0.0207,  0.0464,  0.0117,  0.1760,  0.0087,  0.1473,\n",
       "                      -0.1698,  0.0589,  0.0046, -0.0251, -0.0101,  0.1724,  0.0505,\n",
       "                       0.0031,  0.1954,  0.2301,  0.0149,  0.0068,  0.0644,  0.2830,\n",
       "                      -0.0198, -0.0664, -0.1797,  0.1152,  0.1811,  0.0678,  0.1453,\n",
       "                       0.0957, -0.0481,  0.1757,  0.0206,  0.2045,  0.1045,  0.0028,\n",
       "                      -0.0672,  0.1161,  0.3238, -0.0256, -0.1008, -0.2748, -0.0438,\n",
       "                       0.1021, -0.0407,  0.1424,  0.0496,  0.0136, -0.0690, -0.1560,\n",
       "                      -0.0568,  0.2196, -0.0390,  0.0767,  0.1783,  0.0358, -0.1654,\n",
       "                       0.1065,  0.1269,  0.0808,  0.0354,  0.0763,  0.1835, -0.0320,\n",
       "                       0.1095, -0.0778, -0.0183,  0.0020, -0.0535,  0.0680,  0.1305,\n",
       "                       0.0555, -0.2269, -0.1751, -0.0232, -0.0801,  0.2421, -0.0937,\n",
       "                      -0.0280, -0.0400, -0.0009, -0.1328,  0.0166, -0.1790,  0.0023,\n",
       "                       0.0741,  0.0747, -0.0539,  0.0035,  0.0680, -0.0176, -0.0763,\n",
       "                      -0.0302, -0.0200,  0.0770,  0.0666,  0.0758,  0.2027,  0.0827,\n",
       "                       0.1819,  0.1586, -0.0280,  0.1225,  0.1627,  0.0706,  0.0363,\n",
       "                       0.0752,  0.0401,  0.1746,  0.1306, -0.2315, -0.0406, -0.0921,\n",
       "                       0.0478,  0.0589, -0.0492,  0.2356,  0.0568,  0.0026,  0.1820,\n",
       "                       0.2443,  0.1594,  0.1236,  0.0209,  0.2230, -0.0873,  0.0022,\n",
       "                       0.0561,  0.0531,  0.2514, -0.0257, -0.0580,  0.1213, -0.0693,\n",
       "                       0.1710,  0.0805, -0.0210,  0.1575,  0.1350,  0.0355,  0.0195,\n",
       "                      -0.1059, -0.0116,  0.0732,  0.0615,  0.0976,  0.1233,  0.0796,\n",
       "                      -0.0159,  0.0833,  0.1111,  0.0524,  0.1598,  0.0455,  0.1383,\n",
       "                       0.0231, -0.1387,  0.0309, -0.0193,  0.0108,  0.0274,  0.1521,\n",
       "                      -0.0211,  0.2260, -0.0024, -0.0452, -0.0537,  0.0651, -0.0881,\n",
       "                      -0.0690,  0.1569,  0.0352,  0.0140,  0.0782, -0.0071,  0.0709,\n",
       "                      -0.0203, -0.0436,  0.0826,  0.1036,  0.2404,  0.0015,  0.1374,\n",
       "                       0.1029,  0.0496,  0.0604,  0.0221,  0.0415,  0.1796,  0.0898,\n",
       "                       0.0638,  0.0440,  0.0259,  0.2675, -0.0870,  0.0421,  0.0453,\n",
       "                      -0.0067,  0.1259,  0.1073,  0.0143,  0.0513,  0.0038,  0.0115,\n",
       "                      -0.0149, -0.0137,  0.1470,  0.0928,  0.1292,  0.1747,  0.0586,\n",
       "                       0.1164,  0.0589, -0.1453,  0.0161,  0.0569, -0.0434,  0.0208,\n",
       "                      -0.0399,  0.0004,  0.1687,  0.1744,  0.1169, -0.0012,  0.0006,\n",
       "                       0.1021, -0.0269, -0.1538,  0.0186,  0.1452,  0.1372,  0.1606,\n",
       "                       0.1019,  0.1579,  0.0534, -0.0097,  0.1066, -0.0322,  0.1646,\n",
       "                      -0.0328,  0.0941,  0.1605,  0.0336,  0.0826,  0.0122,  0.1848,\n",
       "                      -0.1592,  0.1108,  0.0433,  0.0936, -0.0053,  0.1572,  0.1766,\n",
       "                       0.1577, -0.0654,  0.0415,  0.0557, -0.0503,  0.0491,  0.0514,\n",
       "                       0.0956,  0.0293,  0.0708,  0.2348,  0.1323, -0.0236, -0.1206,\n",
       "                       0.0262,  0.0475, -0.0230,  0.0166,  0.0795,  0.3515,  0.2149,\n",
       "                       0.0321,  0.0192,  0.2616,  0.0606, -0.0275,  0.3869,  0.2609,\n",
       "                      -0.0169,  0.0398, -0.1164, -0.1109, -0.2639, -0.0555,  0.2381,\n",
       "                       0.0415, -0.0678,  0.0745,  0.1641,  0.0418,  0.0140, -0.0896,\n",
       "                       0.0408, -0.0064,  0.1655,  0.0329, -0.1069,  0.2143, -0.0005,\n",
       "                      -0.0480,  0.1501,  0.0254, -0.0660, -0.0036, -0.0152, -0.1523,\n",
       "                       0.2688,  0.1443,  0.0876,  0.1490,  0.0454,  0.0689,  0.0644,\n",
       "                       0.3103,  0.0494, -0.0095, -0.0174, -0.1004,  0.0859,  0.0211,\n",
       "                      -0.0534, -0.0280, -0.0325,  0.0088,  0.0579,  0.0665,  0.0055,\n",
       "                       0.1629,  0.0017,  0.3363, -0.0403,  0.0420,  0.1757,  0.0060,\n",
       "                       0.0615,  0.0105,  0.0135,  0.0657,  0.0719,  0.0495,  0.3030,\n",
       "                      -0.0483,  0.1513,  0.1007,  0.0229,  0.2647,  0.0939,  0.0683,\n",
       "                       0.2115,  0.0348,  0.1983,  0.0935,  0.0410,  0.2048,  0.0246,\n",
       "                      -0.0159, -0.0792,  0.0171,  0.0702,  0.0515,  0.0283, -0.0039,\n",
       "                      -0.1008,  0.1317,  0.1721,  0.1268,  0.1230,  0.0962,  0.1443,\n",
       "                      -0.0295,  0.1243, -0.1890,  0.0045,  0.0670, -0.0481,  0.0660,\n",
       "                      -0.1932,  0.2272,  0.0570,  0.0516,  0.0601,  0.0613,  0.1081,\n",
       "                       0.0370,  0.0835,  0.0234,  0.0492,  0.0158,  0.0113,  0.1855,\n",
       "                       0.1112,  0.0091, -0.0176,  0.1561, -0.0391,  0.0127, -0.0557,\n",
       "                       0.0826], device='cuda:0')),\n",
       "             ('features.24.weight',\n",
       "              tensor([[[[-2.9665e-02, -1.8004e-02, -2.0759e-02],\n",
       "                        [-2.3392e-02, -8.0310e-03, -1.2426e-02],\n",
       "                        [-1.7737e-02, -1.7743e-02, -2.7021e-02]],\n",
       "              \n",
       "                       [[-2.1687e-02, -2.5525e-02, -6.7156e-03],\n",
       "                        [-1.3061e-02, -1.7542e-02, -1.5949e-02],\n",
       "                        [-2.4782e-02, -1.0104e-02, -4.9635e-03]],\n",
       "              \n",
       "                       [[-4.2964e-03, -3.6401e-03, -6.3512e-03],\n",
       "                        [ 1.0383e-02,  2.3713e-02,  1.4648e-02],\n",
       "                        [-9.3529e-03, -1.2316e-03, -8.4364e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.5568e-02,  3.8466e-02,  2.1158e-02],\n",
       "                        [ 4.5726e-02,  5.0937e-02,  3.1546e-02],\n",
       "                        [ 3.8903e-02,  4.3654e-02,  3.7143e-02]],\n",
       "              \n",
       "                       [[ 2.6901e-02,  1.0798e-02,  1.9648e-02],\n",
       "                        [ 2.8889e-03, -8.7730e-03,  1.4934e-02],\n",
       "                        [ 4.2627e-03, -8.3357e-03,  2.3783e-02]],\n",
       "              \n",
       "                       [[ 1.5674e-02,  1.1260e-02,  1.9177e-02],\n",
       "                        [ 2.7215e-02,  9.9037e-03,  2.5009e-02],\n",
       "                        [ 9.9336e-03,  7.7196e-03, -1.3929e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3820e-02, -2.3844e-02, -3.2966e-04],\n",
       "                        [-1.2515e-02, -1.1827e-02,  2.5957e-03],\n",
       "                        [ 5.6352e-04, -4.4090e-03,  9.8300e-03]],\n",
       "              \n",
       "                       [[ 9.0568e-03,  9.2629e-03,  1.4934e-02],\n",
       "                        [ 2.8985e-03,  1.8503e-02,  1.6307e-02],\n",
       "                        [-1.4100e-02,  2.3823e-03, -1.1177e-02]],\n",
       "              \n",
       "                       [[-1.1710e-02, -1.2035e-02, -9.6249e-03],\n",
       "                        [ 3.7106e-03,  1.3383e-02,  1.1210e-02],\n",
       "                        [ 2.5377e-04,  9.5491e-04,  2.6870e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3927e-03, -3.7516e-04,  3.2514e-03],\n",
       "                        [ 2.4906e-02,  2.3891e-02,  1.4050e-03],\n",
       "                        [ 2.8756e-02,  2.8597e-02,  6.6499e-03]],\n",
       "              \n",
       "                       [[-5.6646e-03,  1.5783e-02,  4.7909e-03],\n",
       "                        [-1.4084e-02,  8.0757e-03, -2.0989e-03],\n",
       "                        [-6.8815e-03, -1.7941e-03, -1.1487e-02]],\n",
       "              \n",
       "                       [[ 3.2968e-02,  5.8415e-02,  8.3329e-03],\n",
       "                        [ 1.0411e-02,  3.5860e-02,  8.3363e-03],\n",
       "                        [-1.5696e-02, -1.5042e-02,  1.7315e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1141e-02,  1.5798e-02,  1.6444e-02],\n",
       "                        [ 1.4905e-02,  6.3904e-03,  2.6291e-03],\n",
       "                        [ 3.3458e-02,  1.3344e-02,  1.3005e-02]],\n",
       "              \n",
       "                       [[ 1.1242e-02,  8.7495e-03,  2.7007e-03],\n",
       "                        [ 2.2816e-02,  1.4478e-02,  4.8603e-03],\n",
       "                        [-3.7791e-04, -4.8188e-03, -1.1555e-02]],\n",
       "              \n",
       "                       [[-2.8469e-02, -2.9225e-02, -3.5925e-02],\n",
       "                        [-2.3655e-02, -1.7323e-02, -2.4310e-02],\n",
       "                        [-2.7181e-02, -2.8016e-02, -2.4610e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-9.0945e-03, -1.1648e-02, -1.8368e-03],\n",
       "                        [-9.1741e-03, -1.1730e-02, -5.2244e-03],\n",
       "                        [-3.2614e-04, -3.2733e-03, -1.5314e-02]],\n",
       "              \n",
       "                       [[-5.3404e-03,  3.1406e-03, -4.0876e-03],\n",
       "                        [-1.8448e-02, -1.4205e-02, -8.0051e-03],\n",
       "                        [-4.1017e-02, -1.7671e-02, -1.6075e-02]],\n",
       "              \n",
       "                       [[-5.0619e-03, -3.8657e-02, -1.6724e-02],\n",
       "                        [ 7.7710e-03, -4.6123e-02, -3.3794e-02],\n",
       "                        [ 3.0187e-02, -4.1111e-03,  4.1263e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-8.4440e-03,  1.4478e-02,  2.0925e-03],\n",
       "                        [-1.8277e-02,  9.9649e-03, -9.6685e-03],\n",
       "                        [-2.7329e-02, -9.8696e-04, -7.9309e-03]],\n",
       "              \n",
       "                       [[ 2.2844e-02,  3.1802e-03,  1.7223e-02],\n",
       "                        [ 7.9945e-03, -1.7438e-02, -1.8138e-02],\n",
       "                        [ 5.6933e-03, -1.1354e-02,  3.0347e-03]],\n",
       "              \n",
       "                       [[-8.3175e-03, -3.1811e-02, -2.2094e-02],\n",
       "                        [ 1.4638e-05, -1.5316e-02, -1.5267e-02],\n",
       "                        [-7.2670e-03, -8.0666e-03, -5.5703e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.2208e-03, -4.1981e-03,  2.4875e-03],\n",
       "                        [ 1.2551e-02,  3.9157e-03,  3.4247e-03],\n",
       "                        [ 9.6486e-03,  1.4965e-02,  7.2044e-03]],\n",
       "              \n",
       "                       [[-2.3419e-02, -2.4347e-02, -1.6248e-02],\n",
       "                        [-1.9058e-02, -2.2891e-02, -1.8188e-02],\n",
       "                        [-6.6299e-03, -2.0042e-02, -1.3563e-02]],\n",
       "              \n",
       "                       [[-1.7024e-02, -2.0971e-02, -3.7842e-02],\n",
       "                        [-5.2446e-03, -2.0623e-02, -2.7047e-02],\n",
       "                        [ 1.4369e-02, -1.0064e-02,  7.1109e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.4927e-03,  2.8716e-02,  1.7452e-02],\n",
       "                        [ 1.3738e-02,  1.8917e-02,  5.4851e-03],\n",
       "                        [ 1.4782e-02,  1.0775e-02, -2.3456e-03]],\n",
       "              \n",
       "                       [[ 8.8791e-03,  1.1923e-02,  2.7322e-02],\n",
       "                        [ 2.5228e-02,  2.2188e-02,  3.0305e-02],\n",
       "                        [ 3.5736e-02,  2.4427e-02,  2.1815e-02]],\n",
       "              \n",
       "                       [[-5.7071e-03, -8.7913e-03, -1.3530e-02],\n",
       "                        [-5.4085e-03, -1.7407e-03,  2.3131e-03],\n",
       "                        [ 8.3093e-03,  4.2748e-03,  1.2303e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.5613e-03,  1.1008e-02, -7.1487e-04],\n",
       "                        [ 1.0556e-02,  2.2342e-02, -1.0048e-03],\n",
       "                        [-7.6637e-03,  1.4437e-03, -8.7726e-03]],\n",
       "              \n",
       "                       [[-1.4743e-02, -3.4066e-02, -2.0108e-02],\n",
       "                        [-5.4339e-03, -1.9609e-02, -1.5343e-02],\n",
       "                        [-5.1284e-03, -1.1401e-02,  1.2394e-04]],\n",
       "              \n",
       "                       [[-1.6594e-02, -3.8284e-02, -7.5498e-03],\n",
       "                        [-1.3931e-02, -1.7271e-02, -8.3798e-03],\n",
       "                        [ 2.1377e-03, -2.7655e-03, -2.0783e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.3254e-03,  9.9774e-03,  1.4181e-02],\n",
       "                        [ 1.7003e-02,  1.4496e-02,  1.8798e-02],\n",
       "                        [ 3.4987e-02,  3.2703e-02,  4.6225e-02]],\n",
       "              \n",
       "                       [[-5.5553e-03,  1.6191e-03, -8.5051e-03],\n",
       "                        [-1.4465e-02, -7.8599e-05,  5.5291e-04],\n",
       "                        [-3.7181e-02, -3.0638e-02, -2.9953e-02]],\n",
       "              \n",
       "                       [[ 4.4973e-02,  2.9909e-02,  3.9455e-02],\n",
       "                        [ 4.1707e-02,  2.9728e-02,  3.0226e-02],\n",
       "                        [ 3.2294e-02,  3.8331e-02,  5.5640e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.5318e-03, -2.5768e-03, -1.9835e-02],\n",
       "                        [-3.8708e-03, -6.0238e-03, -5.2313e-03],\n",
       "                        [ 5.3449e-03,  1.9162e-02,  1.5444e-02]],\n",
       "              \n",
       "                       [[-4.0897e-03, -2.1466e-02, -3.2437e-02],\n",
       "                        [-4.8543e-03, -8.3130e-03, -1.7764e-02],\n",
       "                        [-4.6017e-03, -1.2160e-02, -1.6609e-02]],\n",
       "              \n",
       "                       [[-1.7130e-02, -1.9588e-02, -9.0539e-03],\n",
       "                        [-1.5584e-02, -2.0674e-03, -1.0101e-02],\n",
       "                        [ 6.5303e-03,  3.2189e-03,  8.5852e-04]]]], device='cuda:0')),\n",
       "             ('features.24.bias',\n",
       "              tensor([ 0.0170, -0.0875, -0.0399,  0.1166,  0.0071, -0.0086,  0.0036,\n",
       "                       0.0412,  0.0798,  0.0953,  0.0781,  0.0398,  0.0683, -0.0525,\n",
       "                       0.4372,  0.1483,  0.0300,  0.2273,  0.0957,  0.0077,  0.0977,\n",
       "                      -0.1121,  0.0185, -0.1287, -0.0580,  0.1470, -0.0105, -0.1610,\n",
       "                       0.1230, -0.1701,  0.1240, -0.0753,  0.0317,  0.1761, -0.1778,\n",
       "                       0.1011, -0.2500, -0.1378,  0.0540, -0.1295,  0.0049,  0.0738,\n",
       "                      -0.1486,  0.0954, -0.0246,  0.0839, -0.0654, -0.0977,  0.0447,\n",
       "                      -0.1310,  0.0485,  0.0386,  0.1314,  0.0381,  0.0414,  0.0511,\n",
       "                      -0.0406,  0.2377, -0.0563,  0.1697,  0.0308, -0.0962, -0.0642,\n",
       "                      -0.1085,  0.0265, -0.2100,  0.1022, -0.0703, -0.1298,  0.0715,\n",
       "                      -0.0721, -0.0055,  0.1748,  0.0548,  0.2109, -0.0580,  0.0829,\n",
       "                       0.2753, -0.1189,  0.0427,  0.0114,  0.0096,  0.0276,  0.0831,\n",
       "                       0.1636,  0.1559, -0.0379, -0.0096,  0.0926, -0.0480,  0.0822,\n",
       "                      -0.3240,  0.1338,  0.1117, -0.1571, -0.1218,  0.0739,  0.1244,\n",
       "                      -0.1106, -0.0676,  0.1301, -0.0226,  0.0438, -0.3320, -0.0960,\n",
       "                      -0.0154, -0.1423,  0.1716, -0.0882,  0.0227, -0.0128,  0.0516,\n",
       "                       0.0412, -0.0851, -0.0176,  0.0759, -0.0011,  0.2124,  0.0215,\n",
       "                       0.1319,  0.0103,  0.0785,  0.1512, -0.0071, -0.0454, -0.0689,\n",
       "                       0.1862, -0.0155, -0.0020,  0.0567,  0.4030, -0.1112,  0.0375,\n",
       "                       0.1239,  0.2662, -0.0060,  0.0440,  0.1679, -0.0468, -0.0389,\n",
       "                      -0.0514, -0.0975, -0.0915,  0.1276,  0.0840,  0.0748,  0.1412,\n",
       "                      -0.0288,  0.0330,  0.1429,  0.1255,  0.0154, -0.0826, -0.0480,\n",
       "                      -0.0552, -0.0237, -0.0123, -0.0162, -0.1319, -0.0326,  0.0086,\n",
       "                      -0.1325,  0.0498, -0.0529,  0.0375, -0.2020,  0.0661,  0.0272,\n",
       "                       0.1541,  0.1092, -0.2109,  0.1885,  0.2147,  0.0184,  0.1040,\n",
       "                       0.0060,  0.0123, -0.0155, -0.1230,  0.1295,  0.1797,  0.1262,\n",
       "                       0.0965,  0.0992, -0.0371, -0.1158,  0.0154, -0.0538,  0.1050,\n",
       "                      -0.0201,  0.0206, -0.0196,  0.1352,  0.0446, -0.0732, -0.1237,\n",
       "                      -0.0317, -0.0360,  0.0301,  0.0616,  0.0337, -0.0157, -0.0348,\n",
       "                      -0.0609,  0.0838,  0.0188,  0.1521,  0.0852,  0.0758,  0.1071,\n",
       "                      -0.4249,  0.1164, -0.2234,  0.1191, -0.1281,  0.0090,  0.0708,\n",
       "                      -0.2281,  0.0981, -0.1367,  0.1808,  0.0556,  0.1874,  0.0254,\n",
       "                       0.1088, -0.0539,  0.0019,  0.0059,  0.2057,  0.0394,  0.1581,\n",
       "                       0.0183,  0.2806,  0.1101,  0.1550,  0.0755,  0.0733,  0.1688,\n",
       "                       0.0666,  0.0784, -0.0193,  0.1351,  0.0388, -0.0787, -0.0247,\n",
       "                       0.0990,  0.0443, -0.0580,  0.0184, -0.0843, -0.0721,  0.1830,\n",
       "                       0.0935,  0.0572,  0.0682,  0.0633,  0.0722,  0.0157,  0.0926,\n",
       "                       0.0330,  0.0032,  0.0889, -0.1300,  0.0028,  0.0577, -0.0366,\n",
       "                      -0.0112,  0.1617,  0.2441,  0.0320, -0.0326,  0.0416,  0.1684,\n",
       "                       0.0945, -0.1373, -0.0234, -0.1308, -0.0273,  0.0538, -0.0146,\n",
       "                       0.0961,  0.0395,  0.0924,  0.0526,  0.0335,  0.0025,  0.0917,\n",
       "                      -0.1820, -0.0453,  0.0557,  0.0498, -0.1677,  0.1243,  0.0369,\n",
       "                       0.0974,  0.1443,  0.1094, -0.0211,  0.1178,  0.1323,  0.1481,\n",
       "                       0.0407,  0.0032,  0.0146, -0.2711,  0.0241,  0.0280,  0.0462,\n",
       "                      -0.0089,  0.0810, -0.1078, -0.2722, -0.0297,  0.1053,  0.0820,\n",
       "                      -0.0397, -0.0165,  0.1469, -0.0409,  0.1685,  0.0012, -0.0321,\n",
       "                      -0.0251, -0.0536,  0.0626, -0.1810, -0.0423, -0.1122, -0.0305,\n",
       "                      -0.0766,  0.1296, -0.0661,  0.1292, -0.2214,  0.0780,  0.0084,\n",
       "                      -0.0544, -0.0563, -0.0580,  0.0264,  0.1643,  0.0200, -0.0608,\n",
       "                       0.0476,  0.0959,  0.0985,  0.1813, -0.1512,  0.0044,  0.1927,\n",
       "                      -0.0342, -0.1724,  0.0593,  0.2172,  0.0388,  0.0312,  0.0334,\n",
       "                      -0.0781, -0.1078, -0.0776, -0.0531, -0.0028,  0.0210, -0.0502,\n",
       "                      -0.1219, -0.0902,  0.1669, -0.0704, -0.2519, -0.0406,  0.2097,\n",
       "                       0.0685, -0.1483,  0.0544, -0.0963,  0.0750,  0.0415, -0.0184,\n",
       "                       0.0515,  0.0318,  0.0793, -0.0241, -0.0020,  0.1052, -0.0336,\n",
       "                      -0.0999,  0.1941, -0.1637, -0.1551, -0.0979,  0.0144,  0.1128,\n",
       "                      -0.1061,  0.0469, -0.0300,  0.2259, -0.0585, -0.1348,  0.0115,\n",
       "                       0.0285,  0.1336,  0.0425,  0.0315,  0.1148,  0.0174, -0.0545,\n",
       "                       0.0953,  0.0275, -0.1262,  0.1273,  0.0278,  0.0896,  0.0096,\n",
       "                      -0.1567, -0.0966, -0.2123,  0.0802,  0.2327,  0.0681, -0.0489,\n",
       "                      -0.0562,  0.1194,  0.0851,  0.0096,  0.1515, -0.2064, -0.0521,\n",
       "                       0.1748, -0.0462, -0.1200,  0.0830,  0.0368, -0.0473, -0.0434,\n",
       "                       0.1425,  0.1025, -0.1949,  0.0421, -0.0404,  0.1078,  0.1692,\n",
       "                       0.0591,  0.2425,  0.0476, -0.0338,  0.1412, -0.0652,  0.1273,\n",
       "                       0.0438,  0.0049, -0.0378,  0.0815,  0.1011,  0.0974,  0.1034,\n",
       "                      -0.0000,  0.1131, -0.1935,  0.1279,  0.2327,  0.0209, -0.0256,\n",
       "                      -0.0351,  0.1704, -0.0258,  0.0239,  0.0856,  0.0763, -0.0911,\n",
       "                      -0.2745, -0.1014, -0.1627,  0.1120, -0.0288,  0.1119, -0.0221,\n",
       "                      -0.0717,  0.0563,  0.0404, -0.0573,  0.0537, -0.0400,  0.1574,\n",
       "                      -0.0724, -0.0257, -0.0212,  0.2069,  0.0137, -0.1004,  0.0035,\n",
       "                       0.0617,  0.0495,  0.0023,  0.1532,  0.1049,  0.0320,  0.0823,\n",
       "                      -0.0465, -0.0233,  0.1409,  0.0183,  0.0460,  0.0837,  0.0206,\n",
       "                       0.0253,  0.0891,  0.1486, -0.2971, -0.0761,  0.0082,  0.0780,\n",
       "                      -0.4700], device='cuda:0')),\n",
       "             ('features.26.weight',\n",
       "              tensor([[[[ 5.3396e-03, -2.6011e-03,  2.0471e-03],\n",
       "                        [-5.5203e-04, -5.6705e-03, -1.6622e-02],\n",
       "                        [-5.3414e-03, -4.3450e-03, -1.1729e-02]],\n",
       "              \n",
       "                       [[ 2.8564e-02,  2.7208e-02,  3.0957e-02],\n",
       "                        [ 2.9747e-02,  2.6193e-02,  3.5095e-02],\n",
       "                        [ 2.9610e-02,  4.1583e-02,  3.3541e-02]],\n",
       "              \n",
       "                       [[-4.8096e-03,  3.1882e-03,  1.0270e-03],\n",
       "                        [ 6.3651e-03,  1.7796e-02,  1.4464e-02],\n",
       "                        [-2.8096e-03, -5.9703e-03,  2.8339e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.8245e-03,  8.2978e-03, -4.4093e-04],\n",
       "                        [ 3.4736e-04, -7.0685e-03, -1.1561e-02],\n",
       "                        [-8.2451e-03, -2.0998e-02, -1.2935e-02]],\n",
       "              \n",
       "                       [[ 1.1445e-02,  1.9142e-02,  1.2391e-02],\n",
       "                        [ 5.1714e-03,  1.4061e-02,  1.2852e-02],\n",
       "                        [-2.2861e-03,  3.0864e-03,  2.8760e-03]],\n",
       "              \n",
       "                       [[ 4.0615e-03,  1.2981e-02,  3.9028e-03],\n",
       "                        [ 1.0133e-02,  2.2851e-02,  1.2542e-02],\n",
       "                        [-1.8526e-02,  4.0812e-03, -7.3445e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.6611e-03,  1.6469e-02,  1.8038e-02],\n",
       "                        [ 4.2513e-03,  1.3071e-02,  1.3559e-02],\n",
       "                        [ 5.8119e-05, -5.8924e-03,  2.7461e-03]],\n",
       "              \n",
       "                       [[-1.9168e-02, -1.1762e-02, -6.3617e-03],\n",
       "                        [-4.4906e-03,  5.5111e-03,  2.2184e-02],\n",
       "                        [ 1.5402e-02,  3.0761e-02,  2.4692e-02]],\n",
       "              \n",
       "                       [[ 2.4585e-02,  1.4311e-03,  1.1614e-02],\n",
       "                        [ 3.0728e-03,  3.2102e-03, -2.3297e-03],\n",
       "                        [ 8.8638e-03,  2.1141e-04, -6.4401e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.1725e-03, -1.5327e-02, -9.5785e-03],\n",
       "                        [-3.2860e-03, -1.0098e-02, -9.1001e-03],\n",
       "                        [-8.7265e-03, -1.0286e-02, -1.2795e-02]],\n",
       "              \n",
       "                       [[-2.2210e-03, -1.1368e-02, -1.6937e-02],\n",
       "                        [-4.1622e-03, -1.7335e-02, -1.9301e-02],\n",
       "                        [ 1.7208e-02, -5.8893e-03, -3.5251e-03]],\n",
       "              \n",
       "                       [[ 4.2934e-04, -3.1749e-02, -1.1264e-02],\n",
       "                        [-1.3598e-02, -2.6306e-02, -1.2232e-02],\n",
       "                        [-1.0754e-02, -6.1461e-03,  1.9349e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.4869e-03, -1.0894e-02, -2.3739e-02],\n",
       "                        [ 1.2003e-02, -4.4158e-03, -2.6271e-02],\n",
       "                        [ 1.0297e-02, -1.4211e-02, -2.0285e-02]],\n",
       "              \n",
       "                       [[-7.8340e-03, -2.3295e-02, -2.0594e-02],\n",
       "                        [-4.7429e-03, -1.5618e-02, -1.8468e-02],\n",
       "                        [ 2.5025e-03, -1.0162e-02,  2.7711e-03]],\n",
       "              \n",
       "                       [[ 8.0493e-03, -1.5987e-02,  4.0480e-03],\n",
       "                        [ 5.0285e-04, -1.5592e-02, -9.4860e-04],\n",
       "                        [ 1.8756e-03, -1.6222e-03,  2.6918e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.0127e-03, -4.9466e-03,  9.5168e-03],\n",
       "                        [-5.3006e-03, -7.0202e-03,  6.6488e-03],\n",
       "                        [ 2.5722e-03, -5.2046e-03,  7.1014e-04]],\n",
       "              \n",
       "                       [[-2.1340e-02, -1.3918e-02, -1.2257e-02],\n",
       "                        [-1.9682e-02, -2.2466e-02, -1.6505e-02],\n",
       "                        [ 1.6370e-03, -1.8450e-03, -1.6151e-02]],\n",
       "              \n",
       "                       [[-6.9218e-03, -9.6376e-03, -6.8654e-03],\n",
       "                        [-2.6699e-02, -8.4984e-03, -1.5467e-02],\n",
       "                        [-2.1957e-02, -3.2741e-03, -1.0307e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-9.1366e-03, -6.9445e-03, -1.6918e-03],\n",
       "                        [-1.4680e-02, -7.3195e-03, -1.8997e-03],\n",
       "                        [-1.7819e-02, -6.0907e-03, -3.8606e-03]],\n",
       "              \n",
       "                       [[-2.6625e-03, -4.5790e-03, -5.2848e-03],\n",
       "                        [ 2.7805e-03,  1.2579e-02, -3.2661e-03],\n",
       "                        [ 1.6539e-02,  1.5941e-02,  2.5934e-03]],\n",
       "              \n",
       "                       [[-1.7372e-02, -1.5669e-02, -1.7184e-02],\n",
       "                        [-1.0523e-02, -8.0881e-03, -3.5002e-03],\n",
       "                        [ 2.0012e-02,  1.3992e-02,  2.2567e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.8450e-03,  1.4391e-03, -4.8037e-03],\n",
       "                        [ 3.1779e-03, -2.1945e-03, -1.8111e-03],\n",
       "                        [-8.2320e-04, -5.2492e-03,  5.9751e-03]],\n",
       "              \n",
       "                       [[-1.8042e-02, -1.9381e-02, -2.0262e-02],\n",
       "                        [-1.2160e-02, -1.6965e-02, -1.1955e-02],\n",
       "                        [-1.2115e-02, -2.2049e-02, -7.6491e-03]],\n",
       "              \n",
       "                       [[-1.5930e-02, -1.5632e-02, -1.4184e-02],\n",
       "                        [-2.6613e-02, -2.4581e-02, -2.5748e-02],\n",
       "                        [-4.3730e-02, -2.4319e-02, -3.5868e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5428e-02,  1.7873e-02,  3.8022e-03],\n",
       "                        [ 3.0997e-02,  2.7097e-02,  1.3571e-02],\n",
       "                        [ 4.2717e-02,  3.4481e-02,  1.6175e-02]],\n",
       "              \n",
       "                       [[-1.5489e-02, -5.0627e-03,  1.2652e-03],\n",
       "                        [-1.0676e-02, -1.4705e-04,  6.0551e-03],\n",
       "                        [-1.5833e-02, -1.6241e-02, -8.2176e-03]],\n",
       "              \n",
       "                       [[ 5.4370e-03, -9.6808e-03, -1.1396e-02],\n",
       "                        [ 8.2531e-03,  3.7010e-03,  1.4806e-02],\n",
       "                        [ 2.5946e-02,  3.4422e-02,  2.8250e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.0576e-02,  4.6424e-02,  6.3164e-03],\n",
       "                        [ 2.3792e-02,  3.9974e-02,  1.2829e-02],\n",
       "                        [-2.2258e-02, -1.0163e-02, -2.6070e-02]],\n",
       "              \n",
       "                       [[ 3.2659e-02,  3.8465e-02,  5.0303e-02],\n",
       "                        [ 1.5540e-02,  2.3043e-02,  2.1985e-02],\n",
       "                        [ 6.8735e-04, -1.1371e-02, -8.7360e-03]],\n",
       "              \n",
       "                       [[-2.5060e-02, -2.7326e-02, -2.7092e-02],\n",
       "                        [-1.7381e-02, -2.3803e-02, -2.5497e-02],\n",
       "                        [-3.5137e-02, -3.5637e-02, -4.1381e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.4722e-03,  2.6112e-02,  1.4285e-02],\n",
       "                        [ 1.5717e-02,  1.4589e-02,  1.0102e-02],\n",
       "                        [ 3.1282e-04,  1.3287e-02, -1.4117e-03]],\n",
       "              \n",
       "                       [[-3.0626e-02, -1.7090e-02, -1.8398e-02],\n",
       "                        [-1.3602e-02, -1.3641e-02, -1.7517e-05],\n",
       "                        [-4.3749e-03, -1.6990e-02, -5.9113e-03]],\n",
       "              \n",
       "                       [[ 3.5263e-02,  6.0833e-02,  4.4315e-02],\n",
       "                        [ 2.2339e-02,  6.8715e-02,  2.7959e-02],\n",
       "                        [-3.1752e-03,  2.2407e-02,  1.5560e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.8860e-04, -3.1928e-03,  1.3426e-02],\n",
       "                        [-3.6923e-03, -3.4468e-03,  3.3096e-02],\n",
       "                        [-1.2766e-02, -1.6451e-02,  8.1307e-03]],\n",
       "              \n",
       "                       [[-7.9840e-03,  3.2893e-02,  4.4818e-02],\n",
       "                        [ 1.8329e-02,  3.8900e-02,  3.9412e-02],\n",
       "                        [-1.0024e-02,  5.2262e-03, -1.6413e-03]],\n",
       "              \n",
       "                       [[ 7.7319e-03,  1.6902e-02, -3.2354e-03],\n",
       "                        [ 6.6349e-03, -1.1266e-02,  1.1672e-03],\n",
       "                        [ 3.5068e-03,  2.4610e-03,  4.2446e-02]]]], device='cuda:0')),\n",
       "             ('features.26.bias',\n",
       "              tensor([-0.0019,  0.0571,  0.2934, -0.0418, -0.1456,  0.0976,  0.0023,\n",
       "                      -0.0468, -0.1105,  0.0366, -0.0237,  0.1966,  0.0063,  0.1037,\n",
       "                      -0.1243, -0.0555,  0.1067,  0.2884,  0.0754,  0.0453,  0.0714,\n",
       "                       0.0946, -0.1045, -0.3055, -0.1477,  0.1542, -0.0360, -0.0167,\n",
       "                       0.0501, -0.1036,  0.1625,  0.0369, -0.0570, -0.0818,  0.2014,\n",
       "                       0.0700, -0.2286,  0.1382,  0.2611,  0.0211,  0.1023,  0.0865,\n",
       "                       0.0611,  0.0728,  0.0070, -0.0421,  0.1014,  0.1839,  0.0988,\n",
       "                       0.2641,  0.0534,  0.1671,  0.2509,  0.1161,  0.2197,  0.1389,\n",
       "                      -0.0479, -0.0980,  0.1037,  0.1641,  0.1903,  0.0745,  0.2201,\n",
       "                       0.0944, -0.0479,  0.0468, -0.0039,  0.1878, -0.0227,  0.1475,\n",
       "                       0.1419,  0.1883,  0.0249,  0.2175,  0.1030,  0.1513,  0.1767,\n",
       "                       0.0604,  0.1643,  0.0349,  0.0380, -0.0684,  0.0062,  0.0134,\n",
       "                      -0.1396,  0.0781,  0.1955, -0.1259,  0.0960, -0.0021,  0.0694,\n",
       "                      -0.1609,  0.0899,  0.2562, -0.0982,  0.2659, -0.0231, -0.1700,\n",
       "                      -0.0002,  0.0297,  0.1028,  0.1548,  0.1995, -0.2805,  0.1057,\n",
       "                       0.0782,  0.0617,  0.0792,  0.0018, -0.0969,  0.2189, -0.0336,\n",
       "                       0.0301,  0.2673,  0.0727,  0.0383,  0.0447,  0.2947,  0.0264,\n",
       "                       0.2646,  0.2229, -0.1769,  0.1449,  0.2528,  0.0957,  0.0735,\n",
       "                       0.1285,  0.3469,  0.1182,  0.3159, -0.0825, -0.2826,  0.2519,\n",
       "                      -0.0448,  0.0891,  0.0022,  0.1890,  0.1621, -0.1977,  0.1545,\n",
       "                      -0.0176, -0.0165,  0.1899,  0.0614,  0.1695, -0.0271,  0.0531,\n",
       "                       0.1096,  0.1380,  0.0673, -0.0051, -0.1718,  0.0761, -0.0130,\n",
       "                       0.1312, -0.0829,  0.1082,  0.1167,  0.1910, -0.2603,  0.1242,\n",
       "                      -0.6417, -0.0945,  0.1488, -0.0222,  0.1939,  0.2271, -0.0305,\n",
       "                       0.0436,  0.0251,  0.0480,  0.2494,  0.0862,  0.0095,  0.0060,\n",
       "                       0.1541,  0.1584,  0.1380, -0.1268,  0.1323,  0.0464,  0.2226,\n",
       "                       0.2636, -0.0035,  0.1869, -0.0355,  0.0003,  0.0771,  0.0743,\n",
       "                       0.1994, -0.0289,  0.0287,  0.0022,  0.0605,  0.1270, -0.1906,\n",
       "                       0.1417,  0.0581,  0.0256,  0.1129,  0.3187, -0.0687,  0.2257,\n",
       "                       0.1593,  0.0398,  0.1283,  0.1417,  0.4131,  0.0468,  0.1224,\n",
       "                       0.2197,  0.0499,  0.0716, -0.0395, -0.2303,  0.1346, -0.0428,\n",
       "                       0.0154, -0.6689,  0.1627,  0.0222, -0.1776,  0.1278,  0.0213,\n",
       "                      -0.5521,  0.2601,  0.0804,  0.0943, -0.0731,  0.1681,  0.0543,\n",
       "                       0.1454,  0.1938,  0.3558,  0.0512,  0.2236,  0.2353,  0.1623,\n",
       "                       0.0095, -0.2007,  0.0147, -0.2051,  0.1599, -0.1146,  0.2460,\n",
       "                       0.0656,  0.1017, -0.0846, -0.3698,  0.0012, -0.0506,  0.0835,\n",
       "                      -0.2855,  0.1361,  0.1256,  0.2716, -0.1187,  0.0143,  0.0839,\n",
       "                      -0.0217, -0.1032,  0.0408,  0.0162, -0.0642, -0.0084,  0.1034,\n",
       "                      -0.0327, -0.0743, -0.0560,  0.1332, -0.1270,  0.2531,  0.2731,\n",
       "                      -0.0767,  0.1636,  0.1446,  0.0488,  0.1207, -0.3197,  0.0687,\n",
       "                      -0.3042,  0.0517,  0.0694, -0.0055,  0.1413, -0.2432,  0.1387,\n",
       "                       0.0705, -0.1963,  0.2322,  0.0535,  0.1300,  0.2320,  0.0538,\n",
       "                      -0.3201,  0.0975,  0.0695,  0.1273, -0.0653,  0.1390,  0.0980,\n",
       "                       0.0036, -0.0493,  0.2281, -0.1839,  0.0848, -0.0493,  0.0364,\n",
       "                      -0.0149, -0.0332, -0.0288,  0.0734,  0.1093,  0.2110,  0.0743,\n",
       "                      -0.0339, -0.0097, -0.0441,  0.0521,  0.0739,  0.2286,  0.4431,\n",
       "                      -0.2661,  0.2466,  0.0088,  0.2606,  0.0263,  0.0049, -0.0209,\n",
       "                       0.2341,  0.0467, -0.1864, -0.0601,  0.0199,  0.1241,  0.0691,\n",
       "                       0.0876,  0.0606,  0.0193,  0.0073,  0.2791,  0.1581,  0.1419,\n",
       "                       0.0721,  0.1233,  0.2297,  0.0373,  0.2709,  0.2673,  0.2907,\n",
       "                      -0.1266, -0.1798,  0.1459, -0.1673,  0.3007,  0.0551,  0.0330,\n",
       "                      -0.1200,  0.0929,  0.1121,  0.0038,  0.1440,  0.0619, -0.0121,\n",
       "                      -0.0617,  0.2525,  0.1330,  0.1623,  0.0830,  0.0261,  0.1392,\n",
       "                       0.2051,  0.0007, -0.1794,  0.1576, -0.0386, -0.0194,  0.1250,\n",
       "                       0.2685,  0.1051,  0.0056,  0.0165,  0.0064,  0.0814,  0.0667,\n",
       "                       0.0554,  0.0875, -0.0400,  0.1614,  0.0719, -0.0056,  0.2157,\n",
       "                      -0.0744,  0.0581,  0.2633,  0.0283,  0.2442,  0.2476, -0.0290,\n",
       "                       0.3238,  0.1689,  0.1375, -0.1039,  0.0936, -0.0517,  0.0352,\n",
       "                       0.1475,  0.0538,  0.0414,  0.1698,  0.1447, -0.1470,  0.0605,\n",
       "                       0.0632,  0.1252,  0.0532,  0.0760,  0.1058,  0.0985,  0.1902,\n",
       "                       0.0552,  0.3173, -0.0524,  0.1310,  0.0083,  0.2918,  0.0588,\n",
       "                      -0.0510, -0.0422, -0.0118, -0.0148,  0.0133, -0.0519,  0.0083,\n",
       "                       0.0523, -0.0794,  0.1542,  0.0565, -0.1634, -0.0261, -0.1422,\n",
       "                       0.1418,  0.0159, -0.3704,  0.1036, -0.0260,  0.0021,  0.1233,\n",
       "                      -0.2909,  0.4527,  0.0119,  0.0540,  0.1334,  0.1489, -0.2533,\n",
       "                       0.2763,  0.1991,  0.0710, -0.0455,  0.4190,  0.0235,  0.0915,\n",
       "                       0.2258, -0.0707,  0.0960,  0.0376,  0.0341,  0.0710,  0.0337,\n",
       "                      -0.0769,  0.0618,  0.0912,  0.2743,  0.0717,  0.0278,  0.2271,\n",
       "                       0.0992,  0.1366,  0.1474,  0.1803,  0.0693,  0.0207,  0.0263,\n",
       "                       0.0736,  0.0027,  0.0322,  0.2313,  0.0793,  0.0594, -0.2744,\n",
       "                       0.1028, -0.3173,  0.1025,  0.0778,  0.0742,  0.2729,  0.2042,\n",
       "                       0.2968,  0.1126,  0.4318,  0.0007,  0.0122, -0.1074, -0.1471,\n",
       "                       0.1459,  0.0533,  0.2097,  0.0745,  0.1640,  0.0844,  0.2086,\n",
       "                      -1.4974], device='cuda:0')),\n",
       "             ('features.28.weight',\n",
       "              tensor([[[[ 2.7768e-02,  1.5296e-02,  2.1911e-02],\n",
       "                        [ 2.5202e-02,  2.3223e-02,  2.0005e-02],\n",
       "                        [ 3.0154e-02,  8.7023e-03,  1.7728e-02]],\n",
       "              \n",
       "                       [[-1.0682e-02, -9.5476e-03, -9.1195e-03],\n",
       "                        [-3.5036e-03, -1.2508e-02, -1.4557e-02],\n",
       "                        [-1.3689e-02, -1.8028e-02, -2.1646e-02]],\n",
       "              \n",
       "                       [[-8.5565e-03, -7.2054e-03, -6.3846e-03],\n",
       "                        [ 2.0408e-03, -2.1947e-03, -6.8919e-04],\n",
       "                        [-1.6638e-03, -9.0286e-04,  4.9448e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4711e-03,  3.3385e-03,  2.6684e-03],\n",
       "                        [-9.6592e-03, -1.1543e-02, -8.2975e-03],\n",
       "                        [ 3.4230e-03,  5.5182e-03,  1.2600e-02]],\n",
       "              \n",
       "                       [[-6.8517e-03, -4.8486e-03, -8.5124e-03],\n",
       "                        [ 1.0570e-03,  1.1698e-02, -1.0812e-03],\n",
       "                        [ 6.2322e-03,  7.0932e-04, -1.5733e-03]],\n",
       "              \n",
       "                       [[-2.1647e-02,  2.5883e-03,  1.1418e-02],\n",
       "                        [-2.7891e-02,  1.8448e-03,  1.1855e-02],\n",
       "                        [-1.2538e-02, -1.8912e-03,  9.2639e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1915e-02, -2.5141e-02, -5.7179e-03],\n",
       "                        [-1.0882e-02, -2.0027e-02, -1.1911e-02],\n",
       "                        [-1.1790e-02, -2.5523e-03, -9.7380e-03]],\n",
       "              \n",
       "                       [[ 4.7855e-03,  1.2190e-02,  2.7961e-03],\n",
       "                        [ 1.0504e-03,  1.1996e-02,  4.9763e-03],\n",
       "                        [-8.5489e-03,  7.1493e-03, -1.0951e-03]],\n",
       "              \n",
       "                       [[ 2.2856e-02, -2.7013e-04, -1.2531e-02],\n",
       "                        [ 2.3324e-02, -4.0162e-03, -6.5110e-03],\n",
       "                        [ 2.1377e-02, -8.4313e-03, -1.5131e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5753e-03, -9.9031e-03, -8.8476e-03],\n",
       "                        [-5.7730e-03, -5.1446e-04, -7.1723e-03],\n",
       "                        [-2.2436e-02, -9.8933e-03, -1.9306e-02]],\n",
       "              \n",
       "                       [[ 2.5404e-03,  8.9606e-03, -5.4400e-03],\n",
       "                        [ 1.3366e-02,  2.0605e-02,  6.6010e-03],\n",
       "                        [ 1.8054e-02,  3.1267e-02,  2.4730e-02]],\n",
       "              \n",
       "                       [[-1.4774e-03,  1.2404e-02,  8.4087e-03],\n",
       "                        [ 1.2018e-02,  1.7658e-02,  1.7988e-02],\n",
       "                        [-3.6130e-04,  1.8112e-02,  1.8274e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.2360e-03,  7.4191e-04,  2.9408e-03],\n",
       "                        [ 2.4742e-03, -4.0349e-03, -2.9401e-03],\n",
       "                        [-1.5432e-03, -5.3605e-03, -5.8344e-03]],\n",
       "              \n",
       "                       [[-1.3595e-02, -3.1718e-02, -2.3710e-02],\n",
       "                        [-2.1746e-02, -2.5402e-02, -2.3455e-02],\n",
       "                        [-1.5045e-02, -3.1418e-02, -2.8699e-02]],\n",
       "              \n",
       "                       [[ 3.2991e-03, -4.9208e-03,  1.4358e-03],\n",
       "                        [-7.7625e-04,  6.4103e-03,  3.9225e-03],\n",
       "                        [ 1.0592e-02,  5.9198e-03,  1.5063e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.8337e-03, -1.5062e-02, -1.1133e-02],\n",
       "                        [ 4.8897e-03,  3.7414e-03, -6.6763e-03],\n",
       "                        [ 1.0834e-02,  1.6787e-02,  6.9389e-03]],\n",
       "              \n",
       "                       [[-2.0545e-02, -2.2203e-02, -1.7161e-02],\n",
       "                        [-2.5112e-02, -3.0551e-02, -1.5765e-02],\n",
       "                        [-2.4664e-02, -2.2903e-02, -5.8698e-03]],\n",
       "              \n",
       "                       [[-3.2173e-02, -2.9189e-02, -8.3404e-03],\n",
       "                        [-2.5504e-02, -1.6742e-02,  1.7872e-03],\n",
       "                        [-3.1295e-02, -1.2420e-02,  1.1523e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.9429e-02, -2.4556e-02, -1.7622e-02],\n",
       "                        [-3.5300e-02, -3.0947e-02, -2.4672e-02],\n",
       "                        [-2.4305e-02, -2.5179e-02, -7.1441e-03]],\n",
       "              \n",
       "                       [[ 2.9619e-02,  1.2602e-02, -1.9829e-02],\n",
       "                        [ 9.1760e-03, -8.5109e-04, -3.0802e-02],\n",
       "                        [-2.7310e-03, -1.7747e-02, -3.2944e-02]],\n",
       "              \n",
       "                       [[-3.7120e-03, -1.0129e-02,  1.1997e-02],\n",
       "                        [-5.0915e-03, -1.4651e-02,  1.0667e-02],\n",
       "                        [-4.8322e-03, -9.9947e-03,  1.8547e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.4648e-02, -1.5231e-02,  1.0567e-03],\n",
       "                        [-8.6118e-03, -3.1389e-02, -1.3612e-02],\n",
       "                        [-1.7457e-02, -1.7559e-02, -1.1778e-02]],\n",
       "              \n",
       "                       [[-1.4624e-02, -8.1732e-03, -2.6069e-03],\n",
       "                        [-1.8911e-02, -2.5938e-02, -1.7402e-02],\n",
       "                        [-3.9192e-03, -1.7547e-02, -2.6254e-02]],\n",
       "              \n",
       "                       [[-5.1161e-02, -1.9841e-02,  1.4722e-02],\n",
       "                        [-4.5486e-02, -1.1310e-02,  1.3356e-02],\n",
       "                        [-5.4183e-02, -2.0307e-02, -2.4845e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0532e-03, -1.0636e-02,  7.1217e-04],\n",
       "                        [ 1.4047e-02,  1.0330e-02,  1.1886e-02],\n",
       "                        [ 1.9057e-02,  7.6312e-03,  1.1955e-02]],\n",
       "              \n",
       "                       [[-5.0939e-04,  2.6748e-03,  3.8110e-03],\n",
       "                        [-1.6356e-02, -2.5871e-03, -9.2277e-03],\n",
       "                        [-5.9132e-03, -3.3246e-03, -2.0477e-02]],\n",
       "              \n",
       "                       [[ 1.0108e-03,  1.5062e-02,  2.3413e-02],\n",
       "                        [ 4.2264e-05,  6.6031e-03,  3.2643e-02],\n",
       "                        [-2.8598e-03,  4.1518e-03,  2.0333e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.1414e-03, -6.4583e-03, -1.4588e-02],\n",
       "                        [-1.0115e-02, -1.0200e-02, -2.1285e-02],\n",
       "                        [-6.3856e-03, -7.5624e-03, -2.0476e-02]],\n",
       "              \n",
       "                       [[-1.0839e-02,  6.7214e-03,  5.8918e-03],\n",
       "                        [-9.5600e-04,  1.6651e-03,  7.1670e-03],\n",
       "                        [-1.8902e-02, -7.4955e-03, -9.8708e-04]],\n",
       "              \n",
       "                       [[-4.4182e-02, -2.7011e-02, -1.5440e-02],\n",
       "                        [-4.1249e-02, -2.9579e-02, -1.0295e-02],\n",
       "                        [-1.9288e-02, -9.9171e-03,  5.1636e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9454e-02, -2.0776e-02, -1.4369e-02],\n",
       "                        [-8.1482e-03, -1.6480e-02, -1.4024e-02],\n",
       "                        [-8.4481e-03, -2.4206e-02, -1.5236e-02]],\n",
       "              \n",
       "                       [[ 5.7170e-03,  1.4719e-02,  8.7575e-03],\n",
       "                        [ 7.4073e-03, -8.5165e-03, -1.1737e-02],\n",
       "                        [-2.1247e-03, -1.4506e-02, -1.4657e-02]],\n",
       "              \n",
       "                       [[ 3.0560e-02,  4.0275e-02,  5.0865e-02],\n",
       "                        [-2.9477e-03,  2.0548e-02,  4.3352e-02],\n",
       "                        [-1.6921e-02,  4.7982e-03,  2.1169e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.9884e-02, -2.8676e-02, -1.7745e-02],\n",
       "                        [-1.8820e-02, -2.7692e-02, -3.7976e-02],\n",
       "                        [-7.1567e-03, -1.6576e-02, -6.9290e-03]],\n",
       "              \n",
       "                       [[-3.3155e-03, -8.4667e-03,  4.0157e-03],\n",
       "                        [ 1.9905e-02, -1.0356e-02, -4.5904e-04],\n",
       "                        [ 3.1526e-02,  1.0053e-02,  1.1222e-02]],\n",
       "              \n",
       "                       [[-2.6271e-02, -8.1591e-03, -2.9560e-02],\n",
       "                        [-3.3923e-02, -2.4079e-02, -2.2005e-02],\n",
       "                        [-3.4229e-02, -2.6150e-02, -1.4213e-02]]]], device='cuda:0')),\n",
       "             ('features.28.bias',\n",
       "              tensor([ 0.1230,  0.0191,  0.2320,  0.0582,  0.1695,  0.0940,  0.1529,\n",
       "                       0.0360, -0.0107,  0.0455, -0.0352,  0.0255,  0.3716,  0.0743,\n",
       "                      -0.0553,  0.1809,  0.0097,  0.2619,  0.1822,  0.0821,  0.1674,\n",
       "                       0.0168, -0.0710,  0.2560,  0.1193, -0.0604, -0.0791,  0.0214,\n",
       "                       0.1586,  0.1026,  0.1570,  0.1001, -0.0320,  0.1293,  0.0696,\n",
       "                      -0.0650, -0.0298,  0.1416,  0.1933, -0.0536,  0.0173,  0.3494,\n",
       "                       0.5495,  0.0583,  0.1857, -0.0565,  0.0579, -0.3335,  0.1494,\n",
       "                      -0.0446,  0.2232, -0.1302,  0.0067,  0.1777,  0.0620, -0.2490,\n",
       "                       0.0738,  0.0953,  0.0100, -0.0514,  0.1243,  0.1079, -0.0415,\n",
       "                       0.0964, -0.1066,  0.0755,  0.2562,  0.1441, -0.0225,  0.1036,\n",
       "                       0.0704,  0.1181,  0.0350, -0.1615,  0.0751,  0.1418,  0.2138,\n",
       "                       0.0454,  0.2302,  0.1067, -0.2741, -0.0081,  0.1595,  0.1012,\n",
       "                       0.1345,  0.0621, -0.0649,  0.0525,  0.0766,  0.0494,  0.0623,\n",
       "                      -0.0326, -0.0475,  0.1355, -0.0184,  0.0065,  0.0310,  0.3109,\n",
       "                       0.0701, -0.0185, -0.1348, -0.1260,  0.1956,  0.0341,  0.1606,\n",
       "                       0.0529,  0.0766,  0.2215,  0.0399,  0.0616,  0.0748,  0.1443,\n",
       "                      -0.0680, -0.2001,  0.3057, -0.0453,  0.2406,  0.5348,  0.1781,\n",
       "                       0.4935,  0.0074,  0.0350,  0.2468,  0.3110,  0.0540,  0.1472,\n",
       "                      -0.0291,  0.4078,  0.1902, -0.0603, -0.0170,  0.2498,  0.2196,\n",
       "                       0.3696,  0.0307,  0.4371,  0.0885, -0.2757, -0.0066,  0.1497,\n",
       "                       0.1914,  0.1347,  0.0198,  0.0706, -0.0001,  0.0637,  0.0641,\n",
       "                      -0.0498,  0.1318,  0.1331, -0.0119, -0.0036, -0.0733,  0.0159,\n",
       "                       0.0203,  0.1202,  0.1536, -0.1339,  0.2988,  0.0624,  0.2644,\n",
       "                       0.0665,  0.0221, -0.0638,  0.1295, -0.1159,  0.0153,  0.1838,\n",
       "                      -0.0714,  0.0635,  0.0734,  0.3328,  0.2413,  0.1229, -0.0367,\n",
       "                      -0.2264,  0.0942,  0.0640,  0.0642,  0.1613,  0.1121,  0.2340,\n",
       "                       0.0406, -0.1070, -0.0812,  0.0627, -0.0296,  0.0923, -0.0984,\n",
       "                       0.0427, -0.0719,  0.0765,  0.0298,  0.1632,  0.2208,  0.2223,\n",
       "                      -0.0005,  0.0720, -0.0042,  0.2327,  0.2094,  0.0797, -0.0863,\n",
       "                       0.0171,  0.0547, -0.0090,  0.5090,  0.0078,  0.1823,  0.0643,\n",
       "                       0.7274,  0.0451,  0.1437, -0.0377, -0.0549, -0.0120,  0.2043,\n",
       "                       0.1722,  0.0407,  0.0191,  0.0625,  0.0132,  0.1352,  0.0810,\n",
       "                       0.0953,  0.2503, -0.0216,  0.0415,  0.0322,  0.1210, -0.0040,\n",
       "                       0.0407,  0.3698,  0.0159, -0.0229,  0.0246, -0.2767, -0.0235,\n",
       "                       0.1064, -0.0124,  0.1749,  0.0545,  0.0854,  0.1932,  0.0998,\n",
       "                       0.0466,  0.2502,  0.1484,  0.2059, -0.0030,  0.0296,  0.1316,\n",
       "                       0.0254,  0.1022,  0.1315, -0.0781,  0.0232, -0.1824, -0.0204,\n",
       "                       0.0562,  0.0207, -0.1649, -0.1045, -0.0250, -0.0140,  0.0159,\n",
       "                       0.1355,  0.1786,  0.0690,  0.2002,  0.0833,  0.2319,  0.1116,\n",
       "                       0.0520,  0.0550,  0.0084,  0.0385,  0.1227,  0.1181,  0.4251,\n",
       "                       0.0955, -0.0227,  0.0756,  0.1801, -0.1089,  0.0421,  0.1996,\n",
       "                      -0.2437, -0.0282,  0.0453,  0.0441,  0.3614, -0.0412,  0.1239,\n",
       "                       0.0332,  0.2384, -0.0108,  0.0698,  0.1595,  0.0843,  0.0574,\n",
       "                      -0.0412, -0.0599,  0.0130, -0.0364, -0.0569,  0.0959, -0.1712,\n",
       "                       0.1891,  0.1267, -0.0425, -0.0109,  0.0504,  0.1914,  0.2945,\n",
       "                      -0.0578,  0.0961,  0.1997,  0.0618,  0.2468,  0.2437, -0.0335,\n",
       "                       0.0648,  0.1439, -0.0366,  0.0443,  0.0301,  0.0239, -0.0644,\n",
       "                       0.1853, -0.2082, -0.0355,  0.1341,  0.0453, -0.0281,  0.1304,\n",
       "                       0.0101, -0.0061,  0.0926,  0.1800,  0.1255,  0.0115,  0.1394,\n",
       "                       0.0093, -0.1209, -0.0203,  0.1399,  0.1439,  0.1834,  0.1017,\n",
       "                       0.0452,  0.0746, -0.1002,  0.0700,  0.0749,  0.0574,  0.2040,\n",
       "                       0.1284,  0.0805,  0.0870,  0.0006, -0.1511,  0.0101,  0.2440,\n",
       "                       0.0365,  0.0537,  0.1194,  0.0989, -0.0414, -0.0061,  0.1070,\n",
       "                       0.1058,  0.3179,  0.0121,  0.0370,  0.0389,  0.0000, -0.1804,\n",
       "                       0.0929,  0.3558,  0.1756,  0.0522,  0.2872,  0.0886,  0.1082,\n",
       "                      -0.0221,  0.0369,  0.0313, -0.0184,  0.1681, -0.0005,  0.1982,\n",
       "                       0.1346,  0.0420,  0.0092,  0.0873, -0.0329,  0.3260,  0.1076,\n",
       "                       0.0007,  0.0102,  0.0700, -0.0114,  0.1487, -0.2037,  0.0565,\n",
       "                      -0.0911,  0.0195,  0.1008,  0.1843,  0.1602,  0.1813,  0.1170,\n",
       "                       0.0651,  0.0971,  0.1957,  0.1898,  0.0522, -0.1087,  0.1308,\n",
       "                       0.0452,  0.0128, -0.0396, -0.1861, -0.0706,  0.1204, -0.0488,\n",
       "                      -0.0284, -0.0106,  0.1091,  0.0538,  0.1165, -0.0294,  0.4032,\n",
       "                      -0.0647,  0.0229,  0.0882,  0.0315,  0.0037,  0.3014,  0.0682,\n",
       "                      -0.0615,  0.0717,  0.0266,  0.3538, -0.1053,  0.1130,  0.0906,\n",
       "                       0.0033,  0.0573,  0.5151,  0.0496,  0.1050,  0.0009,  0.2959,\n",
       "                      -0.0680,  0.0776, -0.1735, -0.2483,  0.2913,  0.1027, -0.0255,\n",
       "                       0.4228,  0.0564, -0.0218,  0.2791,  0.2471, -0.0206,  0.4103,\n",
       "                       0.1065, -0.1077,  0.0324,  0.0079,  0.0224,  0.0890,  0.0919,\n",
       "                       0.0424,  0.1697,  0.1593,  0.5850,  0.0440,  0.0847,  0.0156,\n",
       "                       0.0537,  0.0076, -0.0170,  0.0694,  0.1975,  0.0270, -0.0401,\n",
       "                      -0.0046,  0.1897,  0.0138,  0.0808, -0.0101,  0.2125,  0.1361,\n",
       "                      -0.7692,  0.0418,  0.0598,  0.0011, -0.0152,  0.2785,  0.0527,\n",
       "                       0.1239,  0.0308,  0.1430,  0.0122,  0.0334, -0.0149, -0.0680,\n",
       "                       0.3459], device='cuda:0')),\n",
       "             ('classifier.0.weight',\n",
       "              tensor([[-1.1094e-03, -2.6891e-03,  2.1942e-03,  ...,  6.6429e-03,\n",
       "                       -4.2384e-04, -2.0694e-03],\n",
       "                      [ 5.1961e-03,  2.0472e-03,  4.6155e-03,  ..., -5.3580e-03,\n",
       "                       -4.5462e-03, -1.8746e-03],\n",
       "                      [-5.2747e-04,  5.1788e-03,  1.8400e-03,  ...,  6.8096e-03,\n",
       "                        4.6883e-04,  9.0971e-03],\n",
       "                      ...,\n",
       "                      [-7.5426e-03, -9.6441e-03, -2.5061e-03,  ..., -7.9279e-03,\n",
       "                       -1.0565e-02, -3.6023e-03],\n",
       "                      [-4.4378e-04,  1.4222e-03, -1.8937e-03,  ...,  3.5541e-03,\n",
       "                        2.1086e-03,  3.7892e-03],\n",
       "                      [ 6.2846e-03,  4.1432e-03, -3.7906e-04,  ..., -2.9724e-03,\n",
       "                        1.0594e-03,  4.7496e-03]], device='cuda:0')),\n",
       "             ('classifier.0.bias', tensor(1.00000e-02 *\n",
       "                     [ 3.4060,  0.2118,  2.1749,  ..., -0.5994,  4.8050,  0.0121], device='cuda:0')),\n",
       "             ('classifier.3.weight',\n",
       "              tensor([[-1.1262e-02,  1.0421e-02, -1.6899e-03,  ..., -1.6088e-02,\n",
       "                        1.2137e-02,  6.5078e-03],\n",
       "                      [-5.4509e-04, -7.8270e-03,  7.1184e-03,  ..., -4.0817e-03,\n",
       "                        9.8776e-03, -1.1085e-02],\n",
       "                      [-1.0933e-02, -5.1533e-03,  1.6766e-02,  ..., -3.6180e-03,\n",
       "                        3.5386e-03, -2.2417e-02],\n",
       "                      ...,\n",
       "                      [-1.0725e-02, -7.2678e-03, -3.8252e-03,  ..., -2.4693e-03,\n",
       "                        8.3481e-03, -5.4105e-03],\n",
       "                      [ 5.4018e-03,  8.1430e-03, -1.3569e-02,  ...,  4.0841e-03,\n",
       "                       -4.1793e-04, -2.2802e-03],\n",
       "                      [ 2.8788e-02,  6.5824e-03,  4.8993e-03,  ...,  2.4367e-02,\n",
       "                        6.5563e-03, -7.2610e-03]], device='cuda:0')),\n",
       "             ('classifier.3.bias',\n",
       "              tensor([ 0.0332,  0.0616,  0.0307,  ...,  0.0456,  0.0442,  0.0588], device='cuda:0')),\n",
       "             ('classifier.6.weight',\n",
       "              tensor([[ 1.3450e-02,  4.2154e-02, -2.3040e-03,  ..., -4.9025e-04,\n",
       "                        1.8880e-02, -1.4209e-02],\n",
       "                      [ 7.6020e-03,  4.7305e-02, -5.0164e-03,  ..., -4.9127e-03,\n",
       "                       -5.6295e-03, -1.4197e-02],\n",
       "                      [ 2.1238e-03, -1.2520e-02, -1.8903e-02,  ..., -1.0263e-02,\n",
       "                        3.0020e-02, -2.8852e-02],\n",
       "                      ...,\n",
       "                      [-9.8278e-03,  3.2054e-02,  3.5979e-02,  ..., -5.6409e-03,\n",
       "                        8.3202e-03, -7.5155e-03],\n",
       "                      [ 1.6646e-02, -1.1247e-03,  1.5044e-03,  ..., -9.1578e-03,\n",
       "                       -8.6418e-03, -2.0923e-02],\n",
       "                      [-6.4900e-06, -2.2274e-02,  5.2750e-04,  ...,  4.4403e-02,\n",
       "                       -9.4047e-03, -1.2332e-02]], device='cuda:0')),\n",
       "             ('classifier.6.bias',\n",
       "              tensor([ 0.0202, -0.0298, -0.0060,  0.0054,  0.0247,  0.0009,  0.0077,\n",
       "                      -0.0130, -0.0173,  0.0025, -0.0030, -0.0124,  0.0192,  0.0229,\n",
       "                       0.0161, -0.0154,  0.0014,  0.0004,  0.0145,  0.0167,  0.0102,\n",
       "                       0.0237, -0.0012,  0.0161, -0.0054, -0.0117, -0.0107, -0.0295,\n",
       "                      -0.0072,  0.0392,  0.0116,  0.0028, -0.0054, -0.0040,  0.0001,\n",
       "                      -0.0116, -0.0019,  0.0158, -0.0177,  0.0106,  0.0125,  0.0068,\n",
       "                      -0.0129, -0.0044,  0.0035, -0.0027,  0.0223,  0.0232,  0.0101,\n",
       "                       0.0126,  0.0079,  0.0211, -0.0168,  0.0063, -0.0283,  0.0075,\n",
       "                      -0.0294,  0.0490,  0.0497,  0.0382, -0.0621,  0.0176,  0.0137,\n",
       "                       0.0551,  0.0636, -0.0159, -0.0215,  0.0242,  0.0029,  0.0367,\n",
       "                      -0.0003,  0.0103,  0.0604, -0.0207, -0.0284,  0.0383,  0.0224,\n",
       "                       0.0125, -0.0162, -0.0069, -0.0125, -0.0058, -0.0141, -0.0314,\n",
       "                      -0.0145,  0.0269,  0.0008,  0.0618, -0.0255,  0.0457, -0.0232,\n",
       "                      -0.0004, -0.0179, -0.0203, -0.0009, -0.0065,  0.0029,  0.0111,\n",
       "                      -0.0065, -0.0274, -0.0001,  0.0126,  0.0191,  0.0374,  0.0055,\n",
       "                       0.0387,  0.0069, -0.0286, -0.0067, -0.0424, -0.1166,  0.0120,\n",
       "                       0.0011,  0.0265,  0.0183, -0.0550, -0.0016,  0.0264, -0.0027,\n",
       "                      -0.0270,  0.0011, -0.0382,  0.0132, -0.0050, -0.0245,  0.0057,\n",
       "                      -0.0611,  0.0027,  0.0060,  0.0008, -0.0679,  0.0090,  0.0449,\n",
       "                      -0.0041, -0.0490, -0.0385, -0.0308, -0.0030,  0.0045, -0.0073,\n",
       "                       0.0077,  0.0056, -0.0159, -0.0335, -0.0125, -0.0192,  0.0203,\n",
       "                       0.0054,  0.0195,  0.0186,  0.0058,  0.0173, -0.0825,  0.0625,\n",
       "                      -0.0129,  0.0201,  0.0271, -0.0017, -0.0591,  0.0241, -0.0064,\n",
       "                       0.0316,  0.0766, -0.0003,  0.0317, -0.0288,  0.0057, -0.0395,\n",
       "                       0.0403,  0.0090,  0.0353,  0.0723, -0.0005, -0.0287,  0.0624,\n",
       "                      -0.0421,  0.0124,  0.0371,  0.0423, -0.0011,  0.0258,  0.0132,\n",
       "                       0.0599,  0.0265, -0.0077,  0.0168,  0.0196,  0.0345, -0.0089,\n",
       "                       0.0296, -0.0119,  0.0311,  0.0379, -0.0068,  0.0291,  0.0707,\n",
       "                       0.0354,  0.0045, -0.0067,  0.0490, -0.0712,  0.0065,  0.0584,\n",
       "                       0.0536,  0.0179,  0.0369, -0.0197,  0.0339, -0.0135,  0.0699,\n",
       "                       0.0044, -0.0183,  0.0152, -0.0228,  0.0163,  0.0454, -0.0286,\n",
       "                       0.0494,  0.0075, -0.0105, -0.0226, -0.0165,  0.0457,  0.0845,\n",
       "                      -0.0123,  0.0725,  0.0025,  0.0064, -0.0066,  0.0710,  0.0356,\n",
       "                      -0.0219,  0.0670,  0.0152,  0.0606,  0.0106,  0.0252,  0.0405,\n",
       "                       0.0454,  0.0645,  0.0140, -0.0260,  0.0069,  0.0154,  0.0104,\n",
       "                      -0.0022, -0.0217,  0.0274, -0.0040,  0.0037,  0.0488,  0.0220,\n",
       "                       0.0235, -0.0357,  0.0599,  0.0036,  0.0102,  0.0718,  0.0151,\n",
       "                       0.0194, -0.0106,  0.0100, -0.0350,  0.0511,  0.0067,  0.0159,\n",
       "                       0.0420, -0.0508, -0.0179,  0.0276,  0.0206, -0.0046,  0.0218,\n",
       "                       0.0059, -0.0330, -0.0076,  0.0198,  0.0094, -0.0087,  0.0171,\n",
       "                      -0.0223,  0.1236, -0.0382,  0.0014,  0.0545,  0.0481,  0.0348,\n",
       "                      -0.0047, -0.0198,  0.0388,  0.0061, -0.0144,  0.0495, -0.0271,\n",
       "                      -0.0248, -0.0063,  0.0143,  0.0225, -0.0492,  0.0385, -0.0297,\n",
       "                      -0.0186, -0.0020, -0.0421, -0.0606,  0.0175,  0.0278, -0.0342,\n",
       "                      -0.0050, -0.0201, -0.0538, -0.0070, -0.0401,  0.0521,  0.0054,\n",
       "                       0.0090, -0.0000, -0.0338, -0.0280, -0.0241, -0.0101, -0.0387,\n",
       "                      -0.0239, -0.0289,  0.0019, -0.0600, -0.0135, -0.0604, -0.0315,\n",
       "                      -0.0743,  0.0064, -0.0305,  0.0306,  0.0530,  0.0517,  0.0226,\n",
       "                       0.0090, -0.0216, -0.0489,  0.0261, -0.0012, -0.0382,  0.0068,\n",
       "                       0.0153,  0.0254, -0.0334,  0.0337,  0.0166, -0.0161,  0.0233,\n",
       "                       0.0262, -0.0083, -0.0136, -0.0102,  0.0126, -0.0027, -0.0517,\n",
       "                      -0.0122, -0.0043,  0.0706, -0.0106,  0.0333,  0.0016,  0.0275,\n",
       "                       0.0352,  0.0263,  0.0474,  0.0294, -0.0152,  0.0410, -0.0119,\n",
       "                      -0.0384,  0.0349,  0.0254,  0.0005,  0.0033,  0.0207,  0.0163,\n",
       "                       0.0597,  0.0152, -0.0606, -0.0177,  0.0670,  0.0148, -0.0190,\n",
       "                      -0.0035,  0.0378, -0.0051,  0.0059,  0.0194, -0.0236,  0.0192,\n",
       "                      -0.0227, -0.0201, -0.0051,  0.0238,  0.0067, -0.0074, -0.0562,\n",
       "                       0.0232,  0.0033,  0.0250, -0.0131,  0.0242, -0.0085,  0.0497,\n",
       "                       0.0106, -0.0742, -0.0759, -0.0241,  0.0011, -0.0035, -0.0161,\n",
       "                       0.0360, -0.0028, -0.0267,  0.0390, -0.0426, -0.0100, -0.0084,\n",
       "                       0.0284, -0.0122, -0.0533,  0.0349,  0.0547,  0.0089, -0.0423,\n",
       "                      -0.0617,  0.0070, -0.0322, -0.0038,  0.0521, -0.0240,  0.0174,\n",
       "                      -0.0689, -0.0026,  0.0306, -0.0150,  0.0140, -0.0509,  0.0037,\n",
       "                      -0.0027,  0.0356, -0.0304,  0.0223,  0.0496,  0.0012, -0.0342,\n",
       "                       0.0607,  0.0339,  0.0061,  0.0072, -0.0017,  0.0361,  0.0212,\n",
       "                      -0.0333,  0.0191, -0.0060, -0.0274,  0.0029, -0.0034,  0.0169,\n",
       "                      -0.0036, -0.0682,  0.0238,  0.0161,  0.0430,  0.0139,  0.0299,\n",
       "                       0.0150, -0.0230,  0.0210, -0.0284,  0.0201,  0.0337,  0.0824,\n",
       "                      -0.0257,  0.1029,  0.0012, -0.0279,  0.0529, -0.0249,  0.0059,\n",
       "                      -0.0044, -0.0279,  0.0325, -0.0176,  0.0520, -0.0838,  0.0148,\n",
       "                      -0.0128,  0.0453,  0.0244, -0.0406, -0.0551, -0.0224,  0.0335,\n",
       "                      -0.0798,  0.0228, -0.0198,  0.0090, -0.0242, -0.0923,  0.0119,\n",
       "                       0.0240,  0.0321, -0.0847, -0.0167, -0.0031,  0.0046, -0.0234,\n",
       "                      -0.0046,  0.0152,  0.0121,  0.0126,  0.0165, -0.0199,  0.0332,\n",
       "                      -0.0082, -0.0203, -0.0363, -0.0076,  0.0289,  0.0028,  0.0445,\n",
       "                       0.0048,  0.0774,  0.0593, -0.0305, -0.0001, -0.0104, -0.0195,\n",
       "                      -0.0008, -0.0237,  0.0168,  0.0380, -0.0249,  0.0280, -0.0025,\n",
       "                      -0.0028, -0.0146, -0.0450, -0.0020, -0.0462, -0.0070, -0.0054,\n",
       "                      -0.0040, -0.0118,  0.0266,  0.0230,  0.0255,  0.0233, -0.0308,\n",
       "                      -0.0450, -0.0214, -0.0138, -0.0379,  0.0137, -0.0358, -0.0602,\n",
       "                      -0.0160,  0.0100, -0.0398,  0.0512,  0.0347, -0.0281,  0.0008,\n",
       "                      -0.0475, -0.0057,  0.0212,  0.0414, -0.0103, -0.0248, -0.0290,\n",
       "                       0.0041,  0.0262,  0.0112,  0.0476, -0.0246,  0.0173, -0.0488,\n",
       "                      -0.0271, -0.0723,  0.0439, -0.0373,  0.0029,  0.0251,  0.0252,\n",
       "                      -0.0091,  0.0319, -0.0140, -0.0053,  0.0259, -0.0083,  0.0186,\n",
       "                      -0.0347, -0.0166,  0.0828,  0.0151, -0.0507, -0.0320, -0.0033,\n",
       "                       0.0010,  0.0323, -0.0096,  0.0188,  0.0316, -0.0527,  0.0082,\n",
       "                      -0.0027,  0.0329, -0.0209,  0.0031,  0.0226, -0.0219, -0.0457,\n",
       "                      -0.0487,  0.0498, -0.0347, -0.0520,  0.0565, -0.0020,  0.0048,\n",
       "                      -0.0103, -0.0120, -0.0271, -0.0044,  0.0470,  0.0094, -0.0103,\n",
       "                       0.0248, -0.0212, -0.0347,  0.0262,  0.0337, -0.0101, -0.0250,\n",
       "                      -0.0410, -0.0628,  0.0076, -0.0245, -0.0353,  0.0055, -0.0542,\n",
       "                      -0.0753, -0.0188, -0.0207, -0.0123,  0.0191,  0.0130,  0.0120,\n",
       "                       0.0456, -0.0108,  0.0257,  0.0293,  0.0715,  0.0344,  0.0175,\n",
       "                      -0.0193, -0.0382,  0.0442,  0.0208,  0.0178, -0.0042,  0.0142,\n",
       "                       0.0465, -0.0007,  0.0019,  0.0272,  0.0299,  0.0335,  0.0776,\n",
       "                       0.0364,  0.0207,  0.0443,  0.0066, -0.0838,  0.0112,  0.0051,\n",
       "                      -0.0130,  0.0119,  0.0223,  0.0121, -0.0162, -0.0284,  0.0287,\n",
       "                      -0.0016,  0.0001, -0.0220, -0.0162,  0.0085,  0.0552, -0.0102,\n",
       "                      -0.0693, -0.0187,  0.0402,  0.0188,  0.0028, -0.0140, -0.0148,\n",
       "                      -0.0254, -0.0217, -0.0373,  0.0195,  0.0414, -0.0673,  0.0544,\n",
       "                       0.0361, -0.0326, -0.0158, -0.0146, -0.0045, -0.0241,  0.0419,\n",
       "                      -0.0429,  0.0342,  0.0145,  0.0023, -0.0101,  0.0136,  0.0103,\n",
       "                      -0.0369, -0.0057, -0.0452, -0.0083, -0.0000,  0.0501,  0.0069,\n",
       "                      -0.0067, -0.0336, -0.0624,  0.0080,  0.0143, -0.0833, -0.0305,\n",
       "                      -0.0105, -0.0207, -0.0287,  0.0366,  0.1096,  0.0066, -0.0229,\n",
       "                       0.0099,  0.0430, -0.0305,  0.0477, -0.0356,  0.0155, -0.0140,\n",
       "                       0.0277, -0.0259,  0.0013,  0.0284, -0.0135, -0.0687,  0.0175,\n",
       "                       0.0502,  0.0174,  0.0380,  0.0099,  0.0229,  0.0129, -0.0269,\n",
       "                       0.0490, -0.0096, -0.0359, -0.0264, -0.0205,  0.0037, -0.0092,\n",
       "                       0.0214, -0.0428, -0.0415, -0.0385, -0.0318,  0.0346,  0.0475,\n",
       "                       0.0245, -0.0623, -0.0527,  0.0087, -0.0044, -0.0183, -0.0355,\n",
       "                      -0.0084,  0.0781,  0.0162, -0.0296,  0.0045, -0.0164, -0.0689,\n",
       "                       0.0055, -0.0009,  0.0075,  0.0003, -0.0457,  0.0227,  0.0017,\n",
       "                      -0.0335, -0.0090, -0.0622,  0.0538,  0.0004,  0.0403,  0.0032,\n",
       "                      -0.0695, -0.0323,  0.0230,  0.0026, -0.0392, -0.0509, -0.0458,\n",
       "                       0.0322, -0.0271, -0.0075, -0.0045,  0.0411, -0.0057, -0.0396,\n",
       "                       0.0143,  0.0024,  0.0146,  0.0460,  0.0008,  0.0130,  0.0144,\n",
       "                      -0.0290, -0.0446,  0.0085, -0.0289, -0.0053,  0.0202,  0.0036,\n",
       "                       0.0152,  0.0809, -0.0155,  0.0449,  0.0006, -0.0124,  0.0082,\n",
       "                      -0.0038, -0.0422,  0.0261,  0.0217, -0.0169,  0.0134, -0.0263,\n",
       "                       0.0363,  0.0485, -0.0037,  0.0141,  0.0008, -0.0600,  0.0037,\n",
       "                      -0.0261,  0.0050, -0.0244, -0.0274, -0.0377,  0.0381,  0.0109,\n",
       "                       0.0282, -0.0358,  0.0233,  0.0198, -0.0038, -0.0066, -0.0189,\n",
       "                      -0.0450, -0.0120,  0.0088, -0.0262, -0.0212,  0.0129, -0.0185,\n",
       "                      -0.0267,  0.0041,  0.0016, -0.0168, -0.0108,  0.0396,  0.0185,\n",
       "                       0.0257, -0.0474,  0.0188, -0.0396, -0.0224, -0.0048,  0.0006,\n",
       "                       0.0015, -0.0296, -0.0237,  0.0059,  0.0393, -0.0045,  0.0013,\n",
       "                       0.0197,  0.0086,  0.0095, -0.0831, -0.0095,  0.0058, -0.0280,\n",
       "                       0.0113,  0.0053,  0.0219, -0.0009, -0.0038, -0.0578,  0.0030,\n",
       "                      -0.0219, -0.0749, -0.0437,  0.0204, -0.0034,  0.0188, -0.0173,\n",
       "                       0.0174,  0.0475,  0.0664, -0.0170, -0.0109,  0.0073,  0.0263,\n",
       "                      -0.0219, -0.0107,  0.0257, -0.0399,  0.0093,  0.0697, -0.0100,\n",
       "                      -0.0324, -0.0781, -0.0267, -0.0001,  0.0298,  0.0063, -0.0153,\n",
       "                      -0.0247, -0.0234, -0.0085, -0.0076, -0.0355,  0.0084, -0.0449,\n",
       "                      -0.0259, -0.0355, -0.0714,  0.0093, -0.0732, -0.0967, -0.0311,\n",
       "                      -0.0351, -0.0168, -0.0227,  0.0074, -0.0098, -0.0447, -0.0233,\n",
       "                      -0.0427, -0.0101,  0.0046, -0.0161, -0.0482, -0.0441,  0.0619,\n",
       "                      -0.0095,  0.0261, -0.0864,  0.0161, -0.0082,  0.0509,  0.0019,\n",
       "                      -0.0513,  0.0221, -0.0030,  0.0367,  0.0274, -0.0147,  0.0105,\n",
       "                       0.0158,  0.0180,  0.0594, -0.0002, -0.0521, -0.0289, -0.0364,\n",
       "                      -0.0654, -0.0006, -0.0276, -0.0442, -0.0488, -0.0452, -0.0585,\n",
       "                      -0.0316, -0.0140, -0.0509,  0.0209, -0.0325, -0.0072], device='cuda:0'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG16.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/lfw/Dan_Ackroyd/Dan_Ackroyd_0001.jpg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_files_short[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Write a Dog Detector\n",
    "\n",
    "While looking at the [dictionary](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a), you will notice that the categories corresponding to dogs appear in an uninterrupted sequence and correspond to dictionary keys 151-268, inclusive, to include all categories from `'Chihuahua'` to `'Mexican hairless'`.  Thus, in order to check to see if an image is predicted to contain a dog by the pre-trained VGG-16 model, we need only check if the pre-trained model predicts an index between 151 and 268 (inclusive).\n",
    "\n",
    "Use these ideas to complete the `dog_detector` function below, which returns `True` if a dog is detected in an image (and `False` if not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### returns \"True\" if a dog is detected in the image stored at img_path\n",
    "def dog_detector(img_path):\n",
    "    ## TODO: Complete the function.\n",
    "    result = VGG16_predict(img_path).item() #convert tensor result to scalar\n",
    "    \n",
    "    return (result >= 151) and (result <=268)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Assess the Dog Detector\n",
    "\n",
    "__Question 2:__ Use the code cell below to test the performance of your `dog_detector` function.  \n",
    "- What percentage of the images in `human_files_short` have a detected dog?  \n",
    "- What percentage of the images in `dog_files_short` have a detected dog?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO: Test the performance of the dog_detector function\n",
    "### on the images in human_files_short and dog_files_short.\n",
    "### TODO implement it for entire series of images not just one\n",
    "\n",
    "#dog_detector(dog_files_short[3])\n",
    "\n",
    "dog_files_short[2]\n",
    "dog_detector(dog_files_short[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suggest VGG-16 as a potential network to detect dog images in your algorithm, but you are free to explore other pre-trained networks (such as [Inception-v3](http://pytorch.org/docs/master/torchvision/models.html#inception-v3), [ResNet-50](http://pytorch.org/docs/master/torchvision/models.html#id3), etc).  Please use the code cell below to test other pre-trained PyTorch models.  If you decide to pursue this _optional_ task, report performance on `human_files_short` and `dog_files_short`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (Optional) \n",
    "### TODO: Report the performance of another pre-trained network.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "## Step 3: Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "\n",
    "Now that we have functions for detecting humans and dogs in images, we need a way to predict breed from images.  In this step, you will create a CNN that classifies dog breeds.  You must create your CNN _from scratch_ (so, you can't use transfer learning _yet_!), and you must attain a test accuracy of at least 10%.  In Step 4 of this notebook, you will have the opportunity to use transfer learning to create a CNN that attains greatly improved accuracy.\n",
    "\n",
    "We mention that the task of assigning breed to dogs from images is considered exceptionally challenging.  To see why, consider that *even a human* would have trouble distinguishing between a Brittany and a Welsh Springer Spaniel.  \n",
    "\n",
    "Brittany | Welsh Springer Spaniel\n",
    "- | - \n",
    "<img src=\"images/Brittany_02625.jpg\" width=\"100\"> | <img src=\"images/Welsh_springer_spaniel_08203.jpg\" width=\"200\">\n",
    "\n",
    "It is not difficult to find other dog breed pairs with minimal inter-class variation (for instance, Curly-Coated Retrievers and American Water Spaniels).  \n",
    "\n",
    "Curly-Coated Retriever | American Water Spaniel\n",
    "- | -\n",
    "<img src=\"images/Curly-coated_retriever_03896.jpg\" width=\"200\"> | <img src=\"images/American_water_spaniel_00648.jpg\" width=\"200\">\n",
    "\n",
    "\n",
    "Likewise, recall that labradors come in yellow, chocolate, and black.  Your vision-based algorithm will have to conquer this high intra-class variation to determine how to classify all of these different shades as the same breed.  \n",
    "\n",
    "Yellow Labrador | Chocolate Labrador | Black Labrador\n",
    "- | -\n",
    "<img src=\"images/Labrador_retriever_06457.jpg\" width=\"150\"> | <img src=\"images/Labrador_retriever_06455.jpg\" width=\"240\"> | <img src=\"images/Labrador_retriever_06449.jpg\" width=\"220\">\n",
    "\n",
    "We also mention that random chance presents an exceptionally low bar: setting aside the fact that the classes are slightly imabalanced, a random guess will provide a correct answer roughly 1 in 133 times, which corresponds to an accuracy of less than 1%.  \n",
    "\n",
    "Remember that the practice is far ahead of the theory in deep learning.  Experiment with many different architectures, and trust your intuition.  And, of course, have fun!\n",
    "\n",
    "### (IMPLEMENTATION) Specify Data Loaders for the Dog Dataset\n",
    "\n",
    "Use the code cell below to write three separate [data loaders](http://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for the training, validation, and test datasets of dog images (located at `dog_images/train`, `dog_images/valid`, and `dog_images/test`, respectively).  You may find [this documentation on custom datasets](http://pytorch.org/docs/stable/torchvision/datasets.html) to be a useful resource.  If you are interested in augmenting your training and/or validation data, check out the wide variety of [transforms](http://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transform)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/dog_images/train/103.Mastiff/Mastiff_06871.jpg'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_files_short[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "### TODO: Write data loaders for training, validation, and test sets\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "data_transform_aug_true = transforms.Compose([\n",
    "    #transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop(224), #later try center crop, there are photos with only dog ears with randomresizecrop\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_transform_aug_false = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "def dataloader_train(data_transform=data_transform_aug_true):\n",
    "    data = torchvision.datasets.ImageFolder('/data/dog_images/train', transform=data_transform)\n",
    "    return data\n",
    "def dataloader_valid(data_transform=data_transform_aug_false):\n",
    "    data = torchvision.datasets.ImageFolder('/data/dog_images/valid', transform=data_transform)\n",
    "    return data\n",
    "def dataloader_test(data_transform=data_transform_aug_false):\n",
    "    data = torchvision.datasets.ImageFolder('/data/dog_images/test', transform=data_transform)\n",
    "    return data\n",
    "\n",
    "#TODO transform\n",
    "#TODO dataset\n",
    "#dog_files_short[2]\n",
    "#test = dataloader_test()\n",
    "#train = dataloader_train()\n",
    "#loaders_scratch = {}\n",
    "'''\n",
    "\n",
    "loaders_scratch['train'] = dataloader_train()\n",
    "loaders_scratch['valid'] = dataloader_valid()\n",
    "loaders_scratch['test'] = dataloader_test()\n",
    "'''\n",
    "\n",
    "batch_size = 20\n",
    "num_workers = 0\n",
    "temp_data = {}\n",
    "temp_data['train'] = dataloader_train()\n",
    "temp_data['valid'] = dataloader_valid()\n",
    "temp_data['test'] = dataloader_test()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(temp_data['train'],\n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=num_workers,\n",
    "                                           shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(temp_data['valid'],\n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=num_workers,\n",
    "                                           shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(temp_data['test'],\n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=num_workers,\n",
    "                                           shuffle=False)\n",
    "\n",
    "loaders_scratch['train'] = train_loader\n",
    "loaders_scratch['valid'] = valid_loader\n",
    "loaders_scratch['test'] = test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%matplotlib inline\\ndef show(img):\\n    npimg = img.numpy()\\n    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\\nshow(test)\\n\\nmodel_scratch(test.unsqueeze_(0))\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train[0][0].size() --> torch.Size([3, 224, 224])\n",
    "#plt.imshow()\n",
    "#test = train[0][0]\n",
    "#test.size()\n",
    "\n",
    "# smth pytorch moderator method to show tensor image using plt.imshow()\n",
    "'''\n",
    "%matplotlib inline\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "show(test)\n",
    "\n",
    "model_scratch(test.unsqueeze_(0))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Describe your chosen procedure for preprocessing the data. \n",
    "- How does your code resize the images (by cropping, stretching, etc)?  What size did you pick for the input tensor, and why?\n",
    "- Did you decide to augment the dataset?  If so, how (through translations, flips, rotations, etc)?  If not, why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "* I wrote two flavors of transformation one with augmentation for train, one for test and valid without augmentation\n",
    "* Augmentation allows my train to generalize better, and learn more (with the horizontal flip) with less data\n",
    "* I picked minor rotation and horizontal flip which should not alter the integrity of the data (a horizontally flipped dog is still a dog)\n",
    "* similarly randomresizedcrop should give my train model some noises hoping to generalize better\n",
    "* for test and valid, to mimic real world, I wouldn't want to change it too much, so it's just a resize\n",
    "* I resize to 224, 224 which trains much faster than the original image (I learned this from earlier exercise)\n",
    "* There's no need for normalization because we are not using an existing architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Create a CNN to classify dog breed.  Use the template in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "#num_breeds=133\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## Define layers of a CNN\n",
    "        '''\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "        # calc padding\n",
    "        # [3, 224, 224] \n",
    "        # 224.0/5.0 = 44.8\n",
    "        # what's the shape after this\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5, padding=1)\n",
    "        # padded to 45 on the side and now don't need extra padding because 45.0/3.0 = 15.0\n",
    "        self.conv2 = nn.Conv2d(10, 15, kernel_size=3) #out_chanel corresponds how many filters in a stack?\n",
    "        self.fc2 = nn.Linear(prev_output,num_breeds)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        '''\n",
    "        '''\n",
    "        if dimension wrong\n",
    "        get this error\n",
    "        RuntimeError: invalid argument 2: size '[-1 x 180]' is invalid for input with 13520 elements at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/TH/THStorage.c:37\n",
    "        '''\n",
    "        \n",
    "        # input 1x 3 x 224 x 224\n",
    "        # padding? thinking about padding and also divisibility\n",
    "        # only stride shrinks the height and width\n",
    "        # padding can make something power of 2 and nice math?\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5) #224-5 = 219+1 = 220 #1 x10 x 220 x 220 if no max pooling\n",
    "        self.conv2 = nn.Conv2d(10, 15, kernel_size=3) # 220-3 = 217 +1 = 218 #1x15x218x218 if no max pooling\n",
    "        self.conv3 = nn.Conv2d(15, 20, kernel_size=3) # 218-3 = 215+1 = 216 # 1x 20x 216 x 216 if no max pooling\n",
    "        self.pool = nn.MaxPool2d(2) # 216/2 , 1, 20, 108 x 108\n",
    "        #self.fc1 = nn.Linear(20*108*108,300) \n",
    "        self.fc1 = nn.Linear(20 * 26 * 26,300) \n",
    "        self.fc2 = nn.Linear(300,133)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## Define forward behavior\n",
    "        x = self.pool(F.relu(self.conv1(x))) # 1 x 3 x 224 x 224 --> 1 x 10 x 220 x 220 --> max --> 1 x 10 x 110 x 110\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 1 x 10 x 110 x 110 --> 110-3 = 107 +1 108-> 1 x 15 x 108 x 108 --> max --> 1 x 15 x 54 x 54\n",
    "        x = self.pool(F.relu(self.conv3(x))) # 1 x 15 x54 x 54 --> 54-3 = 51+1 =52 --> 1 x 20 x 52 x 52 --> 1 x 20 x 26 x 26\n",
    "        #flatten\n",
    "        x = x.view(-1, 20 * 26 * 26)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = self.drop(x)\n",
    "        x = self.fc2(x) \n",
    "        \n",
    "        return x\n",
    "\n",
    "#-#-# You so NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_scratch = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "#num_breeds=133\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1) # 1 x32 x 224+2-3+1x 224\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(128*28*28,300) \n",
    "        self.fc2 = nn.Linear(300,133)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## Define forward behavior\n",
    "        x = self.pool(F.relu(self.conv1(x))) # 1x 32 x 224+2-3+1= 224+2-2= 224/2 x 112\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 1x 64 x 112+2-3+1 = 112/2 x 56 # nice math with padding 1\n",
    "        x = self.pool(F.relu(self.conv3(x))) # 1x 128 x  56+2-3+1= 56/2 x 28\n",
    "        #flatten\n",
    "        x = x.view(-1, 128*28*28)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = self.drop(x)\n",
    "        x = self.fc2(x) \n",
    "        \n",
    "        return x\n",
    "\n",
    "#-#-# You so NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_scratch = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 4:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Specify Loss Function and Optimizer\n",
    "\n",
    "Use the next code cell to specify a [loss function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/stable/optim.html).  Save the chosen loss function as `criterion_scratch`, and the optimizer as `optimizer_scratch` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain[0][0]\\n\\n\\n#output = model_scratch(train[0][0].unsqueeze_(0))\\noutput = model_scratch(train[0][0].unsqueeze_(0))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train[0][0]\n",
    "\n",
    "\n",
    "#output = model_scratch(train[0][0].unsqueeze_(0))\n",
    "output = model_scratch(train[0][0].unsqueeze_(0))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion_scratch = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer_scratch = optim.SGD(model_scratch.parameters(),lr=0.05)\n",
    "#optimizer_scratch = optim.SGD(model_scratch.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noutput\\npred = output.data.max(1, keepdim=True)[1]\\npred\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "output\n",
    "pred = output.data.max(1, keepdim=True)[1]\n",
    "pred\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_scratch.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train and Validate the Model\n",
    "\n",
    "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_scratch.pt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1554  100  1554    0     0  11552      0 --:--:-- --:--:-- --:--:-- 11953\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://raw.githubusercontent.com/udacity/workspaces-student-support/master/jupyter/workspace_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            #data = data.unsqueeze_(0)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #train_loss += loss.item()*data.size(0)\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('epoch {} Batch {} train_loss:{}'.format(epoch, batch_idx, train_loss))\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            #data = data.unsqueeze_(0)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            ## update the average validation loss\n",
    "            #valid_loss += loss.item()*data.size(0)\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "        \n",
    "        #train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        #valid_loss = valid_loss / len(loaders['valid'].dataset)\n",
    "            \n",
    "\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        ## TODO : save mean\n",
    "        \n",
    "        if valid_loss <= valid_loss_min:\n",
    "            \n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss))\n",
    "            torch.save(model.state_dict(), 'model_scratch.pt')\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backup.ipynb\t  haarcascades\t    __pycache__\r\n",
      "dog_app-cn.ipynb  images\t    README.md\r\n",
      "dog_app.ipynb\t  model_scratch.pt  workspace_utils.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from workspace_utils import active_session\n",
    " \n",
    "with active_session():\n",
    "    # do long-running work here\n",
    "# train the model\n",
    "    model_scratch = train(20, loaders_scratch, model_scratch, optimizer_scratch, \n",
    "                          criterion_scratch, use_cuda, 'model_scratch.pt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "model_scratch.load_state_dict(torch.load('model_scratch.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call test function    \n",
    "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## Step 4: Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "\n",
    "You will now use transfer learning to create a CNN that can identify dog breed from images.  Your CNN must attain at least 60% accuracy on the test set.\n",
    "\n",
    "### (IMPLEMENTATION) Specify Data Loaders for the Dog Dataset\n",
    "\n",
    "Use the code cell below to write three separate [data loaders](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader) for the training, validation, and test datasets of dog images (located at `dogImages/train`, `dogImages/valid`, and `dogImages/test`, respectively). \n",
    "\n",
    "If you like, **you are welcome to use the same data loaders from the previous step**, when you created a CNN from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders_transfer = loaders_scratch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "loaders_transfer = {}\n",
    "train_loader = torch.utils.data.DataLoader(temp_data['train'],\n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=num_workers,\n",
    "                                           shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(temp_data['valid'],\n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=num_workers,\n",
    "                                           shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(temp_data['test'],\n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=num_workers,\n",
    "                                           shuffle=False)\n",
    "\n",
    "loaders_transfer['train'] = train_loader\n",
    "loaders_transfer['valid'] = valid_loader\n",
    "loaders_transfer['test'] = test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Specify data loaders\n",
    "#loaders_transfer = loaders_scratch.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Use transfer learning to create a CNN to classify dog breed.  Use the code cell below, and save your initialized model as the variable `model_transfer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "model_transfer = models.resnet152(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "model_transfer = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(40960,10240) \n",
    "        self.fc2 = nn.Linear(10240,2560)\n",
    "        self.fc3 = nn.Linear(2560,133)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        self.fc1 = nn.Linear(2048,1024) \n",
    "        self.fc2 = nn.Linear(1024,512)\n",
    "        self.fc3 = nn.Linear(512,133)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = x.view(1, 40960)\n",
    "        x = x.view(1, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "#-#-# You so NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_transfer_part2 = Net2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer.fc = nn.Linear(2048, 133, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer = nn.Sequential(*list(model_transfer.children())[:-1],Net2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=133, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 Batch 0 train_loss:5.072323322296143\n",
      "epoch 1 Batch 100 train_loss:4.780555725097656\n",
      "epoch 1 Batch 200 train_loss:4.62706995010376\n",
      "epoch 1 Batch 300 train_loss:4.495855331420898\n",
      "Epoch: 1 \tTraining Loss: 4.456425 \tValidation Loss: 3.721248\n",
      "Validation loss decreased (inf --> 3.721248).  Saving model ...\n",
      "epoch 2 Batch 0 train_loss:3.9871978759765625\n",
      "epoch 2 Batch 100 train_loss:3.875159502029419\n",
      "epoch 2 Batch 200 train_loss:3.768874168395996\n",
      "epoch 2 Batch 300 train_loss:3.6555111408233643\n",
      "Epoch: 2 \tTraining Loss: 3.617643 \tValidation Loss: 2.816382\n",
      "Validation loss decreased (3.721248 --> 2.816382).  Saving model ...\n",
      "epoch 3 Batch 0 train_loss:3.199366807937622\n",
      "epoch 3 Batch 100 train_loss:3.1649868488311768\n",
      "epoch 3 Batch 200 train_loss:3.075129508972168\n",
      "epoch 3 Batch 300 train_loss:3.0042030811309814\n",
      "Epoch: 3 \tTraining Loss: 2.979583 \tValidation Loss: 2.182696\n",
      "Validation loss decreased (2.816382 --> 2.182696).  Saving model ...\n",
      "epoch 4 Batch 0 train_loss:2.8207931518554688\n",
      "epoch 4 Batch 100 train_loss:2.6582024097442627\n",
      "epoch 4 Batch 200 train_loss:2.6118876934051514\n",
      "epoch 4 Batch 300 train_loss:2.562255620956421\n",
      "Epoch: 4 \tTraining Loss: 2.545286 \tValidation Loss: 1.748024\n",
      "Validation loss decreased (2.182696 --> 1.748024).  Saving model ...\n",
      "epoch 5 Batch 0 train_loss:2.2856059074401855\n",
      "epoch 5 Batch 100 train_loss:2.3168585300445557\n",
      "epoch 5 Batch 200 train_loss:2.2790186405181885\n",
      "epoch 5 Batch 300 train_loss:2.2370686531066895\n",
      "Epoch: 5 \tTraining Loss: 2.224808 \tValidation Loss: 1.485413\n",
      "Validation loss decreased (1.748024 --> 1.485413).  Saving model ...\n",
      "epoch 6 Batch 0 train_loss:1.6358762979507446\n",
      "epoch 6 Batch 100 train_loss:2.0632669925689697\n",
      "epoch 6 Batch 200 train_loss:2.0340700149536133\n",
      "epoch 6 Batch 300 train_loss:1.9985936880111694\n",
      "Epoch: 6 \tTraining Loss: 1.981807 \tValidation Loss: 1.250108\n",
      "Validation loss decreased (1.485413 --> 1.250108).  Saving model ...\n",
      "epoch 7 Batch 0 train_loss:1.7985451221466064\n",
      "epoch 7 Batch 100 train_loss:1.850759506225586\n",
      "epoch 7 Batch 200 train_loss:1.825186014175415\n",
      "epoch 7 Batch 300 train_loss:1.8171075582504272\n",
      "Epoch: 7 \tTraining Loss: 1.808553 \tValidation Loss: 1.097629\n",
      "Validation loss decreased (1.250108 --> 1.097629).  Saving model ...\n",
      "epoch 8 Batch 0 train_loss:1.2875324487686157\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-869446f12935>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mactive_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders_transfer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_transfer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_transfer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_transfer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saved_models/model_transfer.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-6b999be5202b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m###################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;31m# move to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \"\"\"\n\u001b[1;32m    100\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "\n",
    "for params in model_transfer.fc.parameters():\n",
    "    params.requires_grad = True\n",
    "\n",
    "optimizer_transfer = optim.SGD(model_transfer.fc.parameters(),lr=0.005)\n",
    "\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda() \n",
    "    \n",
    "from workspace_utils import active_session\n",
    " \n",
    "with active_session():\n",
    "    train(20, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'saved_models/model_transfer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test = list(model_transfer.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_transfer[9].parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for item in model_transfer:\n",
    "    print(item)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bias = True or False tells you if it is training\n",
    "\n",
    "\n",
    "## TODO: Specify model architecture \n",
    "\n",
    "\n",
    "# num_features = model_transfer\n",
    "\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 5:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  Describe why you think the architecture is suitable for the current problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Specify Loss Function and Optimizer\n",
    "\n",
    "Use the next code cell to specify a [loss function](http://pytorch.org/docs/master/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/master/optim.html).  Save the chosen loss function as `criterion_transfer`, and the optimizer as `optimizer_transfer` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "optimizer_transfer = optim.SGD(model_transfer[9].parameters(),lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train and Validate the Model\n",
    "\n",
    "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_transfer.pt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workspace_utils import active_session\n",
    " \n",
    "with active_session():\n",
    "    # do long-running work here\n",
    "    # train the model\n",
    "    model_transfer = train(20, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n",
    "\n",
    "#model_transfer = train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n",
    "\n",
    "# load the model that got the best validation accuracy (uncomment the line below)\n",
    "#model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images. Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.087686\n",
      "\n",
      "\n",
      "Test Accuracy: 80% (676/836)\n"
     ]
    }
   ],
   "source": [
    "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Predict Dog Breed with the Model\n",
    "\n",
    "Write a function that takes an image path as input and returns the dog breed (`Affenpinscher`, `Afghan hound`, etc) that is predicted by your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Write a function that takes a path to an image as input\n",
    "### and returns the dog breed that is predicted by the model.\n",
    "\n",
    "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
    "class_names = [item[4:].replace(\"_\", \" \") for item in data_transfer['train'].classes]\n",
    "\n",
    "def predict_breed_transfer(img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## Step 5: Write your Algorithm\n",
    "\n",
    "Write an algorithm that accepts a file path to an image and first determines whether the image contains a human, dog, or neither.  Then,\n",
    "- if a __dog__ is detected in the image, return the predicted breed.\n",
    "- if a __human__ is detected in the image, return the resembling dog breed.\n",
    "- if __neither__ is detected in the image, provide output that indicates an error.\n",
    "\n",
    "You are welcome to write your own functions for detecting humans and dogs in images, but feel free to use the `face_detector` and `human_detector` functions developed above.  You are __required__ to use your CNN from Step 4 to predict dog breed.  \n",
    "\n",
    "Some sample output for our algorithm is provided below, but feel free to design your own user experience!\n",
    "\n",
    "![Sample Human Output](images/sample_human_output.png)\n",
    "\n",
    "\n",
    "### (IMPLEMENTATION) Write your Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Write your algorithm.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "def run_app(img_path):\n",
    "    ## handle cases for a human face, dog, and neither\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step6'></a>\n",
    "## Step 6: Test Your Algorithm\n",
    "\n",
    "In this section, you will take your new algorithm for a spin!  What kind of dog does the algorithm think that _you_ look like?  If you have a dog, does it predict your dog's breed accurately?  If you have a cat, does it mistakenly think that your cat is a dog?\n",
    "\n",
    "### (IMPLEMENTATION) Test Your Algorithm on Sample Images!\n",
    "\n",
    "Test your algorithm at least six images on your computer.  Feel free to use any images you like.  Use at least two human and two dog images.  \n",
    "\n",
    "__Question 6:__ Is the output better than you expected :) ?  Or worse :( ?  Provide at least three possible points of improvement for your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ (Three possible points for improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Execute your algorithm from Step 6 on\n",
    "## at least 6 images on your computer.\n",
    "## Feel free to use as many code cells as needed.\n",
    "\n",
    "## suggested code, below\n",
    "for file in np.hstack((human_files[:3], dog_files[:3])):\n",
    "    run_app(file)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
